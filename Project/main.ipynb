{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad474388-2b5a-4e26-b6e0-e3fa46d32b0d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270113c4-8d80-463b-9259-4880a7d19fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import uuid\n",
    "import PIL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2889d-1627-4450-b3b2-20576af1c1e8",
   "metadata": {},
   "source": [
    "# Loading CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ebd8e5-f4e3-4b9b-82fc-2a4101845236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9883d9c-c167-46b9-b4b3-1d08ccc67228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "c, w, h = 3, 32, 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8706e94-b22b-40bd-8145-35ca1f432199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "im_minibatch, label_minibatch = next(iter(testloader))\n",
    "im, label = im_minibatch[0].cpu(), label_minibatch[0].cpu()\n",
    "\n",
    "# store image size dimensions\n",
    "image_size = tuple(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a8119-9310-4a3a-9117-27c1894d15e6",
   "metadata": {},
   "source": [
    "# Loading MobileNetV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f548df6b-dff9-4b65-8e25-70fd91d6b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\raulv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\raulv\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\raulv\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
    "\n",
    "# Replace the final fully-connected layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = torch.nn.Linear(num_ftrs, len(classes))\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09052c18-85ac-4125-82b9-b5f20c31c7c0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea83f6c-7e87-4ae1-a349-47a362e7686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join('weights')):\n",
    "    shutil.rmtree(os.path.join('weights'))\n",
    "!mkdir weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aca6a47-ba6b-45f3-bf9c-0ac02abf9d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, time: 3.109s, loss: 2.396, train accuracy: 0.086\n",
      "epoch: 0, time: 4.491s, loss: 2.289, train accuracy: 0.141\n",
      "epoch: 0, time: 5.749s, loss: 2.415, train accuracy: 0.141\n",
      "epoch: 0, time: 7.004s, loss: 2.176, train accuracy: 0.148\n",
      "epoch: 0, time: 8.248s, loss: 2.157, train accuracy: 0.195\n",
      "epoch: 0, time: 9.491s, loss: 2.172, train accuracy: 0.219\n",
      "epoch: 0, time: 10.737s, loss: 2.027, train accuracy: 0.211\n",
      "epoch: 0, time: 11.978s, loss: 2.033, train accuracy: 0.227\n",
      "epoch: 0, time: 13.226s, loss: 2.073, train accuracy: 0.234\n",
      "epoch: 0, time: 14.473s, loss: 1.925, train accuracy: 0.297\n",
      "epoch: 0, time: 15.712s, loss: 1.895, train accuracy: 0.305\n",
      "epoch: 0, time: 16.948s, loss: 1.898, train accuracy: 0.250\n",
      "epoch: 0, time: 18.193s, loss: 1.796, train accuracy: 0.297\n",
      "epoch: 0, time: 19.433s, loss: 1.891, train accuracy: 0.312\n",
      "epoch: 0, time: 20.676s, loss: 1.781, train accuracy: 0.344\n",
      "epoch: 0, time: 21.922s, loss: 1.830, train accuracy: 0.359\n",
      "epoch: 0, time: 23.163s, loss: 1.921, train accuracy: 0.227\n",
      "epoch: 0, time: 24.401s, loss: 1.647, train accuracy: 0.367\n",
      "epoch: 0, time: 25.643s, loss: 1.794, train accuracy: 0.305\n",
      "epoch: 0, time: 26.902s, loss: 1.764, train accuracy: 0.320\n",
      "Accuracy on the test set: 0.339\n",
      "epoch: 1, time: 29.873s, loss: 1.769, train accuracy: 0.289\n",
      "epoch: 1, time: 31.162s, loss: 1.821, train accuracy: 0.289\n",
      "epoch: 1, time: 32.416s, loss: 1.939, train accuracy: 0.297\n",
      "epoch: 1, time: 33.662s, loss: 1.860, train accuracy: 0.344\n",
      "epoch: 1, time: 34.905s, loss: 1.545, train accuracy: 0.484\n",
      "epoch: 1, time: 36.180s, loss: 1.677, train accuracy: 0.352\n",
      "epoch: 1, time: 37.441s, loss: 1.621, train accuracy: 0.383\n",
      "epoch: 1, time: 38.683s, loss: 1.775, train accuracy: 0.281\n",
      "epoch: 1, time: 39.932s, loss: 1.779, train accuracy: 0.375\n",
      "epoch: 1, time: 41.195s, loss: 1.718, train accuracy: 0.367\n",
      "epoch: 1, time: 42.456s, loss: 1.791, train accuracy: 0.289\n",
      "epoch: 1, time: 43.703s, loss: 1.639, train accuracy: 0.344\n",
      "epoch: 1, time: 44.940s, loss: 1.492, train accuracy: 0.406\n",
      "epoch: 1, time: 46.172s, loss: 1.490, train accuracy: 0.438\n",
      "epoch: 1, time: 47.412s, loss: 1.656, train accuracy: 0.391\n",
      "epoch: 1, time: 48.654s, loss: 1.652, train accuracy: 0.422\n",
      "epoch: 1, time: 49.953s, loss: 1.759, train accuracy: 0.375\n",
      "epoch: 1, time: 51.190s, loss: 1.511, train accuracy: 0.422\n",
      "epoch: 1, time: 52.429s, loss: 1.655, train accuracy: 0.344\n",
      "epoch: 1, time: 53.677s, loss: 1.575, train accuracy: 0.383\n",
      "Accuracy on the test set: 0.426\n",
      "epoch: 2, time: 56.524s, loss: 1.459, train accuracy: 0.461\n",
      "epoch: 2, time: 57.798s, loss: 1.534, train accuracy: 0.391\n",
      "epoch: 2, time: 59.038s, loss: 1.553, train accuracy: 0.469\n",
      "epoch: 2, time: 60.298s, loss: 1.583, train accuracy: 0.438\n",
      "epoch: 2, time: 61.530s, loss: 1.453, train accuracy: 0.453\n",
      "epoch: 2, time: 62.784s, loss: 1.483, train accuracy: 0.383\n",
      "epoch: 2, time: 64.072s, loss: 1.517, train accuracy: 0.438\n",
      "epoch: 2, time: 65.333s, loss: 1.815, train accuracy: 0.398\n",
      "epoch: 2, time: 66.758s, loss: 1.438, train accuracy: 0.438\n",
      "epoch: 2, time: 68.086s, loss: 1.657, train accuracy: 0.445\n",
      "epoch: 2, time: 69.355s, loss: 1.573, train accuracy: 0.438\n",
      "epoch: 2, time: 70.598s, loss: 1.386, train accuracy: 0.508\n",
      "epoch: 2, time: 71.845s, loss: 1.503, train accuracy: 0.438\n",
      "epoch: 2, time: 73.084s, loss: 1.571, train accuracy: 0.438\n",
      "epoch: 2, time: 74.347s, loss: 1.528, train accuracy: 0.469\n",
      "epoch: 2, time: 75.589s, loss: 1.438, train accuracy: 0.484\n",
      "epoch: 2, time: 76.855s, loss: 1.485, train accuracy: 0.453\n",
      "epoch: 2, time: 78.089s, loss: 1.554, train accuracy: 0.477\n",
      "epoch: 2, time: 79.340s, loss: 1.564, train accuracy: 0.445\n",
      "epoch: 2, time: 80.642s, loss: 1.603, train accuracy: 0.406\n",
      "Accuracy on the test set: 0.484\n",
      "epoch: 3, time: 83.566s, loss: 1.514, train accuracy: 0.453\n",
      "epoch: 3, time: 84.820s, loss: 1.668, train accuracy: 0.414\n",
      "epoch: 3, time: 86.067s, loss: 1.448, train accuracy: 0.523\n",
      "epoch: 3, time: 87.330s, loss: 1.382, train accuracy: 0.516\n",
      "epoch: 3, time: 88.573s, loss: 1.399, train accuracy: 0.461\n",
      "epoch: 3, time: 89.820s, loss: 1.450, train accuracy: 0.445\n",
      "epoch: 3, time: 91.057s, loss: 1.571, train accuracy: 0.414\n",
      "epoch: 3, time: 92.312s, loss: 1.495, train accuracy: 0.461\n",
      "epoch: 3, time: 93.561s, loss: 1.515, train accuracy: 0.492\n",
      "epoch: 3, time: 94.805s, loss: 1.536, train accuracy: 0.430\n",
      "epoch: 3, time: 96.041s, loss: 1.514, train accuracy: 0.461\n",
      "epoch: 3, time: 97.298s, loss: 1.513, train accuracy: 0.430\n",
      "epoch: 3, time: 98.542s, loss: 1.561, train accuracy: 0.445\n",
      "epoch: 3, time: 99.805s, loss: 1.495, train accuracy: 0.492\n",
      "epoch: 3, time: 101.041s, loss: 1.317, train accuracy: 0.547\n",
      "epoch: 3, time: 102.281s, loss: 1.359, train accuracy: 0.523\n",
      "epoch: 3, time: 103.520s, loss: 1.619, train accuracy: 0.445\n",
      "epoch: 3, time: 104.772s, loss: 1.389, train accuracy: 0.516\n",
      "epoch: 3, time: 106.023s, loss: 1.457, train accuracy: 0.508\n",
      "epoch: 3, time: 107.271s, loss: 1.394, train accuracy: 0.477\n",
      "Accuracy on the test set: 0.519\n",
      "epoch: 4, time: 110.132s, loss: 1.519, train accuracy: 0.375\n",
      "epoch: 4, time: 111.400s, loss: 1.499, train accuracy: 0.430\n",
      "epoch: 4, time: 112.647s, loss: 1.381, train accuracy: 0.500\n",
      "epoch: 4, time: 113.892s, loss: 1.332, train accuracy: 0.547\n",
      "epoch: 4, time: 115.128s, loss: 1.438, train accuracy: 0.453\n",
      "epoch: 4, time: 116.365s, loss: 1.411, train accuracy: 0.469\n",
      "epoch: 4, time: 117.598s, loss: 1.269, train accuracy: 0.555\n",
      "epoch: 4, time: 118.830s, loss: 1.317, train accuracy: 0.492\n",
      "epoch: 4, time: 120.096s, loss: 1.448, train accuracy: 0.406\n",
      "epoch: 4, time: 121.333s, loss: 1.343, train accuracy: 0.477\n",
      "epoch: 4, time: 122.573s, loss: 1.420, train accuracy: 0.516\n",
      "epoch: 4, time: 123.812s, loss: 1.461, train accuracy: 0.461\n",
      "epoch: 4, time: 125.049s, loss: 1.334, train accuracy: 0.539\n",
      "epoch: 4, time: 126.299s, loss: 1.364, train accuracy: 0.523\n",
      "epoch: 4, time: 127.550s, loss: 1.274, train accuracy: 0.539\n",
      "epoch: 4, time: 128.813s, loss: 1.394, train accuracy: 0.547\n",
      "epoch: 4, time: 130.056s, loss: 1.369, train accuracy: 0.531\n",
      "epoch: 4, time: 131.292s, loss: 1.314, train accuracy: 0.477\n",
      "epoch: 4, time: 132.525s, loss: 1.272, train accuracy: 0.562\n",
      "epoch: 4, time: 133.765s, loss: 1.351, train accuracy: 0.562\n",
      "Accuracy on the test set: 0.559\n",
      "epoch: 5, time: 136.649s, loss: 1.346, train accuracy: 0.523\n",
      "epoch: 5, time: 137.897s, loss: 1.236, train accuracy: 0.578\n",
      "epoch: 5, time: 139.155s, loss: 1.361, train accuracy: 0.500\n",
      "epoch: 5, time: 140.429s, loss: 1.312, train accuracy: 0.461\n",
      "epoch: 5, time: 141.663s, loss: 1.415, train accuracy: 0.523\n",
      "epoch: 5, time: 142.946s, loss: 1.437, train accuracy: 0.500\n",
      "epoch: 5, time: 144.192s, loss: 1.225, train accuracy: 0.523\n",
      "epoch: 5, time: 145.435s, loss: 1.117, train accuracy: 0.594\n",
      "epoch: 5, time: 146.674s, loss: 1.202, train accuracy: 0.578\n",
      "epoch: 5, time: 147.914s, loss: 1.191, train accuracy: 0.562\n",
      "epoch: 5, time: 149.145s, loss: 1.232, train accuracy: 0.539\n",
      "epoch: 5, time: 150.409s, loss: 1.316, train accuracy: 0.531\n",
      "epoch: 5, time: 151.651s, loss: 1.311, train accuracy: 0.555\n",
      "epoch: 5, time: 152.894s, loss: 1.103, train accuracy: 0.633\n",
      "epoch: 5, time: 154.153s, loss: 1.343, train accuracy: 0.531\n",
      "epoch: 5, time: 155.393s, loss: 1.282, train accuracy: 0.555\n",
      "epoch: 5, time: 156.637s, loss: 1.333, train accuracy: 0.516\n",
      "epoch: 5, time: 157.876s, loss: 1.206, train accuracy: 0.555\n",
      "epoch: 5, time: 159.120s, loss: 1.192, train accuracy: 0.625\n",
      "epoch: 5, time: 160.356s, loss: 1.031, train accuracy: 0.617\n",
      "Accuracy on the test set: 0.570\n",
      "epoch: 6, time: 163.249s, loss: 1.189, train accuracy: 0.586\n",
      "epoch: 6, time: 164.515s, loss: 1.315, train accuracy: 0.547\n",
      "epoch: 6, time: 165.752s, loss: 1.233, train accuracy: 0.570\n",
      "epoch: 6, time: 166.995s, loss: 1.090, train accuracy: 0.602\n",
      "epoch: 6, time: 168.275s, loss: 1.379, train accuracy: 0.523\n",
      "epoch: 6, time: 169.560s, loss: 1.258, train accuracy: 0.555\n",
      "epoch: 6, time: 170.822s, loss: 1.148, train accuracy: 0.562\n",
      "epoch: 6, time: 172.066s, loss: 1.041, train accuracy: 0.680\n",
      "epoch: 6, time: 173.308s, loss: 1.307, train accuracy: 0.516\n",
      "epoch: 6, time: 174.551s, loss: 1.203, train accuracy: 0.578\n",
      "epoch: 6, time: 175.791s, loss: 1.155, train accuracy: 0.570\n",
      "epoch: 6, time: 177.037s, loss: 1.126, train accuracy: 0.555\n",
      "epoch: 6, time: 178.294s, loss: 1.165, train accuracy: 0.609\n",
      "epoch: 6, time: 179.534s, loss: 1.203, train accuracy: 0.578\n",
      "epoch: 6, time: 180.779s, loss: 1.261, train accuracy: 0.609\n",
      "epoch: 6, time: 182.029s, loss: 1.094, train accuracy: 0.602\n",
      "epoch: 6, time: 183.275s, loss: 1.162, train accuracy: 0.539\n",
      "epoch: 6, time: 184.540s, loss: 1.164, train accuracy: 0.555\n",
      "epoch: 6, time: 185.828s, loss: 1.170, train accuracy: 0.641\n",
      "epoch: 6, time: 187.235s, loss: 1.235, train accuracy: 0.594\n",
      "Accuracy on the test set: 0.601\n",
      "epoch: 7, time: 190.058s, loss: 1.200, train accuracy: 0.609\n",
      "epoch: 7, time: 191.317s, loss: 1.223, train accuracy: 0.555\n",
      "epoch: 7, time: 192.564s, loss: 1.365, train accuracy: 0.547\n",
      "epoch: 7, time: 193.799s, loss: 1.105, train accuracy: 0.594\n",
      "epoch: 7, time: 195.047s, loss: 1.063, train accuracy: 0.586\n",
      "epoch: 7, time: 196.289s, loss: 1.151, train accuracy: 0.609\n",
      "epoch: 7, time: 197.546s, loss: 1.094, train accuracy: 0.570\n",
      "epoch: 7, time: 198.789s, loss: 1.210, train accuracy: 0.562\n",
      "epoch: 7, time: 200.039s, loss: 1.197, train accuracy: 0.516\n",
      "epoch: 7, time: 201.299s, loss: 1.183, train accuracy: 0.586\n",
      "epoch: 7, time: 202.570s, loss: 1.060, train accuracy: 0.641\n",
      "epoch: 7, time: 203.809s, loss: 1.127, train accuracy: 0.602\n",
      "epoch: 7, time: 205.053s, loss: 1.102, train accuracy: 0.609\n",
      "epoch: 7, time: 206.292s, loss: 1.139, train accuracy: 0.594\n",
      "epoch: 7, time: 207.530s, loss: 1.014, train accuracy: 0.648\n",
      "epoch: 7, time: 208.768s, loss: 1.287, train accuracy: 0.516\n",
      "epoch: 7, time: 210.007s, loss: 1.255, train accuracy: 0.586\n",
      "epoch: 7, time: 211.266s, loss: 1.033, train accuracy: 0.641\n",
      "epoch: 7, time: 212.517s, loss: 0.995, train accuracy: 0.648\n",
      "epoch: 7, time: 213.751s, loss: 1.120, train accuracy: 0.602\n",
      "Accuracy on the test set: 0.630\n",
      "epoch: 8, time: 216.662s, loss: 0.927, train accuracy: 0.703\n",
      "epoch: 8, time: 217.908s, loss: 1.219, train accuracy: 0.578\n",
      "epoch: 8, time: 219.148s, loss: 1.083, train accuracy: 0.578\n",
      "epoch: 8, time: 220.394s, loss: 1.034, train accuracy: 0.625\n",
      "epoch: 8, time: 221.631s, loss: 1.065, train accuracy: 0.586\n",
      "epoch: 8, time: 222.870s, loss: 1.051, train accuracy: 0.656\n",
      "epoch: 8, time: 224.111s, loss: 1.108, train accuracy: 0.594\n",
      "epoch: 8, time: 225.360s, loss: 1.235, train accuracy: 0.609\n",
      "epoch: 8, time: 226.599s, loss: 0.990, train accuracy: 0.656\n",
      "epoch: 8, time: 227.846s, loss: 1.157, train accuracy: 0.562\n",
      "epoch: 8, time: 229.089s, loss: 0.818, train accuracy: 0.711\n",
      "epoch: 8, time: 230.359s, loss: 1.051, train accuracy: 0.664\n",
      "epoch: 8, time: 231.597s, loss: 1.064, train accuracy: 0.602\n",
      "epoch: 8, time: 232.842s, loss: 0.956, train accuracy: 0.703\n",
      "epoch: 8, time: 234.085s, loss: 0.972, train accuracy: 0.680\n",
      "epoch: 8, time: 235.326s, loss: 0.946, train accuracy: 0.688\n",
      "epoch: 8, time: 236.564s, loss: 1.112, train accuracy: 0.641\n",
      "epoch: 8, time: 237.809s, loss: 1.076, train accuracy: 0.641\n",
      "epoch: 8, time: 239.046s, loss: 1.078, train accuracy: 0.617\n",
      "epoch: 8, time: 240.285s, loss: 1.083, train accuracy: 0.641\n",
      "Accuracy on the test set: 0.647\n",
      "epoch: 9, time: 243.179s, loss: 1.055, train accuracy: 0.609\n",
      "epoch: 9, time: 244.454s, loss: 0.940, train accuracy: 0.633\n",
      "epoch: 9, time: 245.730s, loss: 0.993, train accuracy: 0.641\n",
      "epoch: 9, time: 247.038s, loss: 1.192, train accuracy: 0.578\n",
      "epoch: 9, time: 248.321s, loss: 0.847, train accuracy: 0.703\n",
      "epoch: 9, time: 249.608s, loss: 0.977, train accuracy: 0.648\n",
      "epoch: 9, time: 250.944s, loss: 1.114, train accuracy: 0.594\n",
      "epoch: 9, time: 252.195s, loss: 1.096, train accuracy: 0.594\n",
      "epoch: 9, time: 253.442s, loss: 0.984, train accuracy: 0.625\n",
      "epoch: 9, time: 254.681s, loss: 1.128, train accuracy: 0.594\n",
      "epoch: 9, time: 255.943s, loss: 1.052, train accuracy: 0.609\n",
      "epoch: 9, time: 257.184s, loss: 0.919, train accuracy: 0.664\n",
      "epoch: 9, time: 258.421s, loss: 0.899, train accuracy: 0.688\n",
      "epoch: 9, time: 259.706s, loss: 1.095, train accuracy: 0.641\n",
      "epoch: 9, time: 260.963s, loss: 0.967, train accuracy: 0.672\n",
      "epoch: 9, time: 262.203s, loss: 0.904, train accuracy: 0.750\n",
      "epoch: 9, time: 263.447s, loss: 1.113, train accuracy: 0.586\n",
      "epoch: 9, time: 264.694s, loss: 1.016, train accuracy: 0.695\n",
      "epoch: 9, time: 265.954s, loss: 1.054, train accuracy: 0.617\n",
      "epoch: 9, time: 267.193s, loss: 0.995, train accuracy: 0.656\n",
      "Accuracy on the test set: 0.663\n",
      "epoch: 10, time: 270.052s, loss: 0.985, train accuracy: 0.625\n",
      "epoch: 10, time: 271.300s, loss: 0.901, train accuracy: 0.680\n",
      "epoch: 10, time: 272.554s, loss: 1.075, train accuracy: 0.656\n",
      "epoch: 10, time: 273.799s, loss: 0.940, train accuracy: 0.641\n",
      "epoch: 10, time: 275.032s, loss: 1.013, train accuracy: 0.656\n",
      "epoch: 10, time: 276.307s, loss: 1.122, train accuracy: 0.578\n",
      "epoch: 10, time: 277.543s, loss: 0.988, train accuracy: 0.641\n",
      "epoch: 10, time: 278.810s, loss: 1.140, train accuracy: 0.578\n",
      "epoch: 10, time: 280.057s, loss: 0.961, train accuracy: 0.648\n",
      "epoch: 10, time: 281.311s, loss: 1.009, train accuracy: 0.688\n",
      "epoch: 10, time: 282.551s, loss: 0.994, train accuracy: 0.672\n",
      "epoch: 10, time: 283.793s, loss: 0.886, train accuracy: 0.727\n",
      "epoch: 10, time: 285.039s, loss: 0.991, train accuracy: 0.664\n",
      "epoch: 10, time: 286.280s, loss: 0.936, train accuracy: 0.688\n",
      "epoch: 10, time: 287.521s, loss: 0.860, train accuracy: 0.695\n",
      "epoch: 10, time: 288.757s, loss: 1.020, train accuracy: 0.648\n",
      "epoch: 10, time: 290.011s, loss: 1.092, train accuracy: 0.633\n",
      "epoch: 10, time: 291.249s, loss: 0.958, train accuracy: 0.648\n",
      "epoch: 10, time: 292.493s, loss: 0.922, train accuracy: 0.641\n",
      "epoch: 10, time: 293.730s, loss: 0.987, train accuracy: 0.625\n",
      "Accuracy on the test set: 0.686\n",
      "epoch: 11, time: 296.630s, loss: 0.964, train accuracy: 0.680\n",
      "epoch: 11, time: 297.892s, loss: 0.768, train accuracy: 0.742\n",
      "epoch: 11, time: 299.139s, loss: 0.939, train accuracy: 0.688\n",
      "epoch: 11, time: 300.387s, loss: 1.020, train accuracy: 0.680\n",
      "epoch: 11, time: 301.672s, loss: 1.034, train accuracy: 0.594\n",
      "epoch: 11, time: 302.918s, loss: 0.927, train accuracy: 0.711\n",
      "epoch: 11, time: 304.160s, loss: 0.977, train accuracy: 0.625\n",
      "epoch: 11, time: 305.398s, loss: 0.936, train accuracy: 0.641\n",
      "epoch: 11, time: 306.823s, loss: 0.930, train accuracy: 0.672\n",
      "epoch: 11, time: 308.127s, loss: 0.923, train accuracy: 0.711\n",
      "epoch: 11, time: 309.378s, loss: 0.839, train accuracy: 0.703\n",
      "epoch: 11, time: 310.629s, loss: 0.807, train accuracy: 0.727\n",
      "epoch: 11, time: 311.867s, loss: 1.014, train accuracy: 0.664\n",
      "epoch: 11, time: 313.129s, loss: 0.869, train accuracy: 0.688\n",
      "epoch: 11, time: 314.364s, loss: 1.060, train accuracy: 0.641\n",
      "epoch: 11, time: 315.662s, loss: 0.919, train accuracy: 0.664\n",
      "epoch: 11, time: 316.907s, loss: 0.841, train accuracy: 0.695\n",
      "epoch: 11, time: 318.146s, loss: 0.903, train accuracy: 0.672\n",
      "epoch: 11, time: 319.385s, loss: 0.969, train accuracy: 0.609\n",
      "epoch: 11, time: 320.628s, loss: 0.879, train accuracy: 0.680\n",
      "Accuracy on the test set: 0.700\n",
      "epoch: 12, time: 323.468s, loss: 0.840, train accuracy: 0.664\n",
      "epoch: 12, time: 324.725s, loss: 0.858, train accuracy: 0.727\n",
      "epoch: 12, time: 325.983s, loss: 0.930, train accuracy: 0.617\n",
      "epoch: 12, time: 327.219s, loss: 0.886, train accuracy: 0.703\n",
      "epoch: 12, time: 328.475s, loss: 0.992, train accuracy: 0.656\n",
      "epoch: 12, time: 329.736s, loss: 0.780, train accuracy: 0.711\n",
      "epoch: 12, time: 330.985s, loss: 0.873, train accuracy: 0.688\n",
      "epoch: 12, time: 332.219s, loss: 0.929, train accuracy: 0.641\n",
      "epoch: 12, time: 333.464s, loss: 0.795, train accuracy: 0.703\n",
      "epoch: 12, time: 334.714s, loss: 1.088, train accuracy: 0.617\n",
      "epoch: 12, time: 335.958s, loss: 0.900, train accuracy: 0.656\n",
      "epoch: 12, time: 337.215s, loss: 0.814, train accuracy: 0.695\n",
      "epoch: 12, time: 338.461s, loss: 0.969, train accuracy: 0.625\n",
      "epoch: 12, time: 339.774s, loss: 0.813, train accuracy: 0.688\n",
      "epoch: 12, time: 341.076s, loss: 0.727, train accuracy: 0.773\n",
      "epoch: 12, time: 342.341s, loss: 0.907, train accuracy: 0.734\n",
      "epoch: 12, time: 343.605s, loss: 1.121, train accuracy: 0.625\n",
      "epoch: 12, time: 344.864s, loss: 1.145, train accuracy: 0.609\n",
      "epoch: 12, time: 346.110s, loss: 1.001, train accuracy: 0.633\n",
      "epoch: 12, time: 347.348s, loss: 1.083, train accuracy: 0.625\n",
      "Accuracy on the test set: 0.707\n",
      "epoch: 13, time: 350.218s, loss: 0.727, train accuracy: 0.750\n",
      "epoch: 13, time: 351.475s, loss: 0.898, train accuracy: 0.672\n",
      "epoch: 13, time: 352.719s, loss: 1.019, train accuracy: 0.641\n",
      "epoch: 13, time: 353.996s, loss: 0.778, train accuracy: 0.734\n",
      "epoch: 13, time: 355.231s, loss: 0.844, train accuracy: 0.719\n",
      "epoch: 13, time: 356.482s, loss: 0.645, train accuracy: 0.773\n",
      "epoch: 13, time: 357.719s, loss: 0.885, train accuracy: 0.727\n",
      "epoch: 13, time: 358.959s, loss: 0.878, train accuracy: 0.711\n",
      "epoch: 13, time: 360.195s, loss: 0.756, train accuracy: 0.789\n",
      "epoch: 13, time: 361.449s, loss: 1.018, train accuracy: 0.656\n",
      "epoch: 13, time: 362.697s, loss: 0.712, train accuracy: 0.766\n",
      "epoch: 13, time: 363.929s, loss: 0.948, train accuracy: 0.688\n",
      "epoch: 13, time: 365.183s, loss: 0.833, train accuracy: 0.734\n",
      "epoch: 13, time: 366.423s, loss: 0.875, train accuracy: 0.688\n",
      "epoch: 13, time: 367.659s, loss: 0.879, train accuracy: 0.703\n",
      "epoch: 13, time: 368.894s, loss: 0.941, train accuracy: 0.695\n",
      "epoch: 13, time: 370.145s, loss: 0.823, train accuracy: 0.719\n",
      "epoch: 13, time: 371.409s, loss: 0.950, train accuracy: 0.711\n",
      "epoch: 13, time: 372.643s, loss: 0.767, train accuracy: 0.727\n",
      "epoch: 13, time: 373.885s, loss: 0.812, train accuracy: 0.727\n",
      "Accuracy on the test set: 0.710\n",
      "epoch: 14, time: 376.793s, loss: 0.870, train accuracy: 0.703\n",
      "epoch: 14, time: 378.062s, loss: 0.836, train accuracy: 0.727\n",
      "epoch: 14, time: 379.311s, loss: 0.898, train accuracy: 0.688\n",
      "epoch: 14, time: 380.546s, loss: 0.765, train accuracy: 0.750\n",
      "epoch: 14, time: 381.790s, loss: 0.830, train accuracy: 0.734\n",
      "epoch: 14, time: 383.030s, loss: 0.835, train accuracy: 0.711\n",
      "epoch: 14, time: 384.294s, loss: 0.670, train accuracy: 0.789\n",
      "epoch: 14, time: 385.544s, loss: 0.856, train accuracy: 0.711\n",
      "epoch: 14, time: 386.783s, loss: 0.825, train accuracy: 0.703\n",
      "epoch: 14, time: 388.018s, loss: 0.798, train accuracy: 0.695\n",
      "epoch: 14, time: 389.289s, loss: 0.913, train accuracy: 0.695\n",
      "epoch: 14, time: 390.545s, loss: 0.850, train accuracy: 0.695\n",
      "epoch: 14, time: 391.786s, loss: 0.925, train accuracy: 0.641\n",
      "epoch: 14, time: 393.030s, loss: 0.879, train accuracy: 0.672\n",
      "epoch: 14, time: 394.282s, loss: 0.972, train accuracy: 0.664\n",
      "epoch: 14, time: 395.556s, loss: 0.813, train accuracy: 0.711\n",
      "epoch: 14, time: 396.789s, loss: 0.962, train accuracy: 0.656\n",
      "epoch: 14, time: 398.022s, loss: 0.860, train accuracy: 0.680\n",
      "epoch: 14, time: 399.278s, loss: 0.714, train accuracy: 0.789\n",
      "epoch: 14, time: 400.513s, loss: 0.726, train accuracy: 0.750\n",
      "Accuracy on the test set: 0.726\n",
      "epoch: 15, time: 403.388s, loss: 0.733, train accuracy: 0.727\n",
      "epoch: 15, time: 404.649s, loss: 1.037, train accuracy: 0.602\n",
      "epoch: 15, time: 405.896s, loss: 0.742, train accuracy: 0.727\n",
      "epoch: 15, time: 407.136s, loss: 0.839, train accuracy: 0.734\n",
      "epoch: 15, time: 408.411s, loss: 0.720, train accuracy: 0.742\n",
      "epoch: 15, time: 409.651s, loss: 0.774, train accuracy: 0.750\n",
      "epoch: 15, time: 410.953s, loss: 0.756, train accuracy: 0.711\n",
      "epoch: 15, time: 412.251s, loss: 0.777, train accuracy: 0.719\n",
      "epoch: 15, time: 413.498s, loss: 0.804, train accuracy: 0.672\n",
      "epoch: 15, time: 414.736s, loss: 0.754, train accuracy: 0.703\n",
      "epoch: 15, time: 415.978s, loss: 0.825, train accuracy: 0.688\n",
      "epoch: 15, time: 417.219s, loss: 0.941, train accuracy: 0.703\n",
      "epoch: 15, time: 418.480s, loss: 0.696, train accuracy: 0.766\n",
      "epoch: 15, time: 419.716s, loss: 0.893, train accuracy: 0.688\n",
      "epoch: 15, time: 420.955s, loss: 0.903, train accuracy: 0.672\n",
      "epoch: 15, time: 422.204s, loss: 0.890, train accuracy: 0.727\n",
      "epoch: 15, time: 423.447s, loss: 0.680, train accuracy: 0.750\n",
      "epoch: 15, time: 424.692s, loss: 0.830, train accuracy: 0.711\n",
      "epoch: 15, time: 426.000s, loss: 0.949, train accuracy: 0.609\n",
      "epoch: 15, time: 427.432s, loss: 0.820, train accuracy: 0.680\n",
      "Accuracy on the test set: 0.732\n",
      "epoch: 16, time: 430.181s, loss: 0.577, train accuracy: 0.828\n",
      "epoch: 16, time: 431.525s, loss: 0.940, train accuracy: 0.656\n",
      "epoch: 16, time: 432.803s, loss: 0.770, train accuracy: 0.781\n",
      "epoch: 16, time: 434.107s, loss: 0.683, train accuracy: 0.758\n",
      "epoch: 16, time: 435.377s, loss: 1.000, train accuracy: 0.648\n",
      "epoch: 16, time: 436.620s, loss: 0.853, train accuracy: 0.680\n",
      "epoch: 16, time: 437.880s, loss: 0.774, train accuracy: 0.758\n",
      "epoch: 16, time: 439.176s, loss: 0.867, train accuracy: 0.719\n",
      "epoch: 16, time: 440.433s, loss: 0.685, train accuracy: 0.781\n",
      "epoch: 16, time: 441.671s, loss: 0.678, train accuracy: 0.781\n",
      "epoch: 16, time: 442.907s, loss: 0.650, train accuracy: 0.789\n",
      "epoch: 16, time: 444.148s, loss: 0.851, train accuracy: 0.680\n",
      "epoch: 16, time: 445.440s, loss: 0.740, train accuracy: 0.703\n",
      "epoch: 16, time: 446.681s, loss: 0.718, train accuracy: 0.750\n",
      "epoch: 16, time: 447.928s, loss: 0.765, train accuracy: 0.742\n",
      "epoch: 16, time: 449.173s, loss: 0.968, train accuracy: 0.664\n",
      "epoch: 16, time: 450.413s, loss: 0.845, train accuracy: 0.656\n",
      "epoch: 16, time: 451.672s, loss: 0.789, train accuracy: 0.719\n",
      "epoch: 16, time: 452.913s, loss: 0.824, train accuracy: 0.672\n",
      "epoch: 16, time: 454.150s, loss: 0.799, train accuracy: 0.727\n",
      "Accuracy on the test set: 0.741\n",
      "epoch: 17, time: 456.944s, loss: 0.685, train accuracy: 0.781\n",
      "epoch: 17, time: 458.205s, loss: 0.823, train accuracy: 0.750\n",
      "epoch: 17, time: 459.439s, loss: 0.867, train accuracy: 0.695\n",
      "epoch: 17, time: 460.679s, loss: 0.742, train accuracy: 0.766\n",
      "epoch: 17, time: 461.922s, loss: 0.940, train accuracy: 0.680\n",
      "epoch: 17, time: 463.181s, loss: 0.770, train accuracy: 0.742\n",
      "epoch: 17, time: 464.430s, loss: 0.859, train accuracy: 0.695\n",
      "epoch: 17, time: 465.685s, loss: 1.035, train accuracy: 0.648\n",
      "epoch: 17, time: 466.926s, loss: 0.797, train accuracy: 0.719\n",
      "epoch: 17, time: 468.170s, loss: 0.760, train accuracy: 0.789\n",
      "epoch: 17, time: 469.415s, loss: 0.781, train accuracy: 0.703\n",
      "epoch: 17, time: 470.664s, loss: 0.857, train accuracy: 0.688\n",
      "epoch: 17, time: 471.912s, loss: 0.800, train accuracy: 0.773\n",
      "epoch: 17, time: 473.146s, loss: 0.742, train accuracy: 0.742\n",
      "epoch: 17, time: 474.386s, loss: 0.839, train accuracy: 0.719\n",
      "epoch: 17, time: 475.633s, loss: 0.593, train accuracy: 0.812\n",
      "epoch: 17, time: 476.886s, loss: 0.815, train accuracy: 0.695\n",
      "epoch: 17, time: 478.124s, loss: 0.905, train accuracy: 0.656\n",
      "epoch: 17, time: 479.361s, loss: 0.640, train accuracy: 0.797\n",
      "epoch: 17, time: 480.605s, loss: 0.851, train accuracy: 0.695\n",
      "Accuracy on the test set: 0.731\n",
      "epoch: 18, time: 483.391s, loss: 0.745, train accuracy: 0.695\n",
      "epoch: 18, time: 484.645s, loss: 0.734, train accuracy: 0.727\n",
      "epoch: 18, time: 485.895s, loss: 0.610, train accuracy: 0.836\n",
      "epoch: 18, time: 487.134s, loss: 0.664, train accuracy: 0.820\n",
      "epoch: 18, time: 488.376s, loss: 0.784, train accuracy: 0.742\n",
      "epoch: 18, time: 489.654s, loss: 0.695, train accuracy: 0.758\n",
      "epoch: 18, time: 490.910s, loss: 0.685, train accuracy: 0.758\n",
      "epoch: 18, time: 492.151s, loss: 0.858, train accuracy: 0.734\n",
      "epoch: 18, time: 493.410s, loss: 0.692, train accuracy: 0.734\n",
      "epoch: 18, time: 494.647s, loss: 0.716, train accuracy: 0.703\n",
      "epoch: 18, time: 495.889s, loss: 0.660, train accuracy: 0.773\n",
      "epoch: 18, time: 497.131s, loss: 0.878, train accuracy: 0.727\n",
      "epoch: 18, time: 498.414s, loss: 0.839, train accuracy: 0.734\n",
      "epoch: 18, time: 499.651s, loss: 0.486, train accuracy: 0.828\n",
      "epoch: 18, time: 500.910s, loss: 0.788, train accuracy: 0.734\n",
      "epoch: 18, time: 502.165s, loss: 0.816, train accuracy: 0.711\n",
      "epoch: 18, time: 503.403s, loss: 0.743, train accuracy: 0.789\n",
      "epoch: 18, time: 504.653s, loss: 0.779, train accuracy: 0.727\n",
      "epoch: 18, time: 505.908s, loss: 0.778, train accuracy: 0.758\n",
      "epoch: 18, time: 507.150s, loss: 0.914, train accuracy: 0.672\n",
      "Accuracy on the test set: 0.750\n",
      "epoch: 19, time: 509.999s, loss: 0.774, train accuracy: 0.750\n",
      "epoch: 19, time: 511.249s, loss: 0.599, train accuracy: 0.781\n",
      "epoch: 19, time: 512.504s, loss: 0.907, train accuracy: 0.711\n",
      "epoch: 19, time: 513.748s, loss: 0.764, train accuracy: 0.766\n",
      "epoch: 19, time: 514.991s, loss: 0.835, train accuracy: 0.742\n",
      "epoch: 19, time: 516.240s, loss: 0.779, train accuracy: 0.672\n",
      "epoch: 19, time: 517.480s, loss: 0.848, train accuracy: 0.719\n",
      "epoch: 19, time: 518.721s, loss: 0.792, train accuracy: 0.734\n",
      "epoch: 19, time: 519.969s, loss: 0.724, train accuracy: 0.727\n",
      "epoch: 19, time: 521.211s, loss: 0.708, train accuracy: 0.750\n",
      "epoch: 19, time: 522.465s, loss: 0.786, train accuracy: 0.727\n",
      "epoch: 19, time: 523.707s, loss: 0.792, train accuracy: 0.719\n",
      "epoch: 19, time: 524.970s, loss: 0.752, train accuracy: 0.742\n",
      "epoch: 19, time: 526.223s, loss: 0.764, train accuracy: 0.734\n",
      "epoch: 19, time: 527.487s, loss: 0.563, train accuracy: 0.844\n",
      "epoch: 19, time: 528.737s, loss: 0.865, train accuracy: 0.680\n",
      "epoch: 19, time: 529.982s, loss: 0.717, train accuracy: 0.773\n",
      "epoch: 19, time: 531.231s, loss: 0.776, train accuracy: 0.742\n",
      "epoch: 19, time: 532.471s, loss: 0.719, train accuracy: 0.727\n",
      "epoch: 19, time: 533.712s, loss: 0.660, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.756\n",
      "epoch: 20, time: 536.585s, loss: 0.825, train accuracy: 0.734\n",
      "epoch: 20, time: 537.839s, loss: 1.022, train accuracy: 0.695\n",
      "epoch: 20, time: 539.099s, loss: 0.742, train accuracy: 0.742\n",
      "epoch: 20, time: 540.328s, loss: 0.719, train accuracy: 0.766\n",
      "epoch: 20, time: 541.562s, loss: 0.838, train accuracy: 0.703\n",
      "epoch: 20, time: 542.811s, loss: 0.507, train accuracy: 0.852\n",
      "epoch: 20, time: 544.048s, loss: 0.605, train accuracy: 0.797\n",
      "epoch: 20, time: 545.311s, loss: 0.645, train accuracy: 0.781\n",
      "epoch: 20, time: 546.692s, loss: 0.656, train accuracy: 0.781\n",
      "epoch: 20, time: 548.007s, loss: 0.709, train accuracy: 0.734\n",
      "epoch: 20, time: 549.290s, loss: 0.763, train accuracy: 0.703\n",
      "epoch: 20, time: 550.543s, loss: 0.543, train accuracy: 0.773\n",
      "epoch: 20, time: 551.802s, loss: 0.593, train accuracy: 0.820\n",
      "epoch: 20, time: 553.050s, loss: 0.642, train accuracy: 0.773\n",
      "epoch: 20, time: 554.301s, loss: 0.536, train accuracy: 0.812\n",
      "epoch: 20, time: 555.551s, loss: 0.790, train accuracy: 0.719\n",
      "epoch: 20, time: 556.792s, loss: 0.579, train accuracy: 0.812\n",
      "epoch: 20, time: 558.038s, loss: 0.825, train accuracy: 0.664\n",
      "epoch: 20, time: 559.296s, loss: 0.843, train accuracy: 0.695\n",
      "epoch: 20, time: 560.550s, loss: 0.858, train accuracy: 0.734\n",
      "Accuracy on the test set: 0.758\n",
      "epoch: 21, time: 563.526s, loss: 0.835, train accuracy: 0.727\n",
      "epoch: 21, time: 564.821s, loss: 0.809, train accuracy: 0.797\n",
      "epoch: 21, time: 566.072s, loss: 0.785, train accuracy: 0.734\n",
      "epoch: 21, time: 567.318s, loss: 0.694, train accuracy: 0.766\n",
      "epoch: 21, time: 568.566s, loss: 0.710, train accuracy: 0.766\n",
      "epoch: 21, time: 569.823s, loss: 0.639, train accuracy: 0.758\n",
      "epoch: 21, time: 571.075s, loss: 0.743, train accuracy: 0.773\n",
      "epoch: 21, time: 572.326s, loss: 0.760, train accuracy: 0.719\n",
      "epoch: 21, time: 573.579s, loss: 0.904, train accuracy: 0.703\n",
      "epoch: 21, time: 574.828s, loss: 0.631, train accuracy: 0.742\n",
      "epoch: 21, time: 576.110s, loss: 0.845, train accuracy: 0.695\n",
      "epoch: 21, time: 577.402s, loss: 0.705, train accuracy: 0.805\n",
      "epoch: 21, time: 578.649s, loss: 0.625, train accuracy: 0.797\n",
      "epoch: 21, time: 579.889s, loss: 0.677, train accuracy: 0.773\n",
      "epoch: 21, time: 581.127s, loss: 0.656, train accuracy: 0.766\n",
      "epoch: 21, time: 582.374s, loss: 0.762, train accuracy: 0.719\n",
      "epoch: 21, time: 583.621s, loss: 0.940, train accuracy: 0.695\n",
      "epoch: 21, time: 584.853s, loss: 0.780, train accuracy: 0.750\n",
      "epoch: 21, time: 586.091s, loss: 0.593, train accuracy: 0.781\n",
      "epoch: 21, time: 587.350s, loss: 0.624, train accuracy: 0.805\n",
      "Accuracy on the test set: 0.758\n",
      "epoch: 22, time: 590.186s, loss: 0.677, train accuracy: 0.750\n",
      "epoch: 22, time: 591.471s, loss: 0.530, train accuracy: 0.805\n",
      "epoch: 22, time: 592.761s, loss: 0.699, train accuracy: 0.797\n",
      "epoch: 22, time: 594.135s, loss: 0.730, train accuracy: 0.766\n",
      "epoch: 22, time: 595.435s, loss: 0.581, train accuracy: 0.789\n",
      "epoch: 22, time: 596.749s, loss: 0.630, train accuracy: 0.805\n",
      "epoch: 22, time: 598.121s, loss: 0.608, train accuracy: 0.711\n",
      "epoch: 22, time: 599.417s, loss: 0.656, train accuracy: 0.727\n",
      "epoch: 22, time: 600.770s, loss: 0.815, train accuracy: 0.703\n",
      "epoch: 22, time: 602.037s, loss: 0.717, train accuracy: 0.750\n",
      "epoch: 22, time: 603.311s, loss: 0.539, train accuracy: 0.812\n",
      "epoch: 22, time: 604.588s, loss: 0.678, train accuracy: 0.797\n",
      "epoch: 22, time: 605.864s, loss: 0.704, train accuracy: 0.750\n",
      "epoch: 22, time: 607.138s, loss: 0.513, train accuracy: 0.836\n",
      "epoch: 22, time: 608.438s, loss: 0.680, train accuracy: 0.750\n",
      "epoch: 22, time: 609.704s, loss: 0.618, train accuracy: 0.844\n",
      "epoch: 22, time: 611.039s, loss: 0.667, train accuracy: 0.766\n",
      "epoch: 22, time: 612.343s, loss: 0.570, train accuracy: 0.797\n",
      "epoch: 22, time: 613.629s, loss: 0.655, train accuracy: 0.758\n",
      "epoch: 22, time: 614.915s, loss: 0.565, train accuracy: 0.820\n",
      "Accuracy on the test set: 0.760\n",
      "epoch: 23, time: 617.824s, loss: 0.767, train accuracy: 0.734\n",
      "epoch: 23, time: 619.116s, loss: 0.627, train accuracy: 0.781\n",
      "epoch: 23, time: 620.424s, loss: 0.723, train accuracy: 0.719\n",
      "epoch: 23, time: 621.686s, loss: 0.573, train accuracy: 0.797\n",
      "epoch: 23, time: 622.938s, loss: 0.702, train accuracy: 0.773\n",
      "epoch: 23, time: 624.202s, loss: 0.654, train accuracy: 0.742\n",
      "epoch: 23, time: 625.457s, loss: 0.574, train accuracy: 0.812\n",
      "epoch: 23, time: 626.733s, loss: 0.555, train accuracy: 0.805\n",
      "epoch: 23, time: 627.980s, loss: 0.629, train accuracy: 0.773\n",
      "epoch: 23, time: 629.235s, loss: 0.570, train accuracy: 0.797\n",
      "epoch: 23, time: 630.483s, loss: 0.865, train accuracy: 0.703\n",
      "epoch: 23, time: 631.740s, loss: 0.685, train accuracy: 0.773\n",
      "epoch: 23, time: 633.004s, loss: 0.717, train accuracy: 0.758\n",
      "epoch: 23, time: 634.310s, loss: 0.628, train accuracy: 0.820\n",
      "epoch: 23, time: 635.591s, loss: 0.638, train accuracy: 0.797\n",
      "epoch: 23, time: 636.898s, loss: 0.621, train accuracy: 0.789\n",
      "epoch: 23, time: 638.274s, loss: 0.493, train accuracy: 0.852\n",
      "epoch: 23, time: 639.544s, loss: 0.656, train accuracy: 0.758\n",
      "epoch: 23, time: 640.818s, loss: 0.546, train accuracy: 0.789\n",
      "epoch: 23, time: 642.154s, loss: 1.072, train accuracy: 0.641\n",
      "Accuracy on the test set: 0.761\n",
      "epoch: 24, time: 645.016s, loss: 0.722, train accuracy: 0.750\n",
      "epoch: 24, time: 646.330s, loss: 0.594, train accuracy: 0.820\n",
      "epoch: 24, time: 647.591s, loss: 0.482, train accuracy: 0.828\n",
      "epoch: 24, time: 648.849s, loss: 0.723, train accuracy: 0.758\n",
      "epoch: 24, time: 650.113s, loss: 0.681, train accuracy: 0.773\n",
      "epoch: 24, time: 651.377s, loss: 0.463, train accuracy: 0.828\n",
      "epoch: 24, time: 652.625s, loss: 0.841, train accuracy: 0.734\n",
      "epoch: 24, time: 653.879s, loss: 0.660, train accuracy: 0.711\n",
      "epoch: 24, time: 655.194s, loss: 0.720, train accuracy: 0.758\n",
      "epoch: 24, time: 656.495s, loss: 0.606, train accuracy: 0.734\n",
      "epoch: 24, time: 657.777s, loss: 0.938, train accuracy: 0.727\n",
      "epoch: 24, time: 659.096s, loss: 0.679, train accuracy: 0.797\n",
      "epoch: 24, time: 660.348s, loss: 0.498, train accuracy: 0.852\n",
      "epoch: 24, time: 661.669s, loss: 0.702, train accuracy: 0.789\n",
      "epoch: 24, time: 663.005s, loss: 0.748, train accuracy: 0.742\n",
      "epoch: 24, time: 664.317s, loss: 0.699, train accuracy: 0.734\n",
      "epoch: 24, time: 665.588s, loss: 0.646, train accuracy: 0.789\n",
      "epoch: 24, time: 667.002s, loss: 0.677, train accuracy: 0.758\n",
      "epoch: 24, time: 668.305s, loss: 0.641, train accuracy: 0.766\n",
      "epoch: 24, time: 669.567s, loss: 0.513, train accuracy: 0.781\n",
      "Accuracy on the test set: 0.784\n",
      "epoch: 25, time: 672.428s, loss: 0.669, train accuracy: 0.750\n",
      "epoch: 25, time: 673.721s, loss: 0.829, train accuracy: 0.727\n",
      "epoch: 25, time: 675.028s, loss: 0.731, train accuracy: 0.773\n",
      "epoch: 25, time: 676.386s, loss: 0.621, train accuracy: 0.789\n",
      "epoch: 25, time: 677.721s, loss: 0.633, train accuracy: 0.812\n",
      "epoch: 25, time: 679.020s, loss: 0.651, train accuracy: 0.789\n",
      "epoch: 25, time: 680.360s, loss: 0.605, train accuracy: 0.789\n",
      "epoch: 25, time: 681.604s, loss: 0.580, train accuracy: 0.844\n",
      "epoch: 25, time: 682.897s, loss: 0.528, train accuracy: 0.812\n",
      "epoch: 25, time: 684.172s, loss: 0.540, train accuracy: 0.844\n",
      "epoch: 25, time: 685.501s, loss: 0.553, train accuracy: 0.812\n",
      "epoch: 25, time: 686.838s, loss: 0.538, train accuracy: 0.758\n",
      "epoch: 25, time: 688.229s, loss: 0.603, train accuracy: 0.773\n",
      "epoch: 25, time: 689.511s, loss: 0.681, train accuracy: 0.750\n",
      "epoch: 25, time: 690.781s, loss: 0.644, train accuracy: 0.773\n",
      "epoch: 25, time: 692.065s, loss: 0.575, train accuracy: 0.797\n",
      "epoch: 25, time: 693.347s, loss: 0.712, train accuracy: 0.742\n",
      "epoch: 25, time: 694.611s, loss: 0.697, train accuracy: 0.805\n",
      "epoch: 25, time: 695.896s, loss: 0.571, train accuracy: 0.812\n",
      "epoch: 25, time: 697.218s, loss: 0.783, train accuracy: 0.711\n",
      "Accuracy on the test set: 0.786\n",
      "epoch: 26, time: 699.998s, loss: 0.492, train accuracy: 0.789\n",
      "epoch: 26, time: 701.320s, loss: 0.592, train accuracy: 0.758\n",
      "epoch: 26, time: 702.584s, loss: 0.749, train accuracy: 0.711\n",
      "epoch: 26, time: 703.872s, loss: 0.534, train accuracy: 0.805\n",
      "epoch: 26, time: 705.128s, loss: 0.697, train accuracy: 0.727\n",
      "epoch: 26, time: 706.396s, loss: 0.487, train accuracy: 0.812\n",
      "epoch: 26, time: 707.684s, loss: 0.669, train accuracy: 0.773\n",
      "epoch: 26, time: 708.964s, loss: 0.567, train accuracy: 0.812\n",
      "epoch: 26, time: 710.243s, loss: 0.651, train accuracy: 0.758\n",
      "epoch: 26, time: 711.529s, loss: 0.689, train accuracy: 0.719\n",
      "epoch: 26, time: 712.814s, loss: 0.783, train accuracy: 0.727\n",
      "epoch: 26, time: 714.144s, loss: 0.570, train accuracy: 0.789\n",
      "epoch: 26, time: 715.445s, loss: 0.556, train accuracy: 0.820\n",
      "epoch: 26, time: 716.754s, loss: 0.649, train accuracy: 0.773\n",
      "epoch: 26, time: 718.041s, loss: 0.652, train accuracy: 0.703\n",
      "epoch: 26, time: 719.364s, loss: 0.502, train accuracy: 0.828\n",
      "epoch: 26, time: 720.680s, loss: 0.698, train accuracy: 0.781\n",
      "epoch: 26, time: 721.980s, loss: 0.678, train accuracy: 0.766\n",
      "epoch: 26, time: 723.318s, loss: 0.632, train accuracy: 0.805\n",
      "epoch: 26, time: 724.623s, loss: 0.742, train accuracy: 0.680\n",
      "Accuracy on the test set: 0.780\n",
      "epoch: 27, time: 727.469s, loss: 0.727, train accuracy: 0.789\n",
      "epoch: 27, time: 728.789s, loss: 0.569, train accuracy: 0.797\n",
      "epoch: 27, time: 730.186s, loss: 0.692, train accuracy: 0.766\n",
      "epoch: 27, time: 731.578s, loss: 0.602, train accuracy: 0.812\n",
      "epoch: 27, time: 732.908s, loss: 0.734, train accuracy: 0.734\n",
      "epoch: 27, time: 734.293s, loss: 0.703, train accuracy: 0.805\n",
      "epoch: 27, time: 735.605s, loss: 0.651, train accuracy: 0.766\n",
      "epoch: 27, time: 736.873s, loss: 0.741, train accuracy: 0.727\n",
      "epoch: 27, time: 738.165s, loss: 0.606, train accuracy: 0.781\n",
      "epoch: 27, time: 739.464s, loss: 0.699, train accuracy: 0.766\n",
      "epoch: 27, time: 740.846s, loss: 0.627, train accuracy: 0.805\n",
      "epoch: 27, time: 742.205s, loss: 0.535, train accuracy: 0.812\n",
      "epoch: 27, time: 743.490s, loss: 0.676, train accuracy: 0.766\n",
      "epoch: 27, time: 744.868s, loss: 0.664, train accuracy: 0.750\n",
      "epoch: 27, time: 746.205s, loss: 0.729, train accuracy: 0.711\n",
      "epoch: 27, time: 747.512s, loss: 0.473, train accuracy: 0.828\n",
      "epoch: 27, time: 748.767s, loss: 0.644, train accuracy: 0.812\n",
      "epoch: 27, time: 750.010s, loss: 0.505, train accuracy: 0.812\n",
      "epoch: 27, time: 751.250s, loss: 0.740, train accuracy: 0.758\n",
      "epoch: 27, time: 752.486s, loss: 0.559, train accuracy: 0.844\n",
      "Accuracy on the test set: 0.788\n",
      "epoch: 28, time: 755.311s, loss: 0.604, train accuracy: 0.766\n",
      "epoch: 28, time: 756.606s, loss: 0.741, train accuracy: 0.734\n",
      "epoch: 28, time: 757.849s, loss: 0.573, train accuracy: 0.781\n",
      "epoch: 28, time: 759.104s, loss: 0.468, train accuracy: 0.859\n",
      "epoch: 28, time: 760.345s, loss: 0.475, train accuracy: 0.859\n",
      "epoch: 28, time: 761.627s, loss: 0.517, train accuracy: 0.836\n",
      "epoch: 28, time: 762.882s, loss: 0.560, train accuracy: 0.789\n",
      "epoch: 28, time: 764.130s, loss: 0.635, train accuracy: 0.758\n",
      "epoch: 28, time: 765.376s, loss: 0.657, train accuracy: 0.758\n",
      "epoch: 28, time: 766.627s, loss: 0.643, train accuracy: 0.758\n",
      "epoch: 28, time: 767.870s, loss: 0.655, train accuracy: 0.758\n",
      "epoch: 28, time: 769.117s, loss: 0.540, train accuracy: 0.781\n",
      "epoch: 28, time: 770.365s, loss: 0.701, train accuracy: 0.711\n",
      "epoch: 28, time: 771.607s, loss: 0.692, train accuracy: 0.750\n",
      "epoch: 28, time: 772.849s, loss: 0.612, train accuracy: 0.805\n",
      "epoch: 28, time: 774.094s, loss: 0.770, train accuracy: 0.719\n",
      "epoch: 28, time: 775.348s, loss: 0.581, train accuracy: 0.805\n",
      "epoch: 28, time: 776.596s, loss: 0.554, train accuracy: 0.773\n",
      "epoch: 28, time: 777.842s, loss: 0.664, train accuracy: 0.789\n",
      "epoch: 28, time: 779.085s, loss: 0.638, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.780\n",
      "epoch: 29, time: 782.011s, loss: 0.609, train accuracy: 0.750\n",
      "epoch: 29, time: 783.315s, loss: 0.539, train accuracy: 0.805\n",
      "epoch: 29, time: 784.570s, loss: 0.503, train accuracy: 0.828\n",
      "epoch: 29, time: 785.839s, loss: 0.649, train accuracy: 0.797\n",
      "epoch: 29, time: 787.207s, loss: 0.685, train accuracy: 0.742\n",
      "epoch: 29, time: 788.475s, loss: 0.485, train accuracy: 0.820\n",
      "epoch: 29, time: 789.714s, loss: 0.539, train accuracy: 0.797\n",
      "epoch: 29, time: 790.950s, loss: 0.666, train accuracy: 0.789\n",
      "epoch: 29, time: 792.201s, loss: 0.616, train accuracy: 0.758\n",
      "epoch: 29, time: 793.453s, loss: 0.412, train accuracy: 0.836\n",
      "epoch: 29, time: 794.692s, loss: 0.642, train accuracy: 0.773\n",
      "epoch: 29, time: 795.930s, loss: 0.598, train accuracy: 0.773\n",
      "epoch: 29, time: 797.193s, loss: 0.665, train accuracy: 0.781\n",
      "epoch: 29, time: 798.453s, loss: 0.502, train accuracy: 0.820\n",
      "epoch: 29, time: 799.700s, loss: 0.570, train accuracy: 0.789\n",
      "epoch: 29, time: 800.955s, loss: 0.489, train accuracy: 0.836\n",
      "epoch: 29, time: 802.200s, loss: 0.557, train accuracy: 0.820\n",
      "epoch: 29, time: 803.452s, loss: 0.449, train accuracy: 0.836\n",
      "epoch: 29, time: 804.691s, loss: 0.665, train accuracy: 0.789\n",
      "epoch: 29, time: 805.928s, loss: 0.601, train accuracy: 0.758\n",
      "Accuracy on the test set: 0.789\n",
      "epoch: 30, time: 808.777s, loss: 0.546, train accuracy: 0.797\n",
      "epoch: 30, time: 810.040s, loss: 0.655, train accuracy: 0.750\n",
      "epoch: 30, time: 811.292s, loss: 0.608, train accuracy: 0.828\n",
      "epoch: 30, time: 812.530s, loss: 0.842, train accuracy: 0.711\n",
      "epoch: 30, time: 813.774s, loss: 0.595, train accuracy: 0.805\n",
      "epoch: 30, time: 815.028s, loss: 0.603, train accuracy: 0.805\n",
      "epoch: 30, time: 816.268s, loss: 0.775, train accuracy: 0.703\n",
      "epoch: 30, time: 817.510s, loss: 0.699, train accuracy: 0.750\n",
      "epoch: 30, time: 818.749s, loss: 0.587, train accuracy: 0.852\n",
      "epoch: 30, time: 819.991s, loss: 0.578, train accuracy: 0.797\n",
      "epoch: 30, time: 821.227s, loss: 0.641, train accuracy: 0.797\n",
      "epoch: 30, time: 822.467s, loss: 0.565, train accuracy: 0.812\n",
      "epoch: 30, time: 823.712s, loss: 0.637, train accuracy: 0.766\n",
      "epoch: 30, time: 824.967s, loss: 0.541, train accuracy: 0.852\n",
      "epoch: 30, time: 826.210s, loss: 0.450, train accuracy: 0.820\n",
      "epoch: 30, time: 827.448s, loss: 0.592, train accuracy: 0.758\n",
      "epoch: 30, time: 828.690s, loss: 0.775, train accuracy: 0.711\n",
      "epoch: 30, time: 829.926s, loss: 0.622, train accuracy: 0.797\n",
      "epoch: 30, time: 831.186s, loss: 0.461, train accuracy: 0.844\n",
      "epoch: 30, time: 832.451s, loss: 0.617, train accuracy: 0.805\n",
      "Accuracy on the test set: 0.784\n",
      "epoch: 31, time: 835.286s, loss: 0.428, train accuracy: 0.867\n",
      "epoch: 31, time: 836.558s, loss: 0.585, train accuracy: 0.781\n",
      "epoch: 31, time: 837.797s, loss: 0.572, train accuracy: 0.820\n",
      "epoch: 31, time: 839.034s, loss: 0.501, train accuracy: 0.828\n",
      "epoch: 31, time: 840.280s, loss: 0.516, train accuracy: 0.797\n",
      "epoch: 31, time: 841.526s, loss: 0.777, train accuracy: 0.734\n",
      "epoch: 31, time: 842.764s, loss: 0.634, train accuracy: 0.781\n",
      "epoch: 31, time: 844.004s, loss: 0.499, train accuracy: 0.852\n",
      "epoch: 31, time: 845.270s, loss: 0.500, train accuracy: 0.820\n",
      "epoch: 31, time: 846.529s, loss: 0.514, train accuracy: 0.797\n",
      "epoch: 31, time: 847.767s, loss: 0.552, train accuracy: 0.805\n",
      "epoch: 31, time: 849.026s, loss: 0.355, train accuracy: 0.891\n",
      "epoch: 31, time: 850.273s, loss: 0.803, train accuracy: 0.758\n",
      "epoch: 31, time: 851.514s, loss: 0.641, train accuracy: 0.773\n",
      "epoch: 31, time: 852.754s, loss: 0.452, train accuracy: 0.867\n",
      "epoch: 31, time: 854.006s, loss: 0.742, train accuracy: 0.703\n",
      "epoch: 31, time: 855.260s, loss: 0.444, train accuracy: 0.805\n",
      "epoch: 31, time: 856.497s, loss: 0.570, train accuracy: 0.812\n",
      "epoch: 31, time: 857.735s, loss: 0.655, train accuracy: 0.766\n",
      "epoch: 31, time: 858.982s, loss: 0.587, train accuracy: 0.781\n",
      "Accuracy on the test set: 0.792\n",
      "epoch: 32, time: 861.757s, loss: 0.536, train accuracy: 0.781\n",
      "epoch: 32, time: 863.018s, loss: 0.497, train accuracy: 0.836\n",
      "epoch: 32, time: 864.289s, loss: 0.608, train accuracy: 0.766\n",
      "epoch: 32, time: 865.537s, loss: 0.547, train accuracy: 0.812\n",
      "epoch: 32, time: 866.784s, loss: 0.608, train accuracy: 0.828\n",
      "epoch: 32, time: 868.027s, loss: 0.654, train accuracy: 0.758\n",
      "epoch: 32, time: 869.289s, loss: 0.727, train accuracy: 0.734\n",
      "epoch: 32, time: 870.533s, loss: 0.624, train accuracy: 0.773\n",
      "epoch: 32, time: 871.782s, loss: 0.418, train accuracy: 0.867\n",
      "epoch: 32, time: 873.016s, loss: 0.448, train accuracy: 0.844\n",
      "epoch: 32, time: 874.281s, loss: 0.541, train accuracy: 0.836\n",
      "epoch: 32, time: 875.524s, loss: 0.468, train accuracy: 0.805\n",
      "epoch: 32, time: 876.788s, loss: 0.529, train accuracy: 0.789\n",
      "epoch: 32, time: 878.025s, loss: 0.482, train accuracy: 0.820\n",
      "epoch: 32, time: 879.270s, loss: 0.429, train accuracy: 0.836\n",
      "epoch: 32, time: 880.499s, loss: 0.692, train accuracy: 0.781\n",
      "epoch: 32, time: 881.740s, loss: 0.566, train accuracy: 0.781\n",
      "epoch: 32, time: 882.995s, loss: 0.518, train accuracy: 0.805\n",
      "epoch: 32, time: 884.316s, loss: 0.654, train accuracy: 0.742\n",
      "epoch: 32, time: 885.561s, loss: 0.696, train accuracy: 0.711\n",
      "Accuracy on the test set: 0.801\n",
      "epoch: 33, time: 888.335s, loss: 0.597, train accuracy: 0.805\n",
      "epoch: 33, time: 889.626s, loss: 0.502, train accuracy: 0.828\n",
      "epoch: 33, time: 890.866s, loss: 0.394, train accuracy: 0.852\n",
      "epoch: 33, time: 892.105s, loss: 0.540, train accuracy: 0.836\n",
      "epoch: 33, time: 893.384s, loss: 0.530, train accuracy: 0.836\n",
      "epoch: 33, time: 894.636s, loss: 0.486, train accuracy: 0.812\n",
      "epoch: 33, time: 895.884s, loss: 0.485, train accuracy: 0.820\n",
      "epoch: 33, time: 897.127s, loss: 0.468, train accuracy: 0.859\n",
      "epoch: 33, time: 898.395s, loss: 0.542, train accuracy: 0.844\n",
      "epoch: 33, time: 899.648s, loss: 0.608, train accuracy: 0.766\n",
      "epoch: 33, time: 900.890s, loss: 0.542, train accuracy: 0.789\n",
      "epoch: 33, time: 902.130s, loss: 0.658, train accuracy: 0.766\n",
      "epoch: 33, time: 903.389s, loss: 0.496, train accuracy: 0.820\n",
      "epoch: 33, time: 904.626s, loss: 0.360, train accuracy: 0.883\n",
      "epoch: 33, time: 905.886s, loss: 0.403, train accuracy: 0.852\n",
      "epoch: 33, time: 907.297s, loss: 0.676, train accuracy: 0.773\n",
      "epoch: 33, time: 908.573s, loss: 0.557, train accuracy: 0.812\n",
      "epoch: 33, time: 909.823s, loss: 0.580, train accuracy: 0.805\n",
      "epoch: 33, time: 911.083s, loss: 0.532, train accuracy: 0.781\n",
      "epoch: 33, time: 912.347s, loss: 0.386, train accuracy: 0.867\n",
      "Accuracy on the test set: 0.792\n",
      "epoch: 34, time: 915.238s, loss: 0.461, train accuracy: 0.789\n",
      "epoch: 34, time: 916.539s, loss: 0.445, train accuracy: 0.844\n",
      "epoch: 34, time: 917.784s, loss: 0.577, train accuracy: 0.789\n",
      "epoch: 34, time: 919.033s, loss: 0.747, train accuracy: 0.758\n",
      "epoch: 34, time: 920.277s, loss: 0.523, train accuracy: 0.797\n",
      "epoch: 34, time: 921.523s, loss: 0.600, train accuracy: 0.773\n",
      "epoch: 34, time: 922.770s, loss: 0.564, train accuracy: 0.805\n",
      "epoch: 34, time: 924.012s, loss: 0.557, train accuracy: 0.797\n",
      "epoch: 34, time: 925.263s, loss: 0.534, train accuracy: 0.820\n",
      "epoch: 34, time: 926.501s, loss: 0.549, train accuracy: 0.781\n",
      "epoch: 34, time: 927.792s, loss: 0.391, train accuracy: 0.859\n",
      "epoch: 34, time: 929.031s, loss: 0.577, train accuracy: 0.820\n",
      "epoch: 34, time: 930.284s, loss: 0.394, train accuracy: 0.906\n",
      "epoch: 34, time: 931.560s, loss: 0.522, train accuracy: 0.828\n",
      "epoch: 34, time: 932.811s, loss: 0.394, train accuracy: 0.859\n",
      "epoch: 34, time: 934.057s, loss: 0.542, train accuracy: 0.812\n",
      "epoch: 34, time: 935.303s, loss: 0.545, train accuracy: 0.781\n",
      "epoch: 34, time: 936.554s, loss: 0.427, train accuracy: 0.852\n",
      "epoch: 34, time: 937.812s, loss: 0.480, train accuracy: 0.820\n",
      "epoch: 34, time: 939.050s, loss: 0.708, train accuracy: 0.742\n",
      "Accuracy on the test set: 0.801\n",
      "epoch: 35, time: 941.920s, loss: 0.446, train accuracy: 0.859\n",
      "epoch: 35, time: 943.181s, loss: 0.580, train accuracy: 0.797\n",
      "epoch: 35, time: 944.460s, loss: 0.526, train accuracy: 0.789\n",
      "epoch: 35, time: 945.714s, loss: 0.415, train accuracy: 0.867\n",
      "epoch: 35, time: 946.956s, loss: 0.511, train accuracy: 0.789\n",
      "epoch: 35, time: 948.196s, loss: 0.621, train accuracy: 0.758\n",
      "epoch: 35, time: 949.442s, loss: 0.634, train accuracy: 0.805\n",
      "epoch: 35, time: 950.684s, loss: 0.450, train accuracy: 0.828\n",
      "epoch: 35, time: 951.930s, loss: 0.644, train accuracy: 0.734\n",
      "epoch: 35, time: 953.169s, loss: 0.673, train accuracy: 0.758\n",
      "epoch: 35, time: 954.424s, loss: 0.594, train accuracy: 0.789\n",
      "epoch: 35, time: 955.662s, loss: 0.546, train accuracy: 0.812\n",
      "epoch: 35, time: 956.908s, loss: 0.622, train accuracy: 0.789\n",
      "epoch: 35, time: 958.154s, loss: 0.626, train accuracy: 0.805\n",
      "epoch: 35, time: 959.395s, loss: 0.452, train accuracy: 0.836\n",
      "epoch: 35, time: 960.637s, loss: 0.550, train accuracy: 0.812\n",
      "epoch: 35, time: 961.876s, loss: 0.538, train accuracy: 0.797\n",
      "epoch: 35, time: 963.109s, loss: 0.484, train accuracy: 0.836\n",
      "epoch: 35, time: 964.395s, loss: 0.523, train accuracy: 0.820\n",
      "epoch: 35, time: 965.636s, loss: 0.688, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.795\n",
      "epoch: 36, time: 968.527s, loss: 0.563, train accuracy: 0.773\n",
      "epoch: 36, time: 969.786s, loss: 0.389, train accuracy: 0.891\n",
      "epoch: 36, time: 971.039s, loss: 0.422, train accuracy: 0.836\n",
      "epoch: 36, time: 972.293s, loss: 0.678, train accuracy: 0.766\n",
      "epoch: 36, time: 973.558s, loss: 0.561, train accuracy: 0.797\n",
      "epoch: 36, time: 974.814s, loss: 0.566, train accuracy: 0.820\n",
      "epoch: 36, time: 976.058s, loss: 0.386, train accuracy: 0.859\n",
      "epoch: 36, time: 977.305s, loss: 0.407, train accuracy: 0.867\n",
      "epoch: 36, time: 978.556s, loss: 0.490, train accuracy: 0.867\n",
      "epoch: 36, time: 979.810s, loss: 0.530, train accuracy: 0.820\n",
      "epoch: 36, time: 981.054s, loss: 0.512, train accuracy: 0.836\n",
      "epoch: 36, time: 982.297s, loss: 0.458, train accuracy: 0.797\n",
      "epoch: 36, time: 983.538s, loss: 0.641, train accuracy: 0.781\n",
      "epoch: 36, time: 984.785s, loss: 0.457, train accuracy: 0.836\n",
      "epoch: 36, time: 986.026s, loss: 0.501, train accuracy: 0.828\n",
      "epoch: 36, time: 987.270s, loss: 0.525, train accuracy: 0.836\n",
      "epoch: 36, time: 988.573s, loss: 0.658, train accuracy: 0.758\n",
      "epoch: 36, time: 989.817s, loss: 0.642, train accuracy: 0.781\n",
      "epoch: 36, time: 991.071s, loss: 0.549, train accuracy: 0.797\n",
      "epoch: 36, time: 992.332s, loss: 0.669, train accuracy: 0.766\n",
      "Accuracy on the test set: 0.806\n",
      "epoch: 37, time: 995.191s, loss: 0.596, train accuracy: 0.812\n",
      "epoch: 37, time: 996.454s, loss: 0.469, train accuracy: 0.812\n",
      "epoch: 37, time: 997.704s, loss: 0.632, train accuracy: 0.734\n",
      "epoch: 37, time: 998.958s, loss: 0.599, train accuracy: 0.812\n",
      "epoch: 37, time: 1000.201s, loss: 0.502, train accuracy: 0.820\n",
      "epoch: 37, time: 1001.450s, loss: 0.549, train accuracy: 0.797\n",
      "epoch: 37, time: 1002.713s, loss: 0.484, train accuracy: 0.805\n",
      "epoch: 37, time: 1003.992s, loss: 0.441, train accuracy: 0.828\n",
      "epoch: 37, time: 1005.235s, loss: 0.502, train accuracy: 0.820\n",
      "epoch: 37, time: 1006.476s, loss: 0.512, train accuracy: 0.797\n",
      "epoch: 37, time: 1007.724s, loss: 0.417, train accuracy: 0.852\n",
      "epoch: 37, time: 1008.997s, loss: 0.517, train accuracy: 0.781\n",
      "epoch: 37, time: 1010.234s, loss: 0.496, train accuracy: 0.828\n",
      "epoch: 37, time: 1011.486s, loss: 0.533, train accuracy: 0.820\n",
      "epoch: 37, time: 1012.741s, loss: 0.580, train accuracy: 0.789\n",
      "epoch: 37, time: 1013.989s, loss: 0.517, train accuracy: 0.828\n",
      "epoch: 37, time: 1015.234s, loss: 0.557, train accuracy: 0.781\n",
      "epoch: 37, time: 1016.473s, loss: 0.548, train accuracy: 0.766\n",
      "epoch: 37, time: 1017.725s, loss: 0.523, train accuracy: 0.812\n",
      "epoch: 37, time: 1018.973s, loss: 0.478, train accuracy: 0.820\n",
      "Accuracy on the test set: 0.790\n",
      "epoch: 38, time: 1021.790s, loss: 0.621, train accuracy: 0.789\n",
      "epoch: 38, time: 1023.069s, loss: 0.471, train accuracy: 0.828\n",
      "epoch: 38, time: 1024.319s, loss: 0.526, train accuracy: 0.758\n",
      "epoch: 38, time: 1025.564s, loss: 0.652, train accuracy: 0.758\n",
      "epoch: 38, time: 1026.949s, loss: 0.469, train accuracy: 0.875\n",
      "epoch: 38, time: 1028.253s, loss: 0.585, train accuracy: 0.773\n",
      "epoch: 38, time: 1029.528s, loss: 0.503, train accuracy: 0.844\n",
      "epoch: 38, time: 1030.762s, loss: 0.509, train accuracy: 0.820\n",
      "epoch: 38, time: 1032.019s, loss: 0.636, train accuracy: 0.836\n",
      "epoch: 38, time: 1033.278s, loss: 0.472, train accuracy: 0.867\n",
      "epoch: 38, time: 1034.529s, loss: 0.473, train accuracy: 0.852\n",
      "epoch: 38, time: 1035.776s, loss: 0.412, train accuracy: 0.867\n",
      "epoch: 38, time: 1037.027s, loss: 0.518, train accuracy: 0.820\n",
      "epoch: 38, time: 1038.267s, loss: 0.407, train accuracy: 0.867\n",
      "epoch: 38, time: 1039.514s, loss: 0.400, train accuracy: 0.852\n",
      "epoch: 38, time: 1040.753s, loss: 0.566, train accuracy: 0.797\n",
      "epoch: 38, time: 1041.995s, loss: 0.462, train accuracy: 0.844\n",
      "epoch: 38, time: 1043.258s, loss: 0.469, train accuracy: 0.820\n",
      "epoch: 38, time: 1044.552s, loss: 0.392, train accuracy: 0.875\n",
      "epoch: 38, time: 1045.799s, loss: 0.497, train accuracy: 0.805\n",
      "Accuracy on the test set: 0.805\n",
      "epoch: 39, time: 1048.712s, loss: 0.414, train accuracy: 0.828\n",
      "epoch: 39, time: 1049.976s, loss: 0.418, train accuracy: 0.852\n",
      "epoch: 39, time: 1051.219s, loss: 0.677, train accuracy: 0.781\n",
      "epoch: 39, time: 1052.481s, loss: 0.471, train accuracy: 0.844\n",
      "epoch: 39, time: 1053.723s, loss: 0.395, train accuracy: 0.867\n",
      "epoch: 39, time: 1054.969s, loss: 0.560, train accuracy: 0.805\n",
      "epoch: 39, time: 1056.207s, loss: 0.350, train accuracy: 0.875\n",
      "epoch: 39, time: 1057.506s, loss: 0.623, train accuracy: 0.789\n",
      "epoch: 39, time: 1058.768s, loss: 0.387, train accuracy: 0.875\n",
      "epoch: 39, time: 1060.006s, loss: 0.520, train accuracy: 0.820\n",
      "epoch: 39, time: 1061.267s, loss: 0.513, train accuracy: 0.828\n",
      "epoch: 39, time: 1062.520s, loss: 0.685, train accuracy: 0.750\n",
      "epoch: 39, time: 1063.775s, loss: 0.527, train accuracy: 0.820\n",
      "epoch: 39, time: 1065.020s, loss: 0.453, train accuracy: 0.844\n",
      "epoch: 39, time: 1066.268s, loss: 0.528, train accuracy: 0.797\n",
      "epoch: 39, time: 1067.510s, loss: 0.405, train accuracy: 0.836\n",
      "epoch: 39, time: 1068.799s, loss: 0.446, train accuracy: 0.828\n",
      "epoch: 39, time: 1070.051s, loss: 0.444, train accuracy: 0.836\n",
      "epoch: 39, time: 1071.301s, loss: 0.614, train accuracy: 0.773\n",
      "epoch: 39, time: 1072.550s, loss: 0.465, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.805\n",
      "epoch: 40, time: 1075.333s, loss: 0.343, train accuracy: 0.898\n",
      "epoch: 40, time: 1076.590s, loss: 0.349, train accuracy: 0.859\n",
      "epoch: 40, time: 1077.839s, loss: 0.534, train accuracy: 0.805\n",
      "epoch: 40, time: 1079.075s, loss: 0.565, train accuracy: 0.797\n",
      "epoch: 40, time: 1080.342s, loss: 0.503, train accuracy: 0.812\n",
      "epoch: 40, time: 1081.595s, loss: 0.434, train accuracy: 0.836\n",
      "epoch: 40, time: 1082.836s, loss: 0.358, train accuracy: 0.883\n",
      "epoch: 40, time: 1084.088s, loss: 0.585, train accuracy: 0.820\n",
      "epoch: 40, time: 1085.329s, loss: 0.432, train accuracy: 0.867\n",
      "epoch: 40, time: 1086.565s, loss: 0.383, train accuracy: 0.891\n",
      "epoch: 40, time: 1087.807s, loss: 0.520, train accuracy: 0.828\n",
      "epoch: 40, time: 1089.038s, loss: 0.376, train accuracy: 0.883\n",
      "epoch: 40, time: 1090.288s, loss: 0.450, train accuracy: 0.875\n",
      "epoch: 40, time: 1091.530s, loss: 0.552, train accuracy: 0.797\n",
      "epoch: 40, time: 1092.762s, loss: 0.491, train accuracy: 0.805\n",
      "epoch: 40, time: 1094.003s, loss: 0.375, train accuracy: 0.852\n",
      "epoch: 40, time: 1095.294s, loss: 0.472, train accuracy: 0.836\n",
      "epoch: 40, time: 1096.641s, loss: 0.335, train accuracy: 0.867\n",
      "epoch: 40, time: 1097.967s, loss: 0.420, train accuracy: 0.867\n",
      "epoch: 40, time: 1099.243s, loss: 0.654, train accuracy: 0.789\n",
      "Accuracy on the test set: 0.806\n",
      "epoch: 41, time: 1102.167s, loss: 0.392, train accuracy: 0.828\n",
      "epoch: 41, time: 1103.454s, loss: 0.527, train accuracy: 0.766\n",
      "epoch: 41, time: 1104.710s, loss: 0.409, train accuracy: 0.844\n",
      "epoch: 41, time: 1105.957s, loss: 0.481, train accuracy: 0.805\n",
      "epoch: 41, time: 1107.217s, loss: 0.535, train accuracy: 0.820\n",
      "epoch: 41, time: 1108.472s, loss: 0.431, train accuracy: 0.836\n",
      "epoch: 41, time: 1109.756s, loss: 0.529, train accuracy: 0.789\n",
      "epoch: 41, time: 1111.035s, loss: 0.578, train accuracy: 0.758\n",
      "epoch: 41, time: 1112.320s, loss: 0.478, train accuracy: 0.828\n",
      "epoch: 41, time: 1113.634s, loss: 0.408, train accuracy: 0.852\n",
      "epoch: 41, time: 1114.923s, loss: 0.443, train accuracy: 0.852\n",
      "epoch: 41, time: 1116.234s, loss: 0.762, train accuracy: 0.750\n",
      "epoch: 41, time: 1117.553s, loss: 0.469, train accuracy: 0.844\n",
      "epoch: 41, time: 1118.832s, loss: 0.555, train accuracy: 0.812\n",
      "epoch: 41, time: 1120.213s, loss: 0.631, train accuracy: 0.812\n",
      "epoch: 41, time: 1121.649s, loss: 0.424, train accuracy: 0.828\n",
      "epoch: 41, time: 1122.994s, loss: 0.459, train accuracy: 0.852\n",
      "epoch: 41, time: 1124.331s, loss: 0.480, train accuracy: 0.844\n",
      "epoch: 41, time: 1125.654s, loss: 0.443, train accuracy: 0.844\n",
      "epoch: 41, time: 1127.128s, loss: 0.433, train accuracy: 0.844\n",
      "Accuracy on the test set: 0.793\n",
      "epoch: 42, time: 1129.947s, loss: 0.548, train accuracy: 0.781\n",
      "epoch: 42, time: 1131.253s, loss: 0.397, train accuracy: 0.867\n",
      "epoch: 42, time: 1132.598s, loss: 0.489, train accuracy: 0.875\n",
      "epoch: 42, time: 1133.949s, loss: 0.601, train accuracy: 0.781\n",
      "epoch: 42, time: 1135.297s, loss: 0.450, train accuracy: 0.820\n",
      "epoch: 42, time: 1136.620s, loss: 0.492, train accuracy: 0.828\n",
      "epoch: 42, time: 1137.964s, loss: 0.573, train accuracy: 0.781\n",
      "epoch: 42, time: 1139.297s, loss: 0.410, train accuracy: 0.883\n",
      "epoch: 42, time: 1140.630s, loss: 0.388, train accuracy: 0.875\n",
      "epoch: 42, time: 1142.035s, loss: 0.586, train accuracy: 0.773\n",
      "epoch: 42, time: 1143.445s, loss: 0.444, train accuracy: 0.859\n",
      "epoch: 42, time: 1144.777s, loss: 0.485, train accuracy: 0.820\n",
      "epoch: 42, time: 1146.174s, loss: 0.484, train accuracy: 0.844\n",
      "epoch: 42, time: 1147.575s, loss: 0.484, train accuracy: 0.820\n",
      "epoch: 42, time: 1148.986s, loss: 0.468, train accuracy: 0.820\n",
      "epoch: 42, time: 1150.424s, loss: 0.553, train accuracy: 0.789\n",
      "epoch: 42, time: 1151.790s, loss: 0.487, train accuracy: 0.828\n",
      "epoch: 42, time: 1153.199s, loss: 0.548, train accuracy: 0.828\n",
      "epoch: 42, time: 1154.653s, loss: 0.472, train accuracy: 0.828\n",
      "epoch: 42, time: 1156.038s, loss: 0.448, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.801\n",
      "epoch: 43, time: 1159.013s, loss: 0.534, train accuracy: 0.797\n",
      "epoch: 43, time: 1160.513s, loss: 0.528, train accuracy: 0.805\n",
      "epoch: 43, time: 1161.963s, loss: 0.339, train accuracy: 0.906\n",
      "epoch: 43, time: 1163.358s, loss: 0.345, train accuracy: 0.898\n",
      "epoch: 43, time: 1164.746s, loss: 0.576, train accuracy: 0.828\n",
      "epoch: 43, time: 1166.143s, loss: 0.425, train accuracy: 0.859\n",
      "epoch: 43, time: 1167.633s, loss: 0.585, train accuracy: 0.773\n",
      "epoch: 43, time: 1169.060s, loss: 0.552, train accuracy: 0.805\n",
      "epoch: 43, time: 1170.466s, loss: 0.342, train accuracy: 0.875\n",
      "epoch: 43, time: 1171.833s, loss: 0.427, train accuracy: 0.820\n",
      "epoch: 43, time: 1173.202s, loss: 0.500, train accuracy: 0.828\n",
      "epoch: 43, time: 1174.672s, loss: 0.475, train accuracy: 0.820\n",
      "epoch: 43, time: 1176.107s, loss: 0.467, train accuracy: 0.836\n",
      "epoch: 43, time: 1177.589s, loss: 0.453, train accuracy: 0.852\n",
      "epoch: 43, time: 1179.009s, loss: 0.510, train accuracy: 0.852\n",
      "epoch: 43, time: 1180.337s, loss: 0.514, train accuracy: 0.852\n",
      "epoch: 43, time: 1181.731s, loss: 0.533, train accuracy: 0.812\n",
      "epoch: 43, time: 1183.152s, loss: 0.531, train accuracy: 0.812\n",
      "epoch: 43, time: 1184.677s, loss: 0.373, train accuracy: 0.875\n",
      "epoch: 43, time: 1186.195s, loss: 0.363, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.816\n",
      "epoch: 44, time: 1189.227s, loss: 0.554, train accuracy: 0.797\n",
      "epoch: 44, time: 1190.622s, loss: 0.456, train accuracy: 0.852\n",
      "epoch: 44, time: 1191.942s, loss: 0.393, train accuracy: 0.844\n",
      "epoch: 44, time: 1193.278s, loss: 0.421, train accuracy: 0.836\n",
      "epoch: 44, time: 1194.720s, loss: 0.489, train accuracy: 0.836\n",
      "epoch: 44, time: 1196.177s, loss: 0.416, train accuracy: 0.883\n",
      "epoch: 44, time: 1197.621s, loss: 0.513, train accuracy: 0.836\n",
      "epoch: 44, time: 1199.125s, loss: 0.417, train accuracy: 0.820\n",
      "epoch: 44, time: 1200.540s, loss: 0.496, train accuracy: 0.859\n",
      "epoch: 44, time: 1201.918s, loss: 0.515, train accuracy: 0.812\n",
      "epoch: 44, time: 1203.328s, loss: 0.400, train accuracy: 0.852\n",
      "epoch: 44, time: 1204.794s, loss: 0.488, train accuracy: 0.812\n",
      "epoch: 44, time: 1206.167s, loss: 0.593, train accuracy: 0.766\n",
      "epoch: 44, time: 1207.623s, loss: 0.579, train accuracy: 0.789\n",
      "epoch: 44, time: 1208.987s, loss: 0.497, train accuracy: 0.852\n",
      "epoch: 44, time: 1210.397s, loss: 0.363, train accuracy: 0.875\n",
      "epoch: 44, time: 1211.853s, loss: 0.414, train accuracy: 0.852\n",
      "epoch: 44, time: 1213.285s, loss: 0.443, train accuracy: 0.820\n",
      "epoch: 44, time: 1214.698s, loss: 0.474, train accuracy: 0.867\n",
      "epoch: 44, time: 1216.132s, loss: 0.394, train accuracy: 0.867\n",
      "Accuracy on the test set: 0.821\n",
      "epoch: 45, time: 1219.149s, loss: 0.458, train accuracy: 0.852\n",
      "epoch: 45, time: 1220.578s, loss: 0.511, train accuracy: 0.820\n",
      "epoch: 45, time: 1221.942s, loss: 0.492, train accuracy: 0.812\n",
      "epoch: 45, time: 1223.292s, loss: 0.582, train accuracy: 0.828\n",
      "epoch: 45, time: 1224.659s, loss: 0.402, train accuracy: 0.875\n",
      "epoch: 45, time: 1226.015s, loss: 0.502, train accuracy: 0.828\n",
      "epoch: 45, time: 1227.361s, loss: 0.492, train accuracy: 0.844\n",
      "epoch: 45, time: 1228.684s, loss: 0.415, train accuracy: 0.820\n",
      "epoch: 45, time: 1230.029s, loss: 0.507, train accuracy: 0.812\n",
      "epoch: 45, time: 1231.380s, loss: 0.493, train accuracy: 0.836\n",
      "epoch: 45, time: 1232.701s, loss: 0.472, train accuracy: 0.820\n",
      "epoch: 45, time: 1234.028s, loss: 0.382, train accuracy: 0.852\n",
      "epoch: 45, time: 1235.328s, loss: 0.461, train accuracy: 0.812\n",
      "epoch: 45, time: 1236.638s, loss: 0.568, train accuracy: 0.758\n",
      "epoch: 45, time: 1237.924s, loss: 0.534, train accuracy: 0.797\n",
      "epoch: 45, time: 1239.329s, loss: 0.447, train accuracy: 0.875\n",
      "epoch: 45, time: 1240.641s, loss: 0.336, train accuracy: 0.883\n",
      "epoch: 45, time: 1241.952s, loss: 0.574, train accuracy: 0.789\n",
      "epoch: 45, time: 1243.276s, loss: 0.391, train accuracy: 0.875\n",
      "epoch: 45, time: 1244.579s, loss: 0.345, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.824\n",
      "epoch: 46, time: 1247.495s, loss: 0.461, train accuracy: 0.828\n",
      "epoch: 46, time: 1248.839s, loss: 0.449, train accuracy: 0.859\n",
      "epoch: 46, time: 1250.232s, loss: 0.261, train accuracy: 0.906\n",
      "epoch: 46, time: 1251.541s, loss: 0.398, train accuracy: 0.844\n",
      "epoch: 46, time: 1252.882s, loss: 0.535, train accuracy: 0.820\n",
      "epoch: 46, time: 1254.197s, loss: 0.545, train accuracy: 0.797\n",
      "epoch: 46, time: 1255.552s, loss: 0.321, train accuracy: 0.891\n",
      "epoch: 46, time: 1256.859s, loss: 0.467, train accuracy: 0.805\n",
      "epoch: 46, time: 1258.186s, loss: 0.376, train accuracy: 0.867\n",
      "epoch: 46, time: 1259.497s, loss: 0.393, train accuracy: 0.891\n",
      "epoch: 46, time: 1260.817s, loss: 0.417, train accuracy: 0.852\n",
      "epoch: 46, time: 1262.126s, loss: 0.483, train accuracy: 0.828\n",
      "epoch: 46, time: 1263.422s, loss: 0.454, train accuracy: 0.844\n",
      "epoch: 46, time: 1264.724s, loss: 0.499, train accuracy: 0.844\n",
      "epoch: 46, time: 1266.039s, loss: 0.339, train accuracy: 0.867\n",
      "epoch: 46, time: 1267.386s, loss: 0.451, train accuracy: 0.812\n",
      "epoch: 46, time: 1268.775s, loss: 0.497, train accuracy: 0.844\n",
      "epoch: 46, time: 1270.091s, loss: 0.531, train accuracy: 0.805\n",
      "epoch: 46, time: 1271.473s, loss: 0.485, train accuracy: 0.812\n",
      "epoch: 46, time: 1272.802s, loss: 0.501, train accuracy: 0.789\n",
      "Accuracy on the test set: 0.815\n",
      "epoch: 47, time: 1275.771s, loss: 0.452, train accuracy: 0.812\n",
      "epoch: 47, time: 1277.102s, loss: 0.363, train accuracy: 0.898\n",
      "epoch: 47, time: 1278.412s, loss: 0.430, train accuracy: 0.828\n",
      "epoch: 47, time: 1279.739s, loss: 0.481, train accuracy: 0.805\n",
      "epoch: 47, time: 1281.051s, loss: 0.600, train accuracy: 0.766\n",
      "epoch: 47, time: 1282.362s, loss: 0.429, train accuracy: 0.867\n",
      "epoch: 47, time: 1283.672s, loss: 0.416, train accuracy: 0.844\n",
      "epoch: 47, time: 1284.985s, loss: 0.383, train accuracy: 0.875\n",
      "epoch: 47, time: 1286.284s, loss: 0.527, train accuracy: 0.828\n",
      "epoch: 47, time: 1287.590s, loss: 0.322, train accuracy: 0.898\n",
      "epoch: 47, time: 1288.937s, loss: 0.459, train accuracy: 0.859\n",
      "epoch: 47, time: 1290.235s, loss: 0.671, train accuracy: 0.773\n",
      "epoch: 47, time: 1291.558s, loss: 0.542, train accuracy: 0.820\n",
      "epoch: 47, time: 1292.807s, loss: 0.584, train accuracy: 0.781\n",
      "epoch: 47, time: 1294.088s, loss: 0.470, train accuracy: 0.859\n",
      "epoch: 47, time: 1295.366s, loss: 0.442, train accuracy: 0.836\n",
      "epoch: 47, time: 1296.628s, loss: 0.447, train accuracy: 0.844\n",
      "epoch: 47, time: 1297.902s, loss: 0.459, train accuracy: 0.867\n",
      "epoch: 47, time: 1299.154s, loss: 0.521, train accuracy: 0.820\n",
      "epoch: 47, time: 1300.438s, loss: 0.395, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.821\n",
      "epoch: 48, time: 1303.370s, loss: 0.451, train accuracy: 0.828\n",
      "epoch: 48, time: 1304.623s, loss: 0.423, train accuracy: 0.820\n",
      "epoch: 48, time: 1305.874s, loss: 0.575, train accuracy: 0.820\n",
      "epoch: 48, time: 1307.130s, loss: 0.454, train accuracy: 0.836\n",
      "epoch: 48, time: 1308.381s, loss: 0.410, train accuracy: 0.844\n",
      "epoch: 48, time: 1309.642s, loss: 0.549, train accuracy: 0.797\n",
      "epoch: 48, time: 1310.893s, loss: 0.431, train accuracy: 0.867\n",
      "epoch: 48, time: 1312.158s, loss: 0.538, train accuracy: 0.789\n",
      "epoch: 48, time: 1313.406s, loss: 0.488, train accuracy: 0.828\n",
      "epoch: 48, time: 1314.650s, loss: 0.439, train accuracy: 0.828\n",
      "epoch: 48, time: 1315.936s, loss: 0.383, train accuracy: 0.859\n",
      "epoch: 48, time: 1317.173s, loss: 0.527, train accuracy: 0.789\n",
      "epoch: 48, time: 1318.427s, loss: 0.462, train accuracy: 0.828\n",
      "epoch: 48, time: 1319.670s, loss: 0.667, train accuracy: 0.781\n",
      "epoch: 48, time: 1320.914s, loss: 0.493, train accuracy: 0.812\n",
      "epoch: 48, time: 1322.161s, loss: 0.572, train accuracy: 0.844\n",
      "epoch: 48, time: 1323.404s, loss: 0.558, train accuracy: 0.812\n",
      "epoch: 48, time: 1324.650s, loss: 0.533, train accuracy: 0.820\n",
      "epoch: 48, time: 1325.900s, loss: 0.454, train accuracy: 0.844\n",
      "epoch: 48, time: 1327.136s, loss: 0.562, train accuracy: 0.812\n",
      "Accuracy on the test set: 0.821\n",
      "epoch: 49, time: 1329.923s, loss: 0.434, train accuracy: 0.852\n",
      "epoch: 49, time: 1331.212s, loss: 0.360, train accuracy: 0.891\n",
      "epoch: 49, time: 1332.485s, loss: 0.484, train accuracy: 0.844\n",
      "epoch: 49, time: 1333.741s, loss: 0.377, train accuracy: 0.867\n",
      "epoch: 49, time: 1334.989s, loss: 0.358, train accuracy: 0.875\n",
      "epoch: 49, time: 1336.242s, loss: 0.331, train accuracy: 0.891\n",
      "epoch: 49, time: 1337.495s, loss: 0.465, train accuracy: 0.875\n",
      "epoch: 49, time: 1338.728s, loss: 0.590, train accuracy: 0.812\n",
      "epoch: 49, time: 1339.974s, loss: 0.463, train accuracy: 0.844\n",
      "epoch: 49, time: 1341.227s, loss: 0.622, train accuracy: 0.789\n",
      "epoch: 49, time: 1342.501s, loss: 0.390, train accuracy: 0.844\n",
      "epoch: 49, time: 1343.779s, loss: 0.434, train accuracy: 0.844\n",
      "epoch: 49, time: 1345.014s, loss: 0.487, train accuracy: 0.859\n",
      "epoch: 49, time: 1346.257s, loss: 0.508, train accuracy: 0.820\n",
      "epoch: 49, time: 1347.506s, loss: 0.447, train accuracy: 0.867\n",
      "epoch: 49, time: 1348.770s, loss: 0.561, train accuracy: 0.820\n",
      "epoch: 49, time: 1350.031s, loss: 0.238, train accuracy: 0.914\n",
      "epoch: 49, time: 1351.276s, loss: 0.509, train accuracy: 0.859\n",
      "epoch: 49, time: 1352.518s, loss: 0.441, train accuracy: 0.852\n",
      "epoch: 49, time: 1353.766s, loss: 0.392, train accuracy: 0.844\n",
      "Accuracy on the test set: 0.819\n",
      "epoch: 50, time: 1356.616s, loss: 0.500, train accuracy: 0.805\n",
      "epoch: 50, time: 1357.884s, loss: 0.362, train accuracy: 0.875\n",
      "epoch: 50, time: 1359.129s, loss: 0.415, train accuracy: 0.875\n",
      "epoch: 50, time: 1360.373s, loss: 0.357, train accuracy: 0.883\n",
      "epoch: 50, time: 1361.612s, loss: 0.420, train accuracy: 0.859\n",
      "epoch: 50, time: 1362.859s, loss: 0.586, train accuracy: 0.797\n",
      "epoch: 50, time: 1364.110s, loss: 0.442, train accuracy: 0.844\n",
      "epoch: 50, time: 1365.352s, loss: 0.415, train accuracy: 0.836\n",
      "epoch: 50, time: 1366.595s, loss: 0.532, train accuracy: 0.805\n",
      "epoch: 50, time: 1367.866s, loss: 0.512, train accuracy: 0.859\n",
      "epoch: 50, time: 1369.119s, loss: 0.416, train accuracy: 0.836\n",
      "epoch: 50, time: 1370.363s, loss: 0.502, train accuracy: 0.844\n",
      "epoch: 50, time: 1371.687s, loss: 0.472, train accuracy: 0.844\n",
      "epoch: 50, time: 1372.991s, loss: 0.483, train accuracy: 0.812\n",
      "epoch: 50, time: 1374.248s, loss: 0.521, train accuracy: 0.836\n",
      "epoch: 50, time: 1375.501s, loss: 0.399, train accuracy: 0.820\n",
      "epoch: 50, time: 1376.755s, loss: 0.472, train accuracy: 0.820\n",
      "epoch: 50, time: 1378.036s, loss: 0.395, train accuracy: 0.852\n",
      "epoch: 50, time: 1379.291s, loss: 0.509, train accuracy: 0.812\n",
      "epoch: 50, time: 1380.534s, loss: 0.346, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.819\n",
      "epoch: 51, time: 1383.430s, loss: 0.414, train accuracy: 0.844\n",
      "epoch: 51, time: 1384.749s, loss: 0.433, train accuracy: 0.852\n",
      "epoch: 51, time: 1386.030s, loss: 0.463, train accuracy: 0.805\n",
      "epoch: 51, time: 1387.282s, loss: 0.395, train accuracy: 0.844\n",
      "epoch: 51, time: 1388.542s, loss: 0.359, train accuracy: 0.930\n",
      "epoch: 51, time: 1389.883s, loss: 0.470, train accuracy: 0.852\n",
      "epoch: 51, time: 1391.121s, loss: 0.373, train accuracy: 0.844\n",
      "epoch: 51, time: 1392.373s, loss: 0.440, train accuracy: 0.852\n",
      "epoch: 51, time: 1393.630s, loss: 0.404, train accuracy: 0.852\n",
      "epoch: 51, time: 1394.862s, loss: 0.549, train accuracy: 0.820\n",
      "epoch: 51, time: 1396.110s, loss: 0.405, train accuracy: 0.836\n",
      "epoch: 51, time: 1397.367s, loss: 0.454, train accuracy: 0.836\n",
      "epoch: 51, time: 1398.633s, loss: 0.400, train accuracy: 0.828\n",
      "epoch: 51, time: 1399.883s, loss: 0.503, train accuracy: 0.852\n",
      "epoch: 51, time: 1401.126s, loss: 0.433, train accuracy: 0.820\n",
      "epoch: 51, time: 1402.373s, loss: 0.465, train accuracy: 0.844\n",
      "epoch: 51, time: 1403.619s, loss: 0.435, train accuracy: 0.852\n",
      "epoch: 51, time: 1404.857s, loss: 0.405, train accuracy: 0.867\n",
      "epoch: 51, time: 1406.108s, loss: 0.400, train accuracy: 0.836\n",
      "epoch: 51, time: 1407.354s, loss: 0.415, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.822\n",
      "epoch: 52, time: 1410.162s, loss: 0.449, train accuracy: 0.867\n",
      "epoch: 52, time: 1411.462s, loss: 0.312, train accuracy: 0.883\n",
      "epoch: 52, time: 1412.720s, loss: 0.502, train accuracy: 0.820\n",
      "epoch: 52, time: 1413.967s, loss: 0.422, train accuracy: 0.867\n",
      "epoch: 52, time: 1415.229s, loss: 0.736, train accuracy: 0.734\n",
      "epoch: 52, time: 1416.489s, loss: 0.404, train accuracy: 0.859\n",
      "epoch: 52, time: 1417.731s, loss: 0.441, train accuracy: 0.836\n",
      "epoch: 52, time: 1418.979s, loss: 0.503, train accuracy: 0.836\n",
      "epoch: 52, time: 1420.217s, loss: 0.391, train accuracy: 0.844\n",
      "epoch: 52, time: 1421.466s, loss: 0.454, train accuracy: 0.836\n",
      "epoch: 52, time: 1422.712s, loss: 0.423, train accuracy: 0.891\n",
      "epoch: 52, time: 1423.977s, loss: 0.509, train accuracy: 0.828\n",
      "epoch: 52, time: 1425.268s, loss: 0.427, train accuracy: 0.836\n",
      "epoch: 52, time: 1426.516s, loss: 0.433, train accuracy: 0.852\n",
      "epoch: 52, time: 1427.767s, loss: 0.531, train accuracy: 0.812\n",
      "epoch: 52, time: 1429.036s, loss: 0.537, train accuracy: 0.820\n",
      "epoch: 52, time: 1430.273s, loss: 0.507, train accuracy: 0.812\n",
      "epoch: 52, time: 1431.532s, loss: 0.486, train accuracy: 0.828\n",
      "epoch: 52, time: 1432.781s, loss: 0.625, train accuracy: 0.750\n",
      "epoch: 52, time: 1434.038s, loss: 0.548, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.774\n",
      "epoch: 53, time: 1436.900s, loss: 0.603, train accuracy: 0.805\n",
      "epoch: 53, time: 1438.177s, loss: 0.647, train accuracy: 0.766\n",
      "epoch: 53, time: 1439.430s, loss: 0.642, train accuracy: 0.773\n",
      "epoch: 53, time: 1440.679s, loss: 0.481, train accuracy: 0.828\n",
      "epoch: 53, time: 1441.928s, loss: 0.527, train accuracy: 0.805\n",
      "epoch: 53, time: 1443.174s, loss: 0.413, train accuracy: 0.875\n",
      "epoch: 53, time: 1444.419s, loss: 0.421, train accuracy: 0.875\n",
      "epoch: 53, time: 1445.669s, loss: 0.425, train accuracy: 0.859\n",
      "epoch: 53, time: 1446.917s, loss: 0.453, train accuracy: 0.891\n",
      "epoch: 53, time: 1448.170s, loss: 0.470, train accuracy: 0.875\n",
      "epoch: 53, time: 1449.407s, loss: 0.533, train accuracy: 0.820\n",
      "epoch: 53, time: 1450.658s, loss: 0.545, train accuracy: 0.789\n",
      "epoch: 53, time: 1451.898s, loss: 0.412, train accuracy: 0.836\n",
      "epoch: 53, time: 1453.152s, loss: 0.372, train accuracy: 0.859\n",
      "epoch: 53, time: 1454.407s, loss: 0.444, train accuracy: 0.867\n",
      "epoch: 53, time: 1455.651s, loss: 0.423, train accuracy: 0.844\n",
      "epoch: 53, time: 1456.902s, loss: 0.473, train accuracy: 0.836\n",
      "epoch: 53, time: 1458.148s, loss: 0.593, train accuracy: 0.789\n",
      "epoch: 53, time: 1459.386s, loss: 0.537, train accuracy: 0.805\n",
      "epoch: 53, time: 1460.629s, loss: 0.340, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.820\n",
      "epoch: 54, time: 1463.454s, loss: 0.380, train accuracy: 0.859\n",
      "epoch: 54, time: 1464.728s, loss: 0.467, train accuracy: 0.828\n",
      "epoch: 54, time: 1465.986s, loss: 0.402, train accuracy: 0.867\n",
      "epoch: 54, time: 1467.238s, loss: 0.534, train accuracy: 0.820\n",
      "epoch: 54, time: 1468.504s, loss: 0.331, train accuracy: 0.883\n",
      "epoch: 54, time: 1469.770s, loss: 0.385, train accuracy: 0.875\n",
      "epoch: 54, time: 1471.005s, loss: 0.557, train accuracy: 0.812\n",
      "epoch: 54, time: 1472.251s, loss: 0.305, train accuracy: 0.891\n",
      "epoch: 54, time: 1473.493s, loss: 0.535, train accuracy: 0.812\n",
      "epoch: 54, time: 1474.741s, loss: 0.437, train accuracy: 0.859\n",
      "epoch: 54, time: 1476.013s, loss: 0.400, train accuracy: 0.828\n",
      "epoch: 54, time: 1477.257s, loss: 0.485, train accuracy: 0.836\n",
      "epoch: 54, time: 1478.506s, loss: 0.362, train accuracy: 0.836\n",
      "epoch: 54, time: 1479.746s, loss: 0.436, train accuracy: 0.859\n",
      "epoch: 54, time: 1480.993s, loss: 0.407, train accuracy: 0.844\n",
      "epoch: 54, time: 1482.235s, loss: 0.462, train accuracy: 0.859\n",
      "epoch: 54, time: 1483.476s, loss: 0.619, train accuracy: 0.781\n",
      "epoch: 54, time: 1484.732s, loss: 0.245, train accuracy: 0.914\n",
      "epoch: 54, time: 1485.985s, loss: 0.422, train accuracy: 0.891\n",
      "epoch: 54, time: 1487.231s, loss: 0.363, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.829\n",
      "epoch: 55, time: 1490.057s, loss: 0.385, train accuracy: 0.867\n",
      "epoch: 55, time: 1491.329s, loss: 0.468, train accuracy: 0.852\n",
      "epoch: 55, time: 1492.580s, loss: 0.420, train accuracy: 0.875\n",
      "epoch: 55, time: 1493.839s, loss: 0.353, train accuracy: 0.867\n",
      "epoch: 55, time: 1495.082s, loss: 0.325, train accuracy: 0.891\n",
      "epoch: 55, time: 1496.345s, loss: 0.383, train accuracy: 0.844\n",
      "epoch: 55, time: 1497.592s, loss: 0.507, train accuracy: 0.820\n",
      "epoch: 55, time: 1498.854s, loss: 0.338, train accuracy: 0.891\n",
      "epoch: 55, time: 1500.092s, loss: 0.457, train accuracy: 0.852\n",
      "epoch: 55, time: 1501.337s, loss: 0.410, train accuracy: 0.859\n",
      "epoch: 55, time: 1502.579s, loss: 0.464, train accuracy: 0.828\n",
      "epoch: 55, time: 1503.823s, loss: 0.323, train accuracy: 0.867\n",
      "epoch: 55, time: 1505.085s, loss: 0.332, train accuracy: 0.883\n",
      "epoch: 55, time: 1506.359s, loss: 0.371, train accuracy: 0.875\n",
      "epoch: 55, time: 1507.600s, loss: 0.402, train accuracy: 0.859\n",
      "epoch: 55, time: 1508.846s, loss: 0.396, train accuracy: 0.859\n",
      "epoch: 55, time: 1510.145s, loss: 0.439, train accuracy: 0.820\n",
      "epoch: 55, time: 1511.422s, loss: 0.328, train accuracy: 0.859\n",
      "epoch: 55, time: 1512.663s, loss: 0.486, train accuracy: 0.844\n",
      "epoch: 55, time: 1513.910s, loss: 0.370, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.828\n",
      "epoch: 56, time: 1516.798s, loss: 0.405, train accuracy: 0.836\n",
      "epoch: 56, time: 1518.041s, loss: 0.529, train accuracy: 0.836\n",
      "epoch: 56, time: 1519.286s, loss: 0.453, train accuracy: 0.836\n",
      "epoch: 56, time: 1520.522s, loss: 0.465, train accuracy: 0.820\n",
      "epoch: 56, time: 1521.772s, loss: 0.372, train accuracy: 0.859\n",
      "epoch: 56, time: 1523.013s, loss: 0.380, train accuracy: 0.867\n",
      "epoch: 56, time: 1524.269s, loss: 0.344, train accuracy: 0.852\n",
      "epoch: 56, time: 1525.517s, loss: 0.424, train accuracy: 0.859\n",
      "epoch: 56, time: 1526.767s, loss: 0.294, train accuracy: 0.914\n",
      "epoch: 56, time: 1528.006s, loss: 0.486, train accuracy: 0.836\n",
      "epoch: 56, time: 1529.250s, loss: 0.470, train accuracy: 0.820\n",
      "epoch: 56, time: 1530.485s, loss: 0.296, train accuracy: 0.891\n",
      "epoch: 56, time: 1531.779s, loss: 0.406, train accuracy: 0.859\n",
      "epoch: 56, time: 1533.036s, loss: 0.462, train accuracy: 0.836\n",
      "epoch: 56, time: 1534.274s, loss: 0.435, train accuracy: 0.812\n",
      "epoch: 56, time: 1535.519s, loss: 0.404, train accuracy: 0.852\n",
      "epoch: 56, time: 1536.772s, loss: 0.360, train accuracy: 0.883\n",
      "epoch: 56, time: 1538.019s, loss: 0.330, train accuracy: 0.906\n",
      "epoch: 56, time: 1539.264s, loss: 0.413, train accuracy: 0.859\n",
      "epoch: 56, time: 1540.510s, loss: 0.504, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.822\n",
      "epoch: 57, time: 1543.386s, loss: 0.461, train accuracy: 0.875\n",
      "epoch: 57, time: 1544.753s, loss: 0.330, train accuracy: 0.891\n",
      "epoch: 57, time: 1546.107s, loss: 0.460, train accuracy: 0.867\n",
      "epoch: 57, time: 1547.436s, loss: 0.373, train accuracy: 0.852\n",
      "epoch: 57, time: 1548.729s, loss: 0.352, train accuracy: 0.891\n",
      "epoch: 57, time: 1550.038s, loss: 0.392, train accuracy: 0.836\n",
      "epoch: 57, time: 1551.374s, loss: 0.399, train accuracy: 0.875\n",
      "epoch: 57, time: 1552.677s, loss: 0.376, train accuracy: 0.883\n",
      "epoch: 57, time: 1553.982s, loss: 0.371, train accuracy: 0.883\n",
      "epoch: 57, time: 1555.315s, loss: 0.367, train accuracy: 0.898\n",
      "epoch: 57, time: 1556.619s, loss: 0.408, train accuracy: 0.859\n",
      "epoch: 57, time: 1557.956s, loss: 0.286, train accuracy: 0.883\n",
      "epoch: 57, time: 1559.250s, loss: 0.340, train accuracy: 0.875\n",
      "epoch: 57, time: 1560.608s, loss: 0.377, train accuracy: 0.875\n",
      "epoch: 57, time: 1561.905s, loss: 0.376, train accuracy: 0.883\n",
      "epoch: 57, time: 1563.195s, loss: 0.419, train accuracy: 0.859\n",
      "epoch: 57, time: 1564.506s, loss: 0.381, train accuracy: 0.859\n",
      "epoch: 57, time: 1565.802s, loss: 0.392, train accuracy: 0.859\n",
      "epoch: 57, time: 1567.121s, loss: 0.398, train accuracy: 0.852\n",
      "epoch: 57, time: 1568.461s, loss: 0.403, train accuracy: 0.852\n",
      "Accuracy on the test set: 0.825\n",
      "epoch: 58, time: 1571.441s, loss: 0.293, train accuracy: 0.883\n",
      "epoch: 58, time: 1572.802s, loss: 0.522, train accuracy: 0.852\n",
      "epoch: 58, time: 1574.111s, loss: 0.351, train accuracy: 0.906\n",
      "epoch: 58, time: 1575.417s, loss: 0.376, train accuracy: 0.844\n",
      "epoch: 58, time: 1576.719s, loss: 0.412, train accuracy: 0.820\n",
      "epoch: 58, time: 1578.022s, loss: 0.386, train accuracy: 0.812\n",
      "epoch: 58, time: 1579.346s, loss: 0.307, train accuracy: 0.922\n",
      "epoch: 58, time: 1580.650s, loss: 0.373, train accuracy: 0.844\n",
      "epoch: 58, time: 1581.985s, loss: 0.279, train accuracy: 0.914\n",
      "epoch: 58, time: 1583.374s, loss: 0.471, train accuracy: 0.836\n",
      "epoch: 58, time: 1584.773s, loss: 0.520, train accuracy: 0.836\n",
      "epoch: 58, time: 1586.184s, loss: 0.409, train accuracy: 0.859\n",
      "epoch: 58, time: 1587.602s, loss: 0.618, train accuracy: 0.781\n",
      "epoch: 58, time: 1588.931s, loss: 0.348, train accuracy: 0.883\n",
      "epoch: 58, time: 1590.257s, loss: 0.561, train accuracy: 0.805\n",
      "epoch: 58, time: 1591.608s, loss: 0.390, train accuracy: 0.867\n",
      "epoch: 58, time: 1592.962s, loss: 0.532, train accuracy: 0.859\n",
      "epoch: 58, time: 1594.284s, loss: 0.414, train accuracy: 0.859\n",
      "epoch: 58, time: 1595.648s, loss: 0.362, train accuracy: 0.852\n",
      "epoch: 58, time: 1597.013s, loss: 0.474, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.827\n",
      "epoch: 59, time: 1599.870s, loss: 0.433, train accuracy: 0.852\n",
      "epoch: 59, time: 1601.265s, loss: 0.341, train accuracy: 0.883\n",
      "epoch: 59, time: 1602.568s, loss: 0.415, train accuracy: 0.828\n",
      "epoch: 59, time: 1603.877s, loss: 0.386, train accuracy: 0.859\n",
      "epoch: 59, time: 1605.190s, loss: 0.403, train accuracy: 0.859\n",
      "epoch: 59, time: 1606.508s, loss: 0.268, train accuracy: 0.914\n",
      "epoch: 59, time: 1607.806s, loss: 0.321, train accuracy: 0.875\n",
      "epoch: 59, time: 1609.094s, loss: 0.340, train accuracy: 0.898\n",
      "epoch: 59, time: 1610.447s, loss: 0.320, train accuracy: 0.898\n",
      "epoch: 59, time: 1611.751s, loss: 0.280, train accuracy: 0.867\n",
      "epoch: 59, time: 1613.073s, loss: 0.320, train accuracy: 0.898\n",
      "epoch: 59, time: 1614.416s, loss: 0.300, train accuracy: 0.914\n",
      "epoch: 59, time: 1615.718s, loss: 0.510, train accuracy: 0.820\n",
      "epoch: 59, time: 1617.040s, loss: 0.262, train accuracy: 0.914\n",
      "epoch: 59, time: 1618.350s, loss: 0.389, train accuracy: 0.898\n",
      "epoch: 59, time: 1619.648s, loss: 0.324, train accuracy: 0.891\n",
      "epoch: 59, time: 1620.966s, loss: 0.362, train accuracy: 0.859\n",
      "epoch: 59, time: 1622.268s, loss: 0.401, train accuracy: 0.828\n",
      "epoch: 59, time: 1623.557s, loss: 0.635, train accuracy: 0.797\n",
      "epoch: 59, time: 1624.848s, loss: 0.345, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.824\n",
      "epoch: 60, time: 1627.793s, loss: 0.440, train accuracy: 0.820\n",
      "epoch: 60, time: 1629.123s, loss: 0.538, train accuracy: 0.812\n",
      "epoch: 60, time: 1630.450s, loss: 0.837, train accuracy: 0.773\n",
      "epoch: 60, time: 1631.846s, loss: 0.447, train accuracy: 0.867\n",
      "epoch: 60, time: 1633.146s, loss: 0.488, train accuracy: 0.812\n",
      "epoch: 60, time: 1634.440s, loss: 0.364, train accuracy: 0.867\n",
      "epoch: 60, time: 1635.755s, loss: 0.448, train accuracy: 0.859\n",
      "epoch: 60, time: 1637.067s, loss: 0.425, train accuracy: 0.852\n",
      "epoch: 60, time: 1638.367s, loss: 0.385, train accuracy: 0.875\n",
      "epoch: 60, time: 1639.666s, loss: 0.377, train accuracy: 0.859\n",
      "epoch: 60, time: 1640.993s, loss: 0.321, train accuracy: 0.891\n",
      "epoch: 60, time: 1642.304s, loss: 0.411, train accuracy: 0.828\n",
      "epoch: 60, time: 1643.597s, loss: 0.402, train accuracy: 0.867\n",
      "epoch: 60, time: 1644.892s, loss: 0.533, train accuracy: 0.812\n",
      "epoch: 60, time: 1646.212s, loss: 0.418, train accuracy: 0.844\n",
      "epoch: 60, time: 1647.549s, loss: 0.403, train accuracy: 0.859\n",
      "epoch: 60, time: 1648.842s, loss: 0.601, train accuracy: 0.828\n",
      "epoch: 60, time: 1650.134s, loss: 0.421, train accuracy: 0.844\n",
      "epoch: 60, time: 1651.465s, loss: 0.379, train accuracy: 0.859\n",
      "epoch: 60, time: 1652.777s, loss: 0.354, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.826\n",
      "epoch: 61, time: 1655.710s, loss: 0.369, train accuracy: 0.875\n",
      "epoch: 61, time: 1657.071s, loss: 0.368, train accuracy: 0.875\n",
      "epoch: 61, time: 1658.363s, loss: 0.412, train accuracy: 0.836\n",
      "epoch: 61, time: 1659.673s, loss: 0.781, train accuracy: 0.750\n",
      "epoch: 61, time: 1660.995s, loss: 0.437, train accuracy: 0.867\n",
      "epoch: 61, time: 1662.301s, loss: 0.430, train accuracy: 0.836\n",
      "epoch: 61, time: 1663.600s, loss: 0.434, train accuracy: 0.836\n",
      "epoch: 61, time: 1664.892s, loss: 0.396, train accuracy: 0.852\n",
      "epoch: 61, time: 1666.205s, loss: 0.351, train accuracy: 0.883\n",
      "epoch: 61, time: 1667.516s, loss: 0.442, train accuracy: 0.836\n",
      "epoch: 61, time: 1668.807s, loss: 0.338, train accuracy: 0.898\n",
      "epoch: 61, time: 1670.107s, loss: 0.427, train accuracy: 0.852\n",
      "epoch: 61, time: 1671.441s, loss: 0.474, train accuracy: 0.836\n",
      "epoch: 61, time: 1672.751s, loss: 0.342, train accuracy: 0.891\n",
      "epoch: 61, time: 1674.069s, loss: 0.518, train accuracy: 0.844\n",
      "epoch: 61, time: 1675.410s, loss: 0.478, train accuracy: 0.812\n",
      "epoch: 61, time: 1676.705s, loss: 0.529, train accuracy: 0.844\n",
      "epoch: 61, time: 1678.027s, loss: 0.414, train accuracy: 0.844\n",
      "epoch: 61, time: 1679.357s, loss: 0.495, train accuracy: 0.820\n",
      "epoch: 61, time: 1680.663s, loss: 0.348, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.831\n",
      "epoch: 62, time: 1683.597s, loss: 0.351, train accuracy: 0.883\n",
      "epoch: 62, time: 1684.902s, loss: 0.338, train accuracy: 0.898\n",
      "epoch: 62, time: 1686.235s, loss: 0.293, train accuracy: 0.898\n",
      "epoch: 62, time: 1687.550s, loss: 0.956, train accuracy: 0.695\n",
      "epoch: 62, time: 1688.871s, loss: 0.510, train accuracy: 0.852\n",
      "epoch: 62, time: 1690.267s, loss: 0.578, train accuracy: 0.781\n",
      "epoch: 62, time: 1691.599s, loss: 0.599, train accuracy: 0.836\n",
      "epoch: 62, time: 1692.959s, loss: 0.472, train accuracy: 0.844\n",
      "epoch: 62, time: 1694.337s, loss: 0.436, train accuracy: 0.836\n",
      "epoch: 62, time: 1695.706s, loss: 0.414, train accuracy: 0.867\n",
      "epoch: 62, time: 1697.059s, loss: 0.428, train accuracy: 0.867\n",
      "epoch: 62, time: 1698.426s, loss: 0.392, train accuracy: 0.875\n",
      "epoch: 62, time: 1699.777s, loss: 0.379, train accuracy: 0.867\n",
      "epoch: 62, time: 1701.157s, loss: 0.422, train accuracy: 0.820\n",
      "epoch: 62, time: 1702.494s, loss: 0.432, train accuracy: 0.805\n",
      "epoch: 62, time: 1703.922s, loss: 0.443, train accuracy: 0.836\n",
      "epoch: 62, time: 1705.264s, loss: 0.486, train accuracy: 0.852\n",
      "epoch: 62, time: 1706.624s, loss: 0.525, train accuracy: 0.844\n",
      "epoch: 62, time: 1707.994s, loss: 0.476, train accuracy: 0.805\n",
      "epoch: 62, time: 1709.442s, loss: 0.411, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.822\n",
      "epoch: 63, time: 1712.496s, loss: 0.453, train accuracy: 0.828\n",
      "epoch: 63, time: 1713.861s, loss: 0.459, train accuracy: 0.836\n",
      "epoch: 63, time: 1715.239s, loss: 0.557, train accuracy: 0.812\n",
      "epoch: 63, time: 1716.593s, loss: 0.394, train accuracy: 0.828\n",
      "epoch: 63, time: 1717.928s, loss: 0.758, train accuracy: 0.758\n",
      "epoch: 63, time: 1719.273s, loss: 0.527, train accuracy: 0.797\n",
      "epoch: 63, time: 1720.646s, loss: 0.373, train accuracy: 0.891\n",
      "epoch: 63, time: 1722.022s, loss: 0.461, train accuracy: 0.852\n",
      "epoch: 63, time: 1723.467s, loss: 0.563, train accuracy: 0.797\n",
      "epoch: 63, time: 1724.854s, loss: 0.344, train accuracy: 0.883\n",
      "epoch: 63, time: 1726.217s, loss: 0.508, train accuracy: 0.812\n",
      "epoch: 63, time: 1727.580s, loss: 0.567, train accuracy: 0.812\n",
      "epoch: 63, time: 1728.945s, loss: 0.518, train accuracy: 0.805\n",
      "epoch: 63, time: 1730.350s, loss: 0.247, train accuracy: 0.922\n",
      "epoch: 63, time: 1731.745s, loss: 0.412, train accuracy: 0.859\n",
      "epoch: 63, time: 1733.153s, loss: 0.557, train accuracy: 0.812\n",
      "epoch: 63, time: 1734.532s, loss: 0.400, train accuracy: 0.883\n",
      "epoch: 63, time: 1735.861s, loss: 0.431, train accuracy: 0.859\n",
      "epoch: 63, time: 1737.306s, loss: 0.424, train accuracy: 0.867\n",
      "epoch: 63, time: 1738.642s, loss: 0.564, train accuracy: 0.812\n",
      "Accuracy on the test set: 0.829\n",
      "epoch: 64, time: 1741.640s, loss: 0.325, train accuracy: 0.898\n",
      "epoch: 64, time: 1743.048s, loss: 0.399, train accuracy: 0.852\n",
      "epoch: 64, time: 1744.396s, loss: 0.472, train accuracy: 0.836\n",
      "epoch: 64, time: 1745.713s, loss: 0.373, train accuracy: 0.844\n",
      "epoch: 64, time: 1747.074s, loss: 0.305, train accuracy: 0.898\n",
      "epoch: 64, time: 1748.395s, loss: 0.239, train accuracy: 0.891\n",
      "epoch: 64, time: 1749.750s, loss: 0.433, train accuracy: 0.836\n",
      "epoch: 64, time: 1751.058s, loss: 0.347, train accuracy: 0.859\n",
      "epoch: 64, time: 1752.466s, loss: 0.335, train accuracy: 0.891\n",
      "epoch: 64, time: 1753.854s, loss: 0.357, train accuracy: 0.875\n",
      "epoch: 64, time: 1755.247s, loss: 0.318, train accuracy: 0.891\n",
      "epoch: 64, time: 1756.623s, loss: 0.513, train accuracy: 0.844\n",
      "epoch: 64, time: 1758.039s, loss: 0.451, train accuracy: 0.836\n",
      "epoch: 64, time: 1759.387s, loss: 0.482, train accuracy: 0.852\n",
      "epoch: 64, time: 1760.781s, loss: 0.308, train accuracy: 0.898\n",
      "epoch: 64, time: 1762.147s, loss: 0.356, train accuracy: 0.859\n",
      "epoch: 64, time: 1763.527s, loss: 0.470, train accuracy: 0.859\n",
      "epoch: 64, time: 1764.927s, loss: 0.415, train accuracy: 0.852\n",
      "epoch: 64, time: 1766.227s, loss: 0.484, train accuracy: 0.805\n",
      "epoch: 64, time: 1767.536s, loss: 0.362, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.828\n",
      "epoch: 65, time: 1770.492s, loss: 0.425, train accuracy: 0.859\n",
      "epoch: 65, time: 1771.889s, loss: 0.318, train accuracy: 0.914\n",
      "epoch: 65, time: 1773.207s, loss: 0.330, train accuracy: 0.883\n",
      "epoch: 65, time: 1774.525s, loss: 0.379, train accuracy: 0.883\n",
      "epoch: 65, time: 1775.838s, loss: 0.474, train accuracy: 0.820\n",
      "epoch: 65, time: 1777.159s, loss: 0.573, train accuracy: 0.844\n",
      "epoch: 65, time: 1778.503s, loss: 0.414, train accuracy: 0.875\n",
      "epoch: 65, time: 1779.903s, loss: 0.402, train accuracy: 0.852\n",
      "epoch: 65, time: 1781.234s, loss: 0.477, train accuracy: 0.852\n",
      "epoch: 65, time: 1782.612s, loss: 0.356, train accuracy: 0.883\n",
      "epoch: 65, time: 1783.954s, loss: 0.406, train accuracy: 0.852\n",
      "epoch: 65, time: 1785.301s, loss: 0.385, train accuracy: 0.859\n",
      "epoch: 65, time: 1786.646s, loss: 0.378, train accuracy: 0.859\n",
      "epoch: 65, time: 1787.986s, loss: 0.380, train accuracy: 0.820\n",
      "epoch: 65, time: 1789.444s, loss: 0.361, train accuracy: 0.891\n",
      "epoch: 65, time: 1790.788s, loss: 0.274, train accuracy: 0.891\n",
      "epoch: 65, time: 1792.157s, loss: 0.350, train accuracy: 0.852\n",
      "epoch: 65, time: 1793.599s, loss: 0.352, train accuracy: 0.891\n",
      "epoch: 65, time: 1794.947s, loss: 0.384, train accuracy: 0.875\n",
      "epoch: 65, time: 1796.306s, loss: 0.338, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.831\n",
      "epoch: 66, time: 1799.250s, loss: 0.260, train accuracy: 0.914\n",
      "epoch: 66, time: 1800.557s, loss: 0.371, train accuracy: 0.883\n",
      "epoch: 66, time: 1801.877s, loss: 0.319, train accuracy: 0.898\n",
      "epoch: 66, time: 1803.174s, loss: 0.451, train accuracy: 0.844\n",
      "epoch: 66, time: 1804.506s, loss: 0.300, train accuracy: 0.859\n",
      "epoch: 66, time: 1805.823s, loss: 0.276, train accuracy: 0.898\n",
      "epoch: 66, time: 1807.151s, loss: 0.402, train accuracy: 0.844\n",
      "epoch: 66, time: 1808.476s, loss: 0.340, train accuracy: 0.898\n",
      "epoch: 66, time: 1809.768s, loss: 0.325, train accuracy: 0.875\n",
      "epoch: 66, time: 1811.063s, loss: 0.486, train accuracy: 0.859\n",
      "epoch: 66, time: 1812.354s, loss: 0.470, train accuracy: 0.844\n",
      "epoch: 66, time: 1813.667s, loss: 0.386, train accuracy: 0.875\n",
      "epoch: 66, time: 1814.978s, loss: 0.475, train accuracy: 0.875\n",
      "epoch: 66, time: 1816.293s, loss: 0.317, train accuracy: 0.891\n",
      "epoch: 66, time: 1817.595s, loss: 0.422, train accuracy: 0.812\n",
      "epoch: 66, time: 1818.891s, loss: 0.396, train accuracy: 0.852\n",
      "epoch: 66, time: 1820.193s, loss: 0.390, train accuracy: 0.867\n",
      "epoch: 66, time: 1821.505s, loss: 0.438, train accuracy: 0.836\n",
      "epoch: 66, time: 1822.835s, loss: 0.405, train accuracy: 0.883\n",
      "epoch: 66, time: 1824.152s, loss: 0.416, train accuracy: 0.836\n",
      "Accuracy on the test set: 0.830\n",
      "epoch: 67, time: 1827.077s, loss: 0.333, train accuracy: 0.883\n",
      "epoch: 67, time: 1828.421s, loss: 0.384, train accuracy: 0.859\n",
      "epoch: 67, time: 1829.715s, loss: 0.393, train accuracy: 0.844\n",
      "epoch: 67, time: 1831.020s, loss: 0.348, train accuracy: 0.883\n",
      "epoch: 67, time: 1832.331s, loss: 0.266, train accuracy: 0.922\n",
      "epoch: 67, time: 1833.659s, loss: 0.453, train accuracy: 0.820\n",
      "epoch: 67, time: 1834.967s, loss: 0.488, train accuracy: 0.828\n",
      "epoch: 67, time: 1836.273s, loss: 0.357, train accuracy: 0.891\n",
      "epoch: 67, time: 1837.577s, loss: 0.385, train accuracy: 0.891\n",
      "epoch: 67, time: 1838.888s, loss: 0.413, train accuracy: 0.859\n",
      "epoch: 67, time: 1840.187s, loss: 0.400, train accuracy: 0.867\n",
      "epoch: 67, time: 1841.527s, loss: 0.239, train accuracy: 0.922\n",
      "epoch: 67, time: 1842.842s, loss: 0.284, train accuracy: 0.906\n",
      "epoch: 67, time: 1844.135s, loss: 0.264, train accuracy: 0.875\n",
      "epoch: 67, time: 1845.447s, loss: 0.399, train accuracy: 0.836\n",
      "epoch: 67, time: 1846.766s, loss: 0.361, train accuracy: 0.867\n",
      "epoch: 67, time: 1848.086s, loss: 0.292, train accuracy: 0.906\n",
      "epoch: 67, time: 1849.384s, loss: 0.301, train accuracy: 0.883\n",
      "epoch: 67, time: 1850.713s, loss: 0.307, train accuracy: 0.867\n",
      "epoch: 67, time: 1852.053s, loss: 0.350, train accuracy: 0.867\n",
      "Accuracy on the test set: 0.829\n",
      "epoch: 68, time: 1854.970s, loss: 0.215, train accuracy: 0.930\n",
      "epoch: 68, time: 1856.296s, loss: 0.352, train accuracy: 0.859\n",
      "epoch: 68, time: 1857.629s, loss: 0.384, train accuracy: 0.883\n",
      "epoch: 68, time: 1858.919s, loss: 0.225, train accuracy: 0.914\n",
      "epoch: 68, time: 1860.231s, loss: 0.428, train accuracy: 0.836\n",
      "epoch: 68, time: 1861.536s, loss: 0.363, train accuracy: 0.867\n",
      "epoch: 68, time: 1862.878s, loss: 0.310, train accuracy: 0.883\n",
      "epoch: 68, time: 1864.172s, loss: 0.515, train accuracy: 0.828\n",
      "epoch: 68, time: 1865.476s, loss: 0.261, train accuracy: 0.898\n",
      "epoch: 68, time: 1866.783s, loss: 0.469, train accuracy: 0.812\n",
      "epoch: 68, time: 1868.109s, loss: 0.419, train accuracy: 0.859\n",
      "epoch: 68, time: 1869.411s, loss: 0.254, train accuracy: 0.930\n",
      "epoch: 68, time: 1870.736s, loss: 0.406, train accuracy: 0.836\n",
      "epoch: 68, time: 1872.048s, loss: 0.444, train accuracy: 0.836\n",
      "epoch: 68, time: 1873.425s, loss: 0.315, train accuracy: 0.891\n",
      "epoch: 68, time: 1874.771s, loss: 0.351, train accuracy: 0.859\n",
      "epoch: 68, time: 1876.082s, loss: 0.347, train accuracy: 0.867\n",
      "epoch: 68, time: 1877.394s, loss: 0.413, train accuracy: 0.891\n",
      "epoch: 68, time: 1878.694s, loss: 0.395, train accuracy: 0.828\n",
      "epoch: 68, time: 1880.011s, loss: 0.471, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.818\n",
      "epoch: 69, time: 1882.983s, loss: 0.344, train accuracy: 0.898\n",
      "epoch: 69, time: 1884.314s, loss: 0.245, train accuracy: 0.898\n",
      "epoch: 69, time: 1885.632s, loss: 0.457, train accuracy: 0.859\n",
      "epoch: 69, time: 1886.953s, loss: 0.263, train accuracy: 0.914\n",
      "epoch: 69, time: 1888.274s, loss: 0.381, train accuracy: 0.883\n",
      "epoch: 69, time: 1889.563s, loss: 0.338, train accuracy: 0.859\n",
      "epoch: 69, time: 1890.892s, loss: 0.384, train accuracy: 0.852\n",
      "epoch: 69, time: 1892.203s, loss: 0.374, train accuracy: 0.836\n",
      "epoch: 69, time: 1893.529s, loss: 0.350, train accuracy: 0.867\n",
      "epoch: 69, time: 1894.876s, loss: 0.318, train accuracy: 0.883\n",
      "epoch: 69, time: 1896.192s, loss: 0.331, train accuracy: 0.859\n",
      "epoch: 69, time: 1897.551s, loss: 0.357, train accuracy: 0.883\n",
      "epoch: 69, time: 1898.874s, loss: 0.386, train accuracy: 0.875\n",
      "epoch: 69, time: 1900.187s, loss: 0.350, train accuracy: 0.891\n",
      "epoch: 69, time: 1901.508s, loss: 0.428, train accuracy: 0.852\n",
      "epoch: 69, time: 1902.820s, loss: 0.432, train accuracy: 0.859\n",
      "epoch: 69, time: 1904.121s, loss: 0.415, train accuracy: 0.828\n",
      "epoch: 69, time: 1905.459s, loss: 0.295, train accuracy: 0.883\n",
      "epoch: 69, time: 1906.753s, loss: 0.171, train accuracy: 0.945\n",
      "epoch: 69, time: 1908.075s, loss: 0.448, train accuracy: 0.828\n",
      "Accuracy on the test set: 0.832\n",
      "epoch: 70, time: 1911.020s, loss: 0.224, train accuracy: 0.938\n",
      "epoch: 70, time: 1912.337s, loss: 0.291, train accuracy: 0.891\n",
      "epoch: 70, time: 1913.640s, loss: 0.439, train accuracy: 0.828\n",
      "epoch: 70, time: 1914.940s, loss: 0.368, train accuracy: 0.875\n",
      "epoch: 70, time: 1916.255s, loss: 0.264, train accuracy: 0.891\n",
      "epoch: 70, time: 1917.572s, loss: 0.299, train accuracy: 0.891\n",
      "epoch: 70, time: 1918.875s, loss: 0.342, train accuracy: 0.883\n",
      "epoch: 70, time: 1920.185s, loss: 0.343, train accuracy: 0.859\n",
      "epoch: 70, time: 1921.516s, loss: 0.302, train accuracy: 0.891\n",
      "epoch: 70, time: 1922.814s, loss: 0.378, train accuracy: 0.883\n",
      "epoch: 70, time: 1924.114s, loss: 0.336, train accuracy: 0.852\n",
      "epoch: 70, time: 1925.404s, loss: 0.263, train accuracy: 0.883\n",
      "epoch: 70, time: 1926.697s, loss: 0.387, train accuracy: 0.844\n",
      "epoch: 70, time: 1928.003s, loss: 0.453, train accuracy: 0.812\n",
      "epoch: 70, time: 1929.353s, loss: 0.373, train accuracy: 0.852\n",
      "epoch: 70, time: 1930.660s, loss: 0.312, train accuracy: 0.867\n",
      "epoch: 70, time: 1931.967s, loss: 0.345, train accuracy: 0.875\n",
      "epoch: 70, time: 1933.267s, loss: 0.396, train accuracy: 0.844\n",
      "epoch: 70, time: 1934.561s, loss: 0.360, train accuracy: 0.891\n",
      "epoch: 70, time: 1935.874s, loss: 0.311, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.831\n",
      "epoch: 71, time: 1938.859s, loss: 0.307, train accuracy: 0.914\n",
      "epoch: 71, time: 1940.236s, loss: 0.405, train accuracy: 0.852\n",
      "epoch: 71, time: 1941.540s, loss: 0.486, train accuracy: 0.820\n",
      "epoch: 71, time: 1942.887s, loss: 0.421, train accuracy: 0.828\n",
      "epoch: 71, time: 1944.200s, loss: 0.256, train accuracy: 0.922\n",
      "epoch: 71, time: 1945.525s, loss: 0.309, train accuracy: 0.883\n",
      "epoch: 71, time: 1946.835s, loss: 0.353, train accuracy: 0.859\n",
      "epoch: 71, time: 1948.142s, loss: 0.349, train accuracy: 0.867\n",
      "epoch: 71, time: 1949.459s, loss: 0.275, train accuracy: 0.906\n",
      "epoch: 71, time: 1950.770s, loss: 0.290, train accuracy: 0.898\n",
      "epoch: 71, time: 1952.073s, loss: 0.307, train accuracy: 0.891\n",
      "epoch: 71, time: 1953.370s, loss: 0.321, train accuracy: 0.883\n",
      "epoch: 71, time: 1954.667s, loss: 0.401, train accuracy: 0.883\n",
      "epoch: 71, time: 1955.963s, loss: 0.272, train accuracy: 0.898\n",
      "epoch: 71, time: 1957.262s, loss: 0.300, train accuracy: 0.906\n",
      "epoch: 71, time: 1958.589s, loss: 0.352, train accuracy: 0.875\n",
      "epoch: 71, time: 1959.916s, loss: 0.358, train accuracy: 0.852\n",
      "epoch: 71, time: 1961.211s, loss: 0.323, train accuracy: 0.898\n",
      "epoch: 71, time: 1962.512s, loss: 0.367, train accuracy: 0.859\n",
      "epoch: 71, time: 1963.827s, loss: 0.333, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.826\n",
      "epoch: 72, time: 1966.722s, loss: 0.393, train accuracy: 0.859\n",
      "epoch: 72, time: 1968.080s, loss: 0.281, train accuracy: 0.906\n",
      "epoch: 72, time: 1969.502s, loss: 0.339, train accuracy: 0.898\n",
      "epoch: 72, time: 1970.802s, loss: 0.356, train accuracy: 0.891\n",
      "epoch: 72, time: 1972.112s, loss: 0.472, train accuracy: 0.859\n",
      "epoch: 72, time: 1973.410s, loss: 0.261, train accuracy: 0.906\n",
      "epoch: 72, time: 1974.737s, loss: 0.348, train accuracy: 0.875\n",
      "epoch: 72, time: 1976.061s, loss: 0.350, train accuracy: 0.867\n",
      "epoch: 72, time: 1977.385s, loss: 0.259, train accuracy: 0.891\n",
      "epoch: 72, time: 1978.686s, loss: 0.239, train accuracy: 0.930\n",
      "epoch: 72, time: 1980.001s, loss: 0.448, train accuracy: 0.820\n",
      "epoch: 72, time: 1981.304s, loss: 0.334, train accuracy: 0.898\n",
      "epoch: 72, time: 1982.601s, loss: 0.264, train accuracy: 0.867\n",
      "epoch: 72, time: 1983.898s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 72, time: 1985.200s, loss: 0.366, train accuracy: 0.883\n",
      "epoch: 72, time: 1986.493s, loss: 0.293, train accuracy: 0.922\n",
      "epoch: 72, time: 1987.807s, loss: 0.357, train accuracy: 0.844\n",
      "epoch: 72, time: 1989.112s, loss: 0.275, train accuracy: 0.914\n",
      "epoch: 72, time: 1990.452s, loss: 0.273, train accuracy: 0.922\n",
      "epoch: 72, time: 1991.744s, loss: 0.346, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.830\n",
      "epoch: 73, time: 1994.741s, loss: 0.363, train accuracy: 0.867\n",
      "epoch: 73, time: 1996.091s, loss: 0.245, train accuracy: 0.906\n",
      "epoch: 73, time: 1997.413s, loss: 0.439, train accuracy: 0.820\n",
      "epoch: 73, time: 1998.735s, loss: 0.393, train accuracy: 0.844\n",
      "epoch: 73, time: 2000.043s, loss: 0.227, train accuracy: 0.930\n",
      "epoch: 73, time: 2001.341s, loss: 0.373, train accuracy: 0.859\n",
      "epoch: 73, time: 2002.651s, loss: 0.421, train accuracy: 0.836\n",
      "epoch: 73, time: 2003.999s, loss: 0.285, train accuracy: 0.906\n",
      "epoch: 73, time: 2005.330s, loss: 0.478, train accuracy: 0.828\n",
      "epoch: 73, time: 2006.638s, loss: 0.340, train accuracy: 0.891\n",
      "epoch: 73, time: 2007.957s, loss: 0.375, train accuracy: 0.859\n",
      "epoch: 73, time: 2009.334s, loss: 0.370, train accuracy: 0.859\n",
      "epoch: 73, time: 2010.635s, loss: 0.343, train accuracy: 0.883\n",
      "epoch: 73, time: 2011.924s, loss: 0.286, train accuracy: 0.914\n",
      "epoch: 73, time: 2013.251s, loss: 0.325, train accuracy: 0.875\n",
      "epoch: 73, time: 2014.555s, loss: 0.372, train accuracy: 0.867\n",
      "epoch: 73, time: 2015.859s, loss: 0.283, train accuracy: 0.883\n",
      "epoch: 73, time: 2017.183s, loss: 0.671, train accuracy: 0.828\n",
      "epoch: 73, time: 2018.495s, loss: 0.278, train accuracy: 0.883\n",
      "epoch: 73, time: 2019.785s, loss: 0.369, train accuracy: 0.852\n",
      "Accuracy on the test set: 0.831\n",
      "epoch: 74, time: 2022.768s, loss: 0.386, train accuracy: 0.844\n",
      "epoch: 74, time: 2024.086s, loss: 0.498, train accuracy: 0.828\n",
      "epoch: 74, time: 2025.411s, loss: 0.249, train accuracy: 0.938\n",
      "epoch: 74, time: 2026.735s, loss: 0.366, train accuracy: 0.836\n",
      "epoch: 74, time: 2028.048s, loss: 0.318, train accuracy: 0.883\n",
      "epoch: 74, time: 2029.356s, loss: 0.384, train accuracy: 0.844\n",
      "epoch: 74, time: 2030.659s, loss: 0.280, train accuracy: 0.883\n",
      "epoch: 74, time: 2031.960s, loss: 0.314, train accuracy: 0.883\n",
      "epoch: 74, time: 2033.284s, loss: 0.364, train accuracy: 0.859\n",
      "epoch: 74, time: 2034.592s, loss: 0.249, train accuracy: 0.922\n",
      "epoch: 74, time: 2035.912s, loss: 0.363, train accuracy: 0.859\n",
      "epoch: 74, time: 2037.274s, loss: 0.303, train accuracy: 0.898\n",
      "epoch: 74, time: 2038.578s, loss: 0.386, train accuracy: 0.875\n",
      "epoch: 74, time: 2039.882s, loss: 0.343, train accuracy: 0.859\n",
      "epoch: 74, time: 2041.187s, loss: 0.444, train accuracy: 0.844\n",
      "epoch: 74, time: 2042.486s, loss: 0.306, train accuracy: 0.875\n",
      "epoch: 74, time: 2043.799s, loss: 0.286, train accuracy: 0.938\n",
      "epoch: 74, time: 2045.123s, loss: 0.324, train accuracy: 0.914\n",
      "epoch: 74, time: 2046.439s, loss: 0.247, train accuracy: 0.922\n",
      "epoch: 74, time: 2047.768s, loss: 0.457, train accuracy: 0.844\n",
      "Accuracy on the test set: 0.827\n",
      "epoch: 75, time: 2050.709s, loss: 0.305, train accuracy: 0.891\n",
      "epoch: 75, time: 2052.017s, loss: 0.385, train accuracy: 0.859\n",
      "epoch: 75, time: 2053.325s, loss: 0.273, train accuracy: 0.898\n",
      "epoch: 75, time: 2054.658s, loss: 0.273, train accuracy: 0.914\n",
      "epoch: 75, time: 2055.950s, loss: 0.337, train accuracy: 0.867\n",
      "epoch: 75, time: 2057.245s, loss: 0.467, train accuracy: 0.828\n",
      "epoch: 75, time: 2058.541s, loss: 0.401, train accuracy: 0.867\n",
      "epoch: 75, time: 2059.835s, loss: 0.423, train accuracy: 0.859\n",
      "epoch: 75, time: 2061.145s, loss: 0.287, train accuracy: 0.891\n",
      "epoch: 75, time: 2062.472s, loss: 0.368, train accuracy: 0.883\n",
      "epoch: 75, time: 2063.790s, loss: 0.428, train accuracy: 0.867\n",
      "epoch: 75, time: 2065.092s, loss: 0.272, train accuracy: 0.922\n",
      "epoch: 75, time: 2066.384s, loss: 0.733, train accuracy: 0.742\n",
      "epoch: 75, time: 2067.680s, loss: 0.523, train accuracy: 0.812\n",
      "epoch: 75, time: 2068.991s, loss: 0.392, train accuracy: 0.844\n",
      "epoch: 75, time: 2070.283s, loss: 0.407, train accuracy: 0.875\n",
      "epoch: 75, time: 2071.597s, loss: 0.501, train accuracy: 0.844\n",
      "epoch: 75, time: 2072.904s, loss: 0.529, train accuracy: 0.820\n",
      "epoch: 75, time: 2074.240s, loss: 0.511, train accuracy: 0.844\n",
      "epoch: 75, time: 2075.551s, loss: 0.375, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.817\n",
      "epoch: 76, time: 2078.542s, loss: 0.404, train accuracy: 0.844\n",
      "epoch: 76, time: 2079.867s, loss: 0.438, train accuracy: 0.891\n",
      "epoch: 76, time: 2081.170s, loss: 0.434, train accuracy: 0.844\n",
      "epoch: 76, time: 2082.501s, loss: 0.289, train accuracy: 0.883\n",
      "epoch: 76, time: 2083.873s, loss: 0.443, train accuracy: 0.875\n",
      "epoch: 76, time: 2085.217s, loss: 0.465, train accuracy: 0.844\n",
      "epoch: 76, time: 2086.528s, loss: 0.339, train accuracy: 0.891\n",
      "epoch: 76, time: 2087.844s, loss: 0.391, train accuracy: 0.859\n",
      "epoch: 76, time: 2089.182s, loss: 0.443, train accuracy: 0.820\n",
      "epoch: 76, time: 2090.504s, loss: 0.378, train accuracy: 0.852\n",
      "epoch: 76, time: 2091.807s, loss: 0.456, train accuracy: 0.836\n",
      "epoch: 76, time: 2093.116s, loss: 0.365, train accuracy: 0.883\n",
      "epoch: 76, time: 2094.424s, loss: 0.369, train accuracy: 0.844\n",
      "epoch: 76, time: 2095.758s, loss: 0.312, train accuracy: 0.898\n",
      "epoch: 76, time: 2097.075s, loss: 0.409, train accuracy: 0.875\n",
      "epoch: 76, time: 2098.396s, loss: 0.376, train accuracy: 0.875\n",
      "epoch: 76, time: 2099.693s, loss: 0.336, train accuracy: 0.898\n",
      "epoch: 76, time: 2100.982s, loss: 0.317, train accuracy: 0.875\n",
      "epoch: 76, time: 2102.275s, loss: 0.339, train accuracy: 0.867\n",
      "epoch: 76, time: 2103.592s, loss: 0.323, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.835\n",
      "epoch: 77, time: 2106.529s, loss: 0.292, train accuracy: 0.898\n",
      "epoch: 77, time: 2107.841s, loss: 0.277, train accuracy: 0.891\n",
      "epoch: 77, time: 2109.197s, loss: 0.350, train accuracy: 0.875\n",
      "epoch: 77, time: 2110.509s, loss: 0.339, train accuracy: 0.875\n",
      "epoch: 77, time: 2111.816s, loss: 0.297, train accuracy: 0.867\n",
      "epoch: 77, time: 2113.113s, loss: 0.349, train accuracy: 0.891\n",
      "epoch: 77, time: 2114.407s, loss: 0.340, train accuracy: 0.898\n",
      "epoch: 77, time: 2115.753s, loss: 0.378, train accuracy: 0.859\n",
      "epoch: 77, time: 2117.053s, loss: 0.362, train accuracy: 0.852\n",
      "epoch: 77, time: 2118.347s, loss: 0.328, train accuracy: 0.875\n",
      "epoch: 77, time: 2119.665s, loss: 0.212, train accuracy: 0.906\n",
      "epoch: 77, time: 2121.003s, loss: 0.406, train accuracy: 0.859\n",
      "epoch: 77, time: 2122.308s, loss: 0.225, train accuracy: 0.938\n",
      "epoch: 77, time: 2123.607s, loss: 0.406, train accuracy: 0.844\n",
      "epoch: 77, time: 2124.907s, loss: 0.383, train accuracy: 0.875\n",
      "epoch: 77, time: 2126.200s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 77, time: 2127.496s, loss: 0.344, train accuracy: 0.891\n",
      "epoch: 77, time: 2128.837s, loss: 0.323, train accuracy: 0.875\n",
      "epoch: 77, time: 2130.151s, loss: 0.243, train accuracy: 0.906\n",
      "epoch: 77, time: 2131.467s, loss: 0.340, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 78, time: 2134.429s, loss: 0.347, train accuracy: 0.898\n",
      "epoch: 78, time: 2135.766s, loss: 0.403, train accuracy: 0.867\n",
      "epoch: 78, time: 2137.074s, loss: 0.318, train accuracy: 0.875\n",
      "epoch: 78, time: 2138.380s, loss: 0.565, train accuracy: 0.844\n",
      "epoch: 78, time: 2139.687s, loss: 0.213, train accuracy: 0.898\n",
      "epoch: 78, time: 2140.980s, loss: 0.382, train accuracy: 0.891\n",
      "epoch: 78, time: 2142.271s, loss: 0.437, train accuracy: 0.820\n",
      "epoch: 78, time: 2143.591s, loss: 0.392, train accuracy: 0.828\n",
      "epoch: 78, time: 2144.884s, loss: 0.254, train accuracy: 0.898\n",
      "epoch: 78, time: 2146.203s, loss: 0.296, train accuracy: 0.891\n",
      "epoch: 78, time: 2147.506s, loss: 0.387, train accuracy: 0.875\n",
      "epoch: 78, time: 2148.816s, loss: 0.252, train accuracy: 0.906\n",
      "epoch: 78, time: 2150.141s, loss: 0.364, train accuracy: 0.875\n",
      "epoch: 78, time: 2151.456s, loss: 0.379, train accuracy: 0.883\n",
      "epoch: 78, time: 2152.752s, loss: 0.272, train accuracy: 0.891\n",
      "epoch: 78, time: 2154.072s, loss: 0.327, train accuracy: 0.883\n",
      "epoch: 78, time: 2155.366s, loss: 0.344, train accuracy: 0.875\n",
      "epoch: 78, time: 2156.660s, loss: 0.293, train accuracy: 0.906\n",
      "epoch: 78, time: 2157.957s, loss: 0.394, train accuracy: 0.844\n",
      "epoch: 78, time: 2159.262s, loss: 0.256, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.834\n",
      "epoch: 79, time: 2162.193s, loss: 0.370, train accuracy: 0.891\n",
      "epoch: 79, time: 2163.506s, loss: 0.278, train accuracy: 0.891\n",
      "epoch: 79, time: 2164.800s, loss: 0.300, train accuracy: 0.891\n",
      "epoch: 79, time: 2166.106s, loss: 0.290, train accuracy: 0.891\n",
      "epoch: 79, time: 2167.422s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 79, time: 2168.718s, loss: 0.264, train accuracy: 0.922\n",
      "epoch: 79, time: 2170.043s, loss: 0.399, train accuracy: 0.859\n",
      "epoch: 79, time: 2171.356s, loss: 0.325, train accuracy: 0.867\n",
      "epoch: 79, time: 2172.677s, loss: 0.302, train accuracy: 0.922\n",
      "epoch: 79, time: 2173.983s, loss: 0.267, train accuracy: 0.898\n",
      "epoch: 79, time: 2175.284s, loss: 0.188, train accuracy: 0.938\n",
      "epoch: 79, time: 2176.584s, loss: 0.426, train accuracy: 0.859\n",
      "epoch: 79, time: 2177.895s, loss: 0.316, train accuracy: 0.883\n",
      "epoch: 79, time: 2179.215s, loss: 0.357, train accuracy: 0.867\n",
      "epoch: 79, time: 2180.527s, loss: 0.224, train accuracy: 0.930\n",
      "epoch: 79, time: 2181.818s, loss: 0.412, train accuracy: 0.844\n",
      "epoch: 79, time: 2183.113s, loss: 0.321, train accuracy: 0.859\n",
      "epoch: 79, time: 2184.406s, loss: 0.345, train accuracy: 0.852\n",
      "epoch: 79, time: 2185.706s, loss: 0.222, train accuracy: 0.914\n",
      "epoch: 79, time: 2186.997s, loss: 0.316, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 80, time: 2190.062s, loss: 0.347, train accuracy: 0.906\n",
      "epoch: 80, time: 2191.383s, loss: 0.283, train accuracy: 0.930\n",
      "epoch: 80, time: 2192.682s, loss: 0.297, train accuracy: 0.898\n",
      "epoch: 80, time: 2193.997s, loss: 0.190, train accuracy: 0.930\n",
      "epoch: 80, time: 2195.312s, loss: 0.322, train accuracy: 0.891\n",
      "epoch: 80, time: 2196.611s, loss: 0.278, train accuracy: 0.883\n",
      "epoch: 80, time: 2197.904s, loss: 0.342, train accuracy: 0.852\n",
      "epoch: 80, time: 2199.221s, loss: 0.361, train accuracy: 0.859\n",
      "epoch: 80, time: 2200.583s, loss: 0.319, train accuracy: 0.906\n",
      "epoch: 80, time: 2201.946s, loss: 0.264, train accuracy: 0.875\n",
      "epoch: 80, time: 2203.256s, loss: 0.538, train accuracy: 0.828\n",
      "epoch: 80, time: 2204.577s, loss: 0.682, train accuracy: 0.797\n",
      "epoch: 80, time: 2205.885s, loss: 0.397, train accuracy: 0.859\n",
      "epoch: 80, time: 2207.222s, loss: 0.394, train accuracy: 0.883\n",
      "epoch: 80, time: 2208.531s, loss: 0.346, train accuracy: 0.883\n",
      "epoch: 80, time: 2209.885s, loss: 0.467, train accuracy: 0.812\n",
      "epoch: 80, time: 2211.182s, loss: 0.343, train accuracy: 0.906\n",
      "epoch: 80, time: 2212.503s, loss: 0.422, train accuracy: 0.867\n",
      "epoch: 80, time: 2213.801s, loss: 0.494, train accuracy: 0.812\n",
      "epoch: 80, time: 2215.123s, loss: 0.430, train accuracy: 0.820\n",
      "Accuracy on the test set: 0.828\n",
      "epoch: 81, time: 2218.087s, loss: 0.464, train accuracy: 0.820\n",
      "epoch: 81, time: 2219.459s, loss: 0.288, train accuracy: 0.898\n",
      "epoch: 81, time: 2220.794s, loss: 0.341, train accuracy: 0.883\n",
      "epoch: 81, time: 2222.120s, loss: 0.291, train accuracy: 0.875\n",
      "epoch: 81, time: 2223.418s, loss: 0.427, train accuracy: 0.867\n",
      "epoch: 81, time: 2224.748s, loss: 0.499, train accuracy: 0.836\n",
      "epoch: 81, time: 2226.042s, loss: 0.389, train accuracy: 0.875\n",
      "epoch: 81, time: 2227.358s, loss: 0.457, train accuracy: 0.852\n",
      "epoch: 81, time: 2228.680s, loss: 0.311, train accuracy: 0.891\n",
      "epoch: 81, time: 2229.983s, loss: 0.456, train accuracy: 0.875\n",
      "epoch: 81, time: 2231.304s, loss: 0.405, train accuracy: 0.852\n",
      "epoch: 81, time: 2232.624s, loss: 0.327, train accuracy: 0.891\n",
      "epoch: 81, time: 2233.933s, loss: 0.297, train accuracy: 0.875\n",
      "epoch: 81, time: 2235.224s, loss: 0.449, train accuracy: 0.852\n",
      "epoch: 81, time: 2236.577s, loss: 0.395, train accuracy: 0.844\n",
      "epoch: 81, time: 2237.903s, loss: 0.278, train accuracy: 0.914\n",
      "epoch: 81, time: 2239.217s, loss: 0.443, train accuracy: 0.836\n",
      "epoch: 81, time: 2240.554s, loss: 0.313, train accuracy: 0.891\n",
      "epoch: 81, time: 2241.876s, loss: 0.290, train accuracy: 0.883\n",
      "epoch: 81, time: 2243.178s, loss: 0.310, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.832\n",
      "epoch: 82, time: 2246.135s, loss: 0.442, train accuracy: 0.828\n",
      "epoch: 82, time: 2247.479s, loss: 0.344, train accuracy: 0.883\n",
      "epoch: 82, time: 2248.806s, loss: 0.334, train accuracy: 0.875\n",
      "epoch: 82, time: 2250.109s, loss: 0.614, train accuracy: 0.812\n",
      "epoch: 82, time: 2251.437s, loss: 0.806, train accuracy: 0.719\n",
      "epoch: 82, time: 2252.729s, loss: 0.480, train accuracy: 0.852\n",
      "epoch: 82, time: 2254.045s, loss: 0.602, train accuracy: 0.828\n",
      "epoch: 82, time: 2255.396s, loss: 0.466, train accuracy: 0.820\n",
      "epoch: 82, time: 2256.727s, loss: 0.426, train accuracy: 0.836\n",
      "epoch: 82, time: 2258.055s, loss: 0.444, train accuracy: 0.844\n",
      "epoch: 82, time: 2259.377s, loss: 0.543, train accuracy: 0.805\n",
      "epoch: 82, time: 2260.794s, loss: 0.506, train accuracy: 0.844\n",
      "epoch: 82, time: 2262.112s, loss: 0.470, train accuracy: 0.836\n",
      "epoch: 82, time: 2263.405s, loss: 0.403, train accuracy: 0.867\n",
      "epoch: 82, time: 2264.724s, loss: 0.415, train accuracy: 0.852\n",
      "epoch: 82, time: 2266.071s, loss: 0.241, train accuracy: 0.930\n",
      "epoch: 82, time: 2267.386s, loss: 0.403, train accuracy: 0.883\n",
      "epoch: 82, time: 2268.681s, loss: 0.357, train accuracy: 0.859\n",
      "epoch: 82, time: 2269.980s, loss: 0.411, train accuracy: 0.852\n",
      "epoch: 82, time: 2271.307s, loss: 0.257, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.834\n",
      "epoch: 83, time: 2274.221s, loss: 0.371, train accuracy: 0.875\n",
      "epoch: 83, time: 2275.542s, loss: 0.322, train accuracy: 0.852\n",
      "epoch: 83, time: 2276.857s, loss: 0.456, train accuracy: 0.867\n",
      "epoch: 83, time: 2278.147s, loss: 0.410, train accuracy: 0.852\n",
      "epoch: 83, time: 2279.464s, loss: 0.398, train accuracy: 0.852\n",
      "epoch: 83, time: 2280.792s, loss: 0.303, train accuracy: 0.891\n",
      "epoch: 83, time: 2282.133s, loss: 0.307, train accuracy: 0.914\n",
      "epoch: 83, time: 2283.424s, loss: 0.388, train accuracy: 0.852\n",
      "epoch: 83, time: 2284.763s, loss: 0.548, train accuracy: 0.758\n",
      "epoch: 83, time: 2286.049s, loss: 0.365, train accuracy: 0.867\n",
      "epoch: 83, time: 2287.344s, loss: 0.405, train accuracy: 0.867\n",
      "epoch: 83, time: 2288.661s, loss: 0.313, train accuracy: 0.906\n",
      "epoch: 83, time: 2289.970s, loss: 0.362, train accuracy: 0.867\n",
      "epoch: 83, time: 2291.259s, loss: 0.371, train accuracy: 0.891\n",
      "epoch: 83, time: 2292.570s, loss: 0.345, train accuracy: 0.906\n",
      "epoch: 83, time: 2293.865s, loss: 0.446, train accuracy: 0.836\n",
      "epoch: 83, time: 2295.177s, loss: 0.363, train accuracy: 0.883\n",
      "epoch: 83, time: 2296.495s, loss: 0.427, train accuracy: 0.852\n",
      "epoch: 83, time: 2297.792s, loss: 0.348, train accuracy: 0.867\n",
      "epoch: 83, time: 2299.115s, loss: 0.414, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.834\n",
      "epoch: 84, time: 2302.058s, loss: 0.295, train accuracy: 0.906\n",
      "epoch: 84, time: 2303.407s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 84, time: 2304.704s, loss: 0.231, train accuracy: 0.922\n",
      "epoch: 84, time: 2306.046s, loss: 0.465, train accuracy: 0.812\n",
      "epoch: 84, time: 2307.349s, loss: 0.421, train accuracy: 0.852\n",
      "epoch: 84, time: 2308.671s, loss: 0.424, train accuracy: 0.828\n",
      "epoch: 84, time: 2309.971s, loss: 0.286, train accuracy: 0.898\n",
      "epoch: 84, time: 2311.290s, loss: 0.203, train accuracy: 0.930\n",
      "epoch: 84, time: 2312.602s, loss: 0.335, train accuracy: 0.883\n",
      "epoch: 84, time: 2313.923s, loss: 0.296, train accuracy: 0.891\n",
      "epoch: 84, time: 2315.213s, loss: 0.402, train accuracy: 0.844\n",
      "epoch: 84, time: 2316.531s, loss: 0.318, train accuracy: 0.875\n",
      "epoch: 84, time: 2317.847s, loss: 0.306, train accuracy: 0.914\n",
      "epoch: 84, time: 2319.178s, loss: 0.299, train accuracy: 0.898\n",
      "epoch: 84, time: 2320.497s, loss: 0.371, train accuracy: 0.859\n",
      "epoch: 84, time: 2321.788s, loss: 0.323, train accuracy: 0.891\n",
      "epoch: 84, time: 2323.086s, loss: 0.269, train accuracy: 0.930\n",
      "epoch: 84, time: 2324.385s, loss: 0.245, train accuracy: 0.922\n",
      "epoch: 84, time: 2325.720s, loss: 0.321, train accuracy: 0.875\n",
      "epoch: 84, time: 2327.062s, loss: 0.362, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 85, time: 2329.972s, loss: 0.339, train accuracy: 0.859\n",
      "epoch: 85, time: 2331.327s, loss: 0.295, train accuracy: 0.891\n",
      "epoch: 85, time: 2332.625s, loss: 0.226, train accuracy: 0.922\n",
      "epoch: 85, time: 2333.940s, loss: 0.217, train accuracy: 0.938\n",
      "epoch: 85, time: 2335.287s, loss: 0.352, train accuracy: 0.875\n",
      "epoch: 85, time: 2336.586s, loss: 0.265, train accuracy: 0.891\n",
      "epoch: 85, time: 2337.881s, loss: 0.281, train accuracy: 0.891\n",
      "epoch: 85, time: 2339.175s, loss: 0.366, train accuracy: 0.875\n",
      "epoch: 85, time: 2340.539s, loss: 0.356, train accuracy: 0.875\n",
      "epoch: 85, time: 2341.832s, loss: 0.198, train accuracy: 0.914\n",
      "epoch: 85, time: 2343.133s, loss: 0.243, train accuracy: 0.906\n",
      "epoch: 85, time: 2344.427s, loss: 0.260, train accuracy: 0.938\n",
      "epoch: 85, time: 2345.792s, loss: 0.320, train accuracy: 0.906\n",
      "epoch: 85, time: 2347.106s, loss: 0.216, train accuracy: 0.914\n",
      "epoch: 85, time: 2348.419s, loss: 0.240, train accuracy: 0.938\n",
      "epoch: 85, time: 2349.754s, loss: 0.303, train accuracy: 0.914\n",
      "epoch: 85, time: 2351.079s, loss: 0.287, train accuracy: 0.898\n",
      "epoch: 85, time: 2352.373s, loss: 0.270, train accuracy: 0.930\n",
      "epoch: 85, time: 2353.670s, loss: 0.223, train accuracy: 0.922\n",
      "epoch: 85, time: 2354.970s, loss: 0.314, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 86, time: 2357.950s, loss: 0.225, train accuracy: 0.930\n",
      "epoch: 86, time: 2359.291s, loss: 0.290, train accuracy: 0.898\n",
      "epoch: 86, time: 2360.631s, loss: 0.686, train accuracy: 0.812\n",
      "epoch: 86, time: 2361.966s, loss: 0.585, train accuracy: 0.766\n",
      "epoch: 86, time: 2363.314s, loss: 0.489, train accuracy: 0.820\n",
      "epoch: 86, time: 2364.672s, loss: 0.545, train accuracy: 0.828\n",
      "epoch: 86, time: 2365.988s, loss: 0.389, train accuracy: 0.820\n",
      "epoch: 86, time: 2367.286s, loss: 0.301, train accuracy: 0.883\n",
      "epoch: 86, time: 2368.583s, loss: 0.459, train accuracy: 0.820\n",
      "epoch: 86, time: 2369.915s, loss: 0.354, train accuracy: 0.891\n",
      "epoch: 86, time: 2371.224s, loss: 0.383, train accuracy: 0.867\n",
      "epoch: 86, time: 2372.512s, loss: 0.231, train accuracy: 0.906\n",
      "epoch: 86, time: 2373.814s, loss: 0.348, train accuracy: 0.898\n",
      "epoch: 86, time: 2375.170s, loss: 0.180, train accuracy: 0.930\n",
      "epoch: 86, time: 2376.466s, loss: 0.307, train accuracy: 0.867\n",
      "epoch: 86, time: 2377.765s, loss: 0.268, train accuracy: 0.914\n",
      "epoch: 86, time: 2379.055s, loss: 0.355, train accuracy: 0.859\n",
      "epoch: 86, time: 2380.358s, loss: 0.382, train accuracy: 0.891\n",
      "epoch: 86, time: 2381.673s, loss: 0.328, train accuracy: 0.875\n",
      "epoch: 86, time: 2382.993s, loss: 0.290, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 87, time: 2385.933s, loss: 0.366, train accuracy: 0.828\n",
      "epoch: 87, time: 2387.251s, loss: 0.317, train accuracy: 0.875\n",
      "epoch: 87, time: 2388.545s, loss: 0.377, train accuracy: 0.875\n",
      "epoch: 87, time: 2389.881s, loss: 0.320, train accuracy: 0.891\n",
      "epoch: 87, time: 2391.194s, loss: 0.279, train accuracy: 0.883\n",
      "epoch: 87, time: 2392.522s, loss: 0.333, train accuracy: 0.859\n",
      "epoch: 87, time: 2393.827s, loss: 0.294, train accuracy: 0.867\n",
      "epoch: 87, time: 2395.127s, loss: 0.275, train accuracy: 0.898\n",
      "epoch: 87, time: 2396.436s, loss: 0.431, train accuracy: 0.836\n",
      "epoch: 87, time: 2397.746s, loss: 0.314, train accuracy: 0.875\n",
      "epoch: 87, time: 2399.062s, loss: 0.433, train accuracy: 0.828\n",
      "epoch: 87, time: 2400.399s, loss: 0.210, train accuracy: 0.930\n",
      "epoch: 87, time: 2401.721s, loss: 0.302, train accuracy: 0.883\n",
      "epoch: 87, time: 2403.033s, loss: 0.357, train accuracy: 0.867\n",
      "epoch: 87, time: 2404.330s, loss: 0.237, train accuracy: 0.938\n",
      "epoch: 87, time: 2405.674s, loss: 0.376, train accuracy: 0.891\n",
      "epoch: 87, time: 2406.974s, loss: 0.398, train accuracy: 0.844\n",
      "epoch: 87, time: 2408.292s, loss: 0.469, train accuracy: 0.812\n",
      "epoch: 87, time: 2409.606s, loss: 0.213, train accuracy: 0.922\n",
      "epoch: 87, time: 2410.920s, loss: 0.293, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 88, time: 2413.842s, loss: 0.396, train accuracy: 0.875\n",
      "epoch: 88, time: 2415.156s, loss: 0.408, train accuracy: 0.859\n",
      "epoch: 88, time: 2416.477s, loss: 0.371, train accuracy: 0.883\n",
      "epoch: 88, time: 2417.773s, loss: 0.352, train accuracy: 0.875\n",
      "epoch: 88, time: 2419.065s, loss: 0.203, train accuracy: 0.953\n",
      "epoch: 88, time: 2420.389s, loss: 0.236, train accuracy: 0.930\n",
      "epoch: 88, time: 2421.703s, loss: 0.279, train accuracy: 0.914\n",
      "epoch: 88, time: 2423.024s, loss: 0.256, train accuracy: 0.914\n",
      "epoch: 88, time: 2424.324s, loss: 0.359, train accuracy: 0.875\n",
      "epoch: 88, time: 2425.659s, loss: 0.197, train accuracy: 0.945\n",
      "epoch: 88, time: 2426.975s, loss: 0.334, train accuracy: 0.891\n",
      "epoch: 88, time: 2428.288s, loss: 0.255, train accuracy: 0.891\n",
      "epoch: 88, time: 2429.582s, loss: 0.262, train accuracy: 0.922\n",
      "epoch: 88, time: 2430.894s, loss: 0.243, train accuracy: 0.898\n",
      "epoch: 88, time: 2432.188s, loss: 0.374, train accuracy: 0.875\n",
      "epoch: 88, time: 2433.505s, loss: 0.217, train accuracy: 0.922\n",
      "epoch: 88, time: 2434.808s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 88, time: 2436.125s, loss: 0.345, train accuracy: 0.875\n",
      "epoch: 88, time: 2437.472s, loss: 0.272, train accuracy: 0.875\n",
      "epoch: 88, time: 2438.771s, loss: 0.397, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 89, time: 2441.775s, loss: 0.244, train accuracy: 0.898\n",
      "epoch: 89, time: 2443.091s, loss: 0.272, train accuracy: 0.891\n",
      "epoch: 89, time: 2444.408s, loss: 0.409, train accuracy: 0.891\n",
      "epoch: 89, time: 2445.719s, loss: 0.322, train accuracy: 0.891\n",
      "epoch: 89, time: 2447.034s, loss: 0.436, train accuracy: 0.852\n",
      "epoch: 89, time: 2448.373s, loss: 0.261, train accuracy: 0.922\n",
      "epoch: 89, time: 2449.688s, loss: 0.353, train accuracy: 0.852\n",
      "epoch: 89, time: 2450.998s, loss: 0.227, train accuracy: 0.922\n",
      "epoch: 89, time: 2452.320s, loss: 0.323, train accuracy: 0.867\n",
      "epoch: 89, time: 2453.619s, loss: 0.258, train accuracy: 0.914\n",
      "epoch: 89, time: 2454.925s, loss: 0.205, train accuracy: 0.922\n",
      "epoch: 89, time: 2456.241s, loss: 0.381, train accuracy: 0.852\n",
      "epoch: 89, time: 2457.538s, loss: 0.358, train accuracy: 0.875\n",
      "epoch: 89, time: 2458.828s, loss: 0.508, train accuracy: 0.828\n",
      "epoch: 89, time: 2460.133s, loss: 0.322, train accuracy: 0.883\n",
      "epoch: 89, time: 2461.444s, loss: 0.274, train accuracy: 0.867\n",
      "epoch: 89, time: 2462.741s, loss: 0.269, train accuracy: 0.883\n",
      "epoch: 89, time: 2464.037s, loss: 0.460, train accuracy: 0.820\n",
      "epoch: 89, time: 2465.344s, loss: 0.274, train accuracy: 0.922\n",
      "epoch: 89, time: 2466.654s, loss: 0.226, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 90, time: 2469.610s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 90, time: 2470.972s, loss: 0.362, train accuracy: 0.883\n",
      "epoch: 90, time: 2472.287s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 90, time: 2473.598s, loss: 0.271, train accuracy: 0.883\n",
      "epoch: 90, time: 2474.903s, loss: 0.374, train accuracy: 0.906\n",
      "epoch: 90, time: 2476.205s, loss: 0.349, train accuracy: 0.852\n",
      "epoch: 90, time: 2477.511s, loss: 0.274, train accuracy: 0.938\n",
      "epoch: 90, time: 2478.876s, loss: 0.272, train accuracy: 0.898\n",
      "epoch: 90, time: 2480.189s, loss: 0.309, train accuracy: 0.883\n",
      "epoch: 90, time: 2481.495s, loss: 0.362, train accuracy: 0.852\n",
      "epoch: 90, time: 2482.837s, loss: 0.182, train accuracy: 0.938\n",
      "epoch: 90, time: 2484.196s, loss: 0.275, train accuracy: 0.883\n",
      "epoch: 90, time: 2485.533s, loss: 0.180, train accuracy: 0.914\n",
      "epoch: 90, time: 2486.912s, loss: 0.294, train accuracy: 0.883\n",
      "epoch: 90, time: 2488.207s, loss: 0.300, train accuracy: 0.883\n",
      "epoch: 90, time: 2489.527s, loss: 0.375, train accuracy: 0.875\n",
      "epoch: 90, time: 2490.859s, loss: 0.338, train accuracy: 0.906\n",
      "epoch: 90, time: 2492.162s, loss: 0.236, train accuracy: 0.906\n",
      "epoch: 90, time: 2493.505s, loss: 0.357, train accuracy: 0.883\n",
      "epoch: 90, time: 2494.795s, loss: 0.349, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 91, time: 2497.819s, loss: 0.191, train accuracy: 0.930\n",
      "epoch: 91, time: 2499.155s, loss: 0.204, train accuracy: 0.961\n",
      "epoch: 91, time: 2500.476s, loss: 0.219, train accuracy: 0.938\n",
      "epoch: 91, time: 2501.800s, loss: 0.204, train accuracy: 0.914\n",
      "epoch: 91, time: 2503.099s, loss: 0.136, train accuracy: 0.953\n",
      "epoch: 91, time: 2504.399s, loss: 0.312, train accuracy: 0.883\n",
      "epoch: 91, time: 2505.714s, loss: 0.308, train accuracy: 0.906\n",
      "epoch: 91, time: 2507.031s, loss: 0.349, train accuracy: 0.898\n",
      "epoch: 91, time: 2508.325s, loss: 0.249, train accuracy: 0.906\n",
      "epoch: 91, time: 2509.681s, loss: 0.288, train accuracy: 0.898\n",
      "epoch: 91, time: 2510.994s, loss: 0.285, train accuracy: 0.891\n",
      "epoch: 91, time: 2512.311s, loss: 0.318, train accuracy: 0.883\n",
      "epoch: 91, time: 2513.616s, loss: 0.532, train accuracy: 0.797\n",
      "epoch: 91, time: 2514.928s, loss: 0.188, train accuracy: 0.953\n",
      "epoch: 91, time: 2516.225s, loss: 0.321, train accuracy: 0.891\n",
      "epoch: 91, time: 2517.525s, loss: 0.318, train accuracy: 0.883\n",
      "epoch: 91, time: 2518.835s, loss: 0.298, train accuracy: 0.891\n",
      "epoch: 91, time: 2520.135s, loss: 0.348, train accuracy: 0.891\n",
      "epoch: 91, time: 2521.459s, loss: 0.302, train accuracy: 0.891\n",
      "epoch: 91, time: 2522.769s, loss: 0.551, train accuracy: 0.797\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 92, time: 2525.658s, loss: 0.370, train accuracy: 0.859\n",
      "epoch: 92, time: 2526.981s, loss: 0.259, train accuracy: 0.891\n",
      "epoch: 92, time: 2528.330s, loss: 0.348, train accuracy: 0.883\n",
      "epoch: 92, time: 2529.639s, loss: 0.326, train accuracy: 0.867\n",
      "epoch: 92, time: 2530.983s, loss: 0.463, train accuracy: 0.875\n",
      "epoch: 92, time: 2532.303s, loss: 0.229, train accuracy: 0.914\n",
      "epoch: 92, time: 2533.609s, loss: 0.262, train accuracy: 0.914\n",
      "epoch: 92, time: 2534.926s, loss: 0.208, train accuracy: 0.906\n",
      "epoch: 92, time: 2536.220s, loss: 0.204, train accuracy: 0.930\n",
      "epoch: 92, time: 2537.520s, loss: 0.256, train accuracy: 0.891\n",
      "epoch: 92, time: 2538.826s, loss: 0.253, train accuracy: 0.922\n",
      "epoch: 92, time: 2540.128s, loss: 0.267, train accuracy: 0.883\n",
      "epoch: 92, time: 2541.442s, loss: 0.222, train accuracy: 0.906\n",
      "epoch: 92, time: 2542.738s, loss: 0.428, train accuracy: 0.836\n",
      "epoch: 92, time: 2544.054s, loss: 0.248, train accuracy: 0.922\n",
      "epoch: 92, time: 2545.347s, loss: 0.361, train accuracy: 0.867\n",
      "epoch: 92, time: 2546.653s, loss: 0.300, train accuracy: 0.891\n",
      "epoch: 92, time: 2547.955s, loss: 0.286, train accuracy: 0.891\n",
      "epoch: 92, time: 2549.254s, loss: 0.311, train accuracy: 0.883\n",
      "epoch: 92, time: 2550.566s, loss: 0.293, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.829\n",
      "epoch: 93, time: 2553.528s, loss: 0.347, train accuracy: 0.883\n",
      "epoch: 93, time: 2554.858s, loss: 0.243, train accuracy: 0.922\n",
      "epoch: 93, time: 2556.169s, loss: 0.160, train accuracy: 0.953\n",
      "epoch: 93, time: 2557.486s, loss: 0.183, train accuracy: 0.922\n",
      "epoch: 93, time: 2558.828s, loss: 0.315, train accuracy: 0.867\n",
      "epoch: 93, time: 2560.124s, loss: 0.251, train accuracy: 0.914\n",
      "epoch: 93, time: 2561.476s, loss: 0.183, train accuracy: 0.930\n",
      "epoch: 93, time: 2562.808s, loss: 0.307, train accuracy: 0.883\n",
      "epoch: 93, time: 2564.114s, loss: 0.254, train accuracy: 0.930\n",
      "epoch: 93, time: 2565.425s, loss: 0.233, train accuracy: 0.938\n",
      "epoch: 93, time: 2566.718s, loss: 0.299, train accuracy: 0.906\n",
      "epoch: 93, time: 2568.017s, loss: 0.235, train accuracy: 0.906\n",
      "epoch: 93, time: 2569.322s, loss: 0.189, train accuracy: 0.906\n",
      "epoch: 93, time: 2570.658s, loss: 0.300, train accuracy: 0.883\n",
      "epoch: 93, time: 2571.995s, loss: 0.245, train accuracy: 0.906\n",
      "epoch: 93, time: 2573.295s, loss: 0.297, train accuracy: 0.891\n",
      "epoch: 93, time: 2574.609s, loss: 0.264, train accuracy: 0.906\n",
      "epoch: 93, time: 2575.907s, loss: 0.378, train accuracy: 0.867\n",
      "epoch: 93, time: 2577.225s, loss: 0.303, train accuracy: 0.859\n",
      "epoch: 93, time: 2578.526s, loss: 0.306, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 94, time: 2581.486s, loss: 0.314, train accuracy: 0.906\n",
      "epoch: 94, time: 2582.830s, loss: 0.202, train accuracy: 0.922\n",
      "epoch: 94, time: 2584.133s, loss: 0.266, train accuracy: 0.906\n",
      "epoch: 94, time: 2585.445s, loss: 0.417, train accuracy: 0.859\n",
      "epoch: 94, time: 2586.755s, loss: 0.195, train accuracy: 0.945\n",
      "epoch: 94, time: 2588.105s, loss: 0.262, train accuracy: 0.914\n",
      "epoch: 94, time: 2589.400s, loss: 0.184, train accuracy: 0.953\n",
      "epoch: 94, time: 2590.737s, loss: 0.251, train accuracy: 0.891\n",
      "epoch: 94, time: 2592.051s, loss: 0.208, train accuracy: 0.945\n",
      "epoch: 94, time: 2593.376s, loss: 0.245, train accuracy: 0.906\n",
      "epoch: 94, time: 2594.707s, loss: 0.341, train accuracy: 0.883\n",
      "epoch: 94, time: 2596.016s, loss: 0.222, train accuracy: 0.938\n",
      "epoch: 94, time: 2597.329s, loss: 0.309, train accuracy: 0.906\n",
      "epoch: 94, time: 2598.702s, loss: 0.281, train accuracy: 0.898\n",
      "epoch: 94, time: 2600.061s, loss: 0.388, train accuracy: 0.891\n",
      "epoch: 94, time: 2601.383s, loss: 0.289, train accuracy: 0.906\n",
      "epoch: 94, time: 2602.683s, loss: 0.354, train accuracy: 0.867\n",
      "epoch: 94, time: 2603.991s, loss: 0.292, train accuracy: 0.883\n",
      "epoch: 94, time: 2605.306s, loss: 0.362, train accuracy: 0.844\n",
      "epoch: 94, time: 2606.627s, loss: 0.323, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.845\n",
      "epoch: 95, time: 2609.644s, loss: 0.204, train accuracy: 0.930\n",
      "epoch: 95, time: 2610.962s, loss: 0.323, train accuracy: 0.906\n",
      "epoch: 95, time: 2612.267s, loss: 0.339, train accuracy: 0.883\n",
      "epoch: 95, time: 2613.626s, loss: 0.335, train accuracy: 0.906\n",
      "epoch: 95, time: 2614.927s, loss: 0.261, train accuracy: 0.891\n",
      "epoch: 95, time: 2616.249s, loss: 0.277, train accuracy: 0.891\n",
      "epoch: 95, time: 2617.573s, loss: 0.277, train accuracy: 0.883\n",
      "epoch: 95, time: 2618.868s, loss: 0.211, train accuracy: 0.930\n",
      "epoch: 95, time: 2620.164s, loss: 0.351, train accuracy: 0.883\n",
      "epoch: 95, time: 2621.459s, loss: 0.332, train accuracy: 0.875\n",
      "epoch: 95, time: 2622.777s, loss: 0.392, train accuracy: 0.867\n",
      "epoch: 95, time: 2624.096s, loss: 0.286, train accuracy: 0.906\n",
      "epoch: 95, time: 2625.408s, loss: 0.317, train accuracy: 0.875\n",
      "epoch: 95, time: 2626.721s, loss: 0.350, train accuracy: 0.867\n",
      "epoch: 95, time: 2628.039s, loss: 0.223, train accuracy: 0.938\n",
      "epoch: 95, time: 2629.357s, loss: 0.358, train accuracy: 0.883\n",
      "epoch: 95, time: 2630.685s, loss: 0.217, train accuracy: 0.930\n",
      "epoch: 95, time: 2632.005s, loss: 0.223, train accuracy: 0.914\n",
      "epoch: 95, time: 2633.314s, loss: 0.326, train accuracy: 0.875\n",
      "epoch: 95, time: 2634.604s, loss: 0.255, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.833\n",
      "epoch: 96, time: 2637.603s, loss: 0.229, train accuracy: 0.906\n",
      "epoch: 96, time: 2638.928s, loss: 0.436, train accuracy: 0.844\n",
      "epoch: 96, time: 2640.230s, loss: 0.356, train accuracy: 0.898\n",
      "epoch: 96, time: 2641.653s, loss: 0.185, train accuracy: 0.938\n",
      "epoch: 96, time: 2642.959s, loss: 0.257, train accuracy: 0.906\n",
      "epoch: 96, time: 2644.272s, loss: 0.435, train accuracy: 0.859\n",
      "epoch: 96, time: 2645.575s, loss: 0.239, train accuracy: 0.930\n",
      "epoch: 96, time: 2646.884s, loss: 0.228, train accuracy: 0.906\n",
      "epoch: 96, time: 2648.178s, loss: 0.371, train accuracy: 0.891\n",
      "epoch: 96, time: 2649.512s, loss: 0.342, train accuracy: 0.859\n",
      "epoch: 96, time: 2650.804s, loss: 0.332, train accuracy: 0.875\n",
      "epoch: 96, time: 2652.119s, loss: 0.394, train accuracy: 0.867\n",
      "epoch: 96, time: 2653.442s, loss: 0.334, train accuracy: 0.883\n",
      "epoch: 96, time: 2654.739s, loss: 0.357, train accuracy: 0.859\n",
      "epoch: 96, time: 2656.060s, loss: 0.293, train accuracy: 0.898\n",
      "epoch: 96, time: 2657.378s, loss: 0.326, train accuracy: 0.891\n",
      "epoch: 96, time: 2658.689s, loss: 0.405, train accuracy: 0.828\n",
      "epoch: 96, time: 2659.998s, loss: 0.315, train accuracy: 0.867\n",
      "epoch: 96, time: 2661.332s, loss: 0.259, train accuracy: 0.898\n",
      "epoch: 96, time: 2662.651s, loss: 0.342, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 97, time: 2665.626s, loss: 0.267, train accuracy: 0.922\n",
      "epoch: 97, time: 2666.952s, loss: 0.214, train accuracy: 0.914\n",
      "epoch: 97, time: 2668.261s, loss: 0.249, train accuracy: 0.922\n",
      "epoch: 97, time: 2669.556s, loss: 0.178, train accuracy: 0.953\n",
      "epoch: 97, time: 2670.880s, loss: 0.268, train accuracy: 0.906\n",
      "epoch: 97, time: 2672.177s, loss: 0.358, train accuracy: 0.852\n",
      "epoch: 97, time: 2673.520s, loss: 0.202, train accuracy: 0.914\n",
      "epoch: 97, time: 2674.835s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 97, time: 2676.139s, loss: 0.333, train accuracy: 0.859\n",
      "epoch: 97, time: 2677.449s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 97, time: 2678.744s, loss: 0.329, train accuracy: 0.891\n",
      "epoch: 97, time: 2680.049s, loss: 0.258, train accuracy: 0.922\n",
      "epoch: 97, time: 2681.370s, loss: 0.345, train accuracy: 0.859\n",
      "epoch: 97, time: 2682.676s, loss: 0.242, train accuracy: 0.930\n",
      "epoch: 97, time: 2683.978s, loss: 0.252, train accuracy: 0.906\n",
      "epoch: 97, time: 2685.275s, loss: 0.236, train accuracy: 0.938\n",
      "epoch: 97, time: 2686.601s, loss: 0.332, train accuracy: 0.898\n",
      "epoch: 97, time: 2687.941s, loss: 0.418, train accuracy: 0.859\n",
      "epoch: 97, time: 2689.235s, loss: 0.159, train accuracy: 0.961\n",
      "epoch: 97, time: 2690.531s, loss: 0.191, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 98, time: 2693.480s, loss: 0.281, train accuracy: 0.898\n",
      "epoch: 98, time: 2694.798s, loss: 0.253, train accuracy: 0.930\n",
      "epoch: 98, time: 2696.089s, loss: 0.269, train accuracy: 0.914\n",
      "epoch: 98, time: 2697.398s, loss: 0.379, train accuracy: 0.867\n",
      "epoch: 98, time: 2698.699s, loss: 0.372, train accuracy: 0.844\n",
      "epoch: 98, time: 2699.997s, loss: 0.187, train accuracy: 0.938\n",
      "epoch: 98, time: 2701.312s, loss: 0.407, train accuracy: 0.867\n",
      "epoch: 98, time: 2702.606s, loss: 0.314, train accuracy: 0.891\n",
      "epoch: 98, time: 2703.923s, loss: 0.306, train accuracy: 0.898\n",
      "epoch: 98, time: 2705.233s, loss: 0.205, train accuracy: 0.938\n",
      "epoch: 98, time: 2706.555s, loss: 0.293, train accuracy: 0.906\n",
      "epoch: 98, time: 2707.865s, loss: 0.303, train accuracy: 0.891\n",
      "epoch: 98, time: 2709.190s, loss: 0.365, train accuracy: 0.867\n",
      "epoch: 98, time: 2710.495s, loss: 0.252, train accuracy: 0.891\n",
      "epoch: 98, time: 2711.810s, loss: 0.221, train accuracy: 0.922\n",
      "epoch: 98, time: 2713.125s, loss: 0.274, train accuracy: 0.891\n",
      "epoch: 98, time: 2714.451s, loss: 0.252, train accuracy: 0.898\n",
      "epoch: 98, time: 2715.750s, loss: 0.339, train accuracy: 0.898\n",
      "epoch: 98, time: 2717.078s, loss: 0.370, train accuracy: 0.836\n",
      "epoch: 98, time: 2718.368s, loss: 0.213, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 99, time: 2721.368s, loss: 0.231, train accuracy: 0.906\n",
      "epoch: 99, time: 2722.699s, loss: 0.391, train accuracy: 0.852\n",
      "epoch: 99, time: 2724.012s, loss: 0.282, train accuracy: 0.898\n",
      "epoch: 99, time: 2725.316s, loss: 0.184, train accuracy: 0.930\n",
      "epoch: 99, time: 2726.687s, loss: 0.232, train accuracy: 0.898\n",
      "epoch: 99, time: 2728.012s, loss: 0.293, train accuracy: 0.891\n",
      "epoch: 99, time: 2729.312s, loss: 0.309, train accuracy: 0.883\n",
      "epoch: 99, time: 2730.612s, loss: 0.231, train accuracy: 0.930\n",
      "epoch: 99, time: 2731.937s, loss: 0.361, train accuracy: 0.859\n",
      "epoch: 99, time: 2733.227s, loss: 0.254, train accuracy: 0.906\n",
      "epoch: 99, time: 2734.562s, loss: 0.352, train accuracy: 0.891\n",
      "epoch: 99, time: 2735.875s, loss: 0.260, train accuracy: 0.906\n",
      "epoch: 99, time: 2737.198s, loss: 0.235, train accuracy: 0.906\n",
      "epoch: 99, time: 2738.513s, loss: 0.247, train accuracy: 0.930\n",
      "epoch: 99, time: 2739.881s, loss: 0.393, train accuracy: 0.875\n",
      "epoch: 99, time: 2741.181s, loss: 0.344, train accuracy: 0.875\n",
      "epoch: 99, time: 2742.509s, loss: 0.275, train accuracy: 0.891\n",
      "epoch: 99, time: 2743.806s, loss: 0.238, train accuracy: 0.914\n",
      "epoch: 99, time: 2745.119s, loss: 0.343, train accuracy: 0.906\n",
      "epoch: 99, time: 2746.418s, loss: 0.243, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 100, time: 2749.371s, loss: 0.282, train accuracy: 0.898\n",
      "epoch: 100, time: 2750.710s, loss: 0.235, train accuracy: 0.914\n",
      "epoch: 100, time: 2752.097s, loss: 0.329, train accuracy: 0.891\n",
      "epoch: 100, time: 2753.402s, loss: 0.263, train accuracy: 0.883\n",
      "epoch: 100, time: 2754.721s, loss: 0.382, train accuracy: 0.867\n",
      "epoch: 100, time: 2756.031s, loss: 0.321, train accuracy: 0.883\n",
      "epoch: 100, time: 2757.320s, loss: 0.245, train accuracy: 0.898\n",
      "epoch: 100, time: 2758.635s, loss: 0.278, train accuracy: 0.859\n",
      "epoch: 100, time: 2759.963s, loss: 0.189, train accuracy: 0.945\n",
      "epoch: 100, time: 2761.277s, loss: 0.273, train accuracy: 0.883\n",
      "epoch: 100, time: 2762.592s, loss: 0.243, train accuracy: 0.914\n",
      "epoch: 100, time: 2763.915s, loss: 0.242, train accuracy: 0.906\n",
      "epoch: 100, time: 2765.215s, loss: 0.249, train accuracy: 0.898\n",
      "epoch: 100, time: 2766.562s, loss: 0.313, train accuracy: 0.891\n",
      "epoch: 100, time: 2767.859s, loss: 0.280, train accuracy: 0.898\n",
      "epoch: 100, time: 2769.157s, loss: 0.271, train accuracy: 0.898\n",
      "epoch: 100, time: 2770.469s, loss: 0.268, train accuracy: 0.883\n",
      "epoch: 100, time: 2771.764s, loss: 0.460, train accuracy: 0.859\n",
      "epoch: 100, time: 2773.087s, loss: 0.345, train accuracy: 0.859\n",
      "epoch: 100, time: 2774.384s, loss: 0.327, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 101, time: 2777.358s, loss: 0.273, train accuracy: 0.914\n",
      "epoch: 101, time: 2778.695s, loss: 0.305, train accuracy: 0.914\n",
      "epoch: 101, time: 2780.002s, loss: 0.215, train accuracy: 0.914\n",
      "epoch: 101, time: 2781.298s, loss: 0.212, train accuracy: 0.938\n",
      "epoch: 101, time: 2782.619s, loss: 0.323, train accuracy: 0.891\n",
      "epoch: 101, time: 2783.966s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 101, time: 2785.271s, loss: 0.250, train accuracy: 0.891\n",
      "epoch: 101, time: 2786.585s, loss: 0.356, train accuracy: 0.891\n",
      "epoch: 101, time: 2787.910s, loss: 0.241, train accuracy: 0.898\n",
      "epoch: 101, time: 2789.252s, loss: 0.218, train accuracy: 0.891\n",
      "epoch: 101, time: 2790.583s, loss: 0.270, train accuracy: 0.891\n",
      "epoch: 101, time: 2791.899s, loss: 0.292, train accuracy: 0.898\n",
      "epoch: 101, time: 2793.223s, loss: 0.326, train accuracy: 0.852\n",
      "epoch: 101, time: 2794.559s, loss: 0.242, train accuracy: 0.914\n",
      "epoch: 101, time: 2795.961s, loss: 0.186, train accuracy: 0.945\n",
      "epoch: 101, time: 2797.342s, loss: 0.329, train accuracy: 0.883\n",
      "epoch: 101, time: 2798.714s, loss: 0.380, train accuracy: 0.844\n",
      "epoch: 101, time: 2800.091s, loss: 0.299, train accuracy: 0.898\n",
      "epoch: 101, time: 2801.419s, loss: 0.195, train accuracy: 0.930\n",
      "epoch: 101, time: 2802.766s, loss: 0.273, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.833\n",
      "epoch: 102, time: 2805.682s, loss: 0.328, train accuracy: 0.852\n",
      "epoch: 102, time: 2807.048s, loss: 0.435, train accuracy: 0.836\n",
      "epoch: 102, time: 2808.382s, loss: 0.307, train accuracy: 0.898\n",
      "epoch: 102, time: 2809.711s, loss: 0.369, train accuracy: 0.859\n",
      "epoch: 102, time: 2811.026s, loss: 0.318, train accuracy: 0.883\n",
      "epoch: 102, time: 2812.387s, loss: 0.212, train accuracy: 0.914\n",
      "epoch: 102, time: 2813.707s, loss: 0.297, train accuracy: 0.867\n",
      "epoch: 102, time: 2815.058s, loss: 0.238, train accuracy: 0.906\n",
      "epoch: 102, time: 2816.421s, loss: 0.358, train accuracy: 0.883\n",
      "epoch: 102, time: 2817.795s, loss: 0.365, train accuracy: 0.867\n",
      "epoch: 102, time: 2819.125s, loss: 0.265, train accuracy: 0.898\n",
      "epoch: 102, time: 2820.423s, loss: 0.212, train accuracy: 0.930\n",
      "epoch: 102, time: 2821.722s, loss: 0.334, train accuracy: 0.867\n",
      "epoch: 102, time: 2823.059s, loss: 0.255, train accuracy: 0.922\n",
      "epoch: 102, time: 2824.376s, loss: 0.403, train accuracy: 0.852\n",
      "epoch: 102, time: 2825.706s, loss: 0.237, train accuracy: 0.914\n",
      "epoch: 102, time: 2827.028s, loss: 0.207, train accuracy: 0.922\n",
      "epoch: 102, time: 2828.350s, loss: 0.206, train accuracy: 0.938\n",
      "epoch: 102, time: 2829.700s, loss: 0.204, train accuracy: 0.930\n",
      "epoch: 102, time: 2831.023s, loss: 0.317, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 103, time: 2833.984s, loss: 0.197, train accuracy: 0.914\n",
      "epoch: 103, time: 2835.314s, loss: 0.227, train accuracy: 0.922\n",
      "epoch: 103, time: 2836.644s, loss: 0.265, train accuracy: 0.898\n",
      "epoch: 103, time: 2838.013s, loss: 0.279, train accuracy: 0.898\n",
      "epoch: 103, time: 2839.338s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 103, time: 2840.679s, loss: 0.304, train accuracy: 0.883\n",
      "epoch: 103, time: 2842.086s, loss: 0.269, train accuracy: 0.898\n",
      "epoch: 103, time: 2843.414s, loss: 0.226, train accuracy: 0.945\n",
      "epoch: 103, time: 2844.748s, loss: 0.289, train accuracy: 0.891\n",
      "epoch: 103, time: 2846.066s, loss: 0.368, train accuracy: 0.883\n",
      "epoch: 103, time: 2847.391s, loss: 0.280, train accuracy: 0.898\n",
      "epoch: 103, time: 2848.730s, loss: 0.224, train accuracy: 0.891\n",
      "epoch: 103, time: 2850.055s, loss: 0.181, train accuracy: 0.930\n",
      "epoch: 103, time: 2851.352s, loss: 0.357, train accuracy: 0.875\n",
      "epoch: 103, time: 2852.691s, loss: 0.229, train accuracy: 0.930\n",
      "epoch: 103, time: 2854.007s, loss: 0.253, train accuracy: 0.898\n",
      "epoch: 103, time: 2855.360s, loss: 0.249, train accuracy: 0.922\n",
      "epoch: 103, time: 2856.687s, loss: 0.239, train accuracy: 0.922\n",
      "epoch: 103, time: 2857.984s, loss: 0.368, train accuracy: 0.852\n",
      "epoch: 103, time: 2859.415s, loss: 0.254, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 104, time: 2862.299s, loss: 0.244, train accuracy: 0.898\n",
      "epoch: 104, time: 2863.655s, loss: 0.224, train accuracy: 0.914\n",
      "epoch: 104, time: 2864.953s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 104, time: 2866.299s, loss: 0.246, train accuracy: 0.922\n",
      "epoch: 104, time: 2867.591s, loss: 0.199, train accuracy: 0.938\n",
      "epoch: 104, time: 2868.989s, loss: 0.248, train accuracy: 0.875\n",
      "epoch: 104, time: 2870.314s, loss: 0.146, train accuracy: 0.930\n",
      "epoch: 104, time: 2871.651s, loss: 0.287, train accuracy: 0.914\n",
      "epoch: 104, time: 2873.001s, loss: 0.249, train accuracy: 0.914\n",
      "epoch: 104, time: 2874.325s, loss: 0.282, train accuracy: 0.914\n",
      "epoch: 104, time: 2875.619s, loss: 0.219, train accuracy: 0.945\n",
      "epoch: 104, time: 2876.938s, loss: 0.277, train accuracy: 0.898\n",
      "epoch: 104, time: 2878.237s, loss: 0.242, train accuracy: 0.922\n",
      "epoch: 104, time: 2879.570s, loss: 0.234, train accuracy: 0.891\n",
      "epoch: 104, time: 2880.906s, loss: 0.249, train accuracy: 0.914\n",
      "epoch: 104, time: 2882.252s, loss: 0.303, train accuracy: 0.914\n",
      "epoch: 104, time: 2883.548s, loss: 0.218, train accuracy: 0.930\n",
      "epoch: 104, time: 2884.853s, loss: 0.326, train accuracy: 0.859\n",
      "epoch: 104, time: 2886.166s, loss: 0.210, train accuracy: 0.906\n",
      "epoch: 104, time: 2887.463s, loss: 0.191, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 105, time: 2890.378s, loss: 0.145, train accuracy: 0.938\n",
      "epoch: 105, time: 2891.697s, loss: 0.351, train accuracy: 0.867\n",
      "epoch: 105, time: 2893.019s, loss: 0.219, train accuracy: 0.906\n",
      "epoch: 105, time: 2894.338s, loss: 0.171, train accuracy: 0.930\n",
      "epoch: 105, time: 2895.661s, loss: 0.322, train accuracy: 0.898\n",
      "epoch: 105, time: 2896.966s, loss: 0.226, train accuracy: 0.898\n",
      "epoch: 105, time: 2898.262s, loss: 0.272, train accuracy: 0.883\n",
      "epoch: 105, time: 2899.575s, loss: 0.123, train accuracy: 0.961\n",
      "epoch: 105, time: 2900.894s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 105, time: 2902.228s, loss: 0.149, train accuracy: 0.945\n",
      "epoch: 105, time: 2903.568s, loss: 0.195, train accuracy: 0.914\n",
      "epoch: 105, time: 2904.927s, loss: 0.319, train accuracy: 0.891\n",
      "epoch: 105, time: 2906.239s, loss: 0.273, train accuracy: 0.914\n",
      "epoch: 105, time: 2907.577s, loss: 0.211, train accuracy: 0.930\n",
      "epoch: 105, time: 2908.901s, loss: 0.205, train accuracy: 0.922\n",
      "epoch: 105, time: 2910.224s, loss: 0.292, train accuracy: 0.875\n",
      "epoch: 105, time: 2911.575s, loss: 0.233, train accuracy: 0.914\n",
      "epoch: 105, time: 2912.868s, loss: 0.242, train accuracy: 0.914\n",
      "epoch: 105, time: 2914.175s, loss: 0.279, train accuracy: 0.898\n",
      "epoch: 105, time: 2915.538s, loss: 0.256, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 106, time: 2918.454s, loss: 0.218, train accuracy: 0.930\n",
      "epoch: 106, time: 2919.782s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 106, time: 2921.094s, loss: 0.314, train accuracy: 0.867\n",
      "epoch: 106, time: 2922.403s, loss: 0.323, train accuracy: 0.883\n",
      "epoch: 106, time: 2923.725s, loss: 0.305, train accuracy: 0.898\n",
      "epoch: 106, time: 2925.034s, loss: 0.276, train accuracy: 0.867\n",
      "epoch: 106, time: 2926.325s, loss: 0.212, train accuracy: 0.914\n",
      "epoch: 106, time: 2927.621s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 106, time: 2928.913s, loss: 0.408, train accuracy: 0.852\n",
      "epoch: 106, time: 2930.210s, loss: 0.367, train accuracy: 0.867\n",
      "epoch: 106, time: 2931.515s, loss: 0.224, train accuracy: 0.922\n",
      "epoch: 106, time: 2932.831s, loss: 0.305, train accuracy: 0.914\n",
      "epoch: 106, time: 2934.126s, loss: 0.225, train accuracy: 0.906\n",
      "epoch: 106, time: 2935.427s, loss: 0.199, train accuracy: 0.938\n",
      "epoch: 106, time: 2936.776s, loss: 0.357, train accuracy: 0.875\n",
      "epoch: 106, time: 2938.079s, loss: 0.326, train accuracy: 0.875\n",
      "epoch: 106, time: 2939.395s, loss: 0.202, train accuracy: 0.938\n",
      "epoch: 106, time: 2940.697s, loss: 0.328, train accuracy: 0.891\n",
      "epoch: 106, time: 2941.986s, loss: 0.327, train accuracy: 0.883\n",
      "epoch: 106, time: 2943.321s, loss: 0.217, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 107, time: 2946.285s, loss: 0.164, train accuracy: 0.953\n",
      "epoch: 107, time: 2947.601s, loss: 0.330, train accuracy: 0.859\n",
      "epoch: 107, time: 2948.905s, loss: 0.214, train accuracy: 0.930\n",
      "epoch: 107, time: 2950.201s, loss: 0.178, train accuracy: 0.953\n",
      "epoch: 107, time: 2951.505s, loss: 0.265, train accuracy: 0.891\n",
      "epoch: 107, time: 2952.813s, loss: 0.203, train accuracy: 0.914\n",
      "epoch: 107, time: 2954.135s, loss: 0.299, train accuracy: 0.906\n",
      "epoch: 107, time: 2955.434s, loss: 0.280, train accuracy: 0.914\n",
      "epoch: 107, time: 2956.731s, loss: 0.396, train accuracy: 0.875\n",
      "epoch: 107, time: 2958.022s, loss: 0.223, train accuracy: 0.891\n",
      "epoch: 107, time: 2959.313s, loss: 0.300, train accuracy: 0.875\n",
      "epoch: 107, time: 2960.624s, loss: 0.319, train accuracy: 0.898\n",
      "epoch: 107, time: 2961.949s, loss: 0.298, train accuracy: 0.906\n",
      "epoch: 107, time: 2963.285s, loss: 0.240, train accuracy: 0.945\n",
      "epoch: 107, time: 2964.602s, loss: 0.254, train accuracy: 0.938\n",
      "epoch: 107, time: 2965.898s, loss: 0.264, train accuracy: 0.891\n",
      "epoch: 107, time: 2967.210s, loss: 0.275, train accuracy: 0.914\n",
      "epoch: 107, time: 2968.521s, loss: 0.264, train accuracy: 0.883\n",
      "epoch: 107, time: 2969.820s, loss: 0.336, train accuracy: 0.891\n",
      "epoch: 107, time: 2971.119s, loss: 0.286, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 108, time: 2974.104s, loss: 0.145, train accuracy: 0.977\n",
      "epoch: 108, time: 2975.440s, loss: 0.242, train accuracy: 0.914\n",
      "epoch: 108, time: 2976.774s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 108, time: 2978.071s, loss: 0.336, train accuracy: 0.891\n",
      "epoch: 108, time: 2979.381s, loss: 0.199, train accuracy: 0.930\n",
      "epoch: 108, time: 2980.706s, loss: 0.216, train accuracy: 0.914\n",
      "epoch: 108, time: 2982.011s, loss: 0.222, train accuracy: 0.930\n",
      "epoch: 108, time: 2983.328s, loss: 0.374, train accuracy: 0.859\n",
      "epoch: 108, time: 2984.644s, loss: 0.242, train accuracy: 0.906\n",
      "epoch: 108, time: 2985.938s, loss: 0.230, train accuracy: 0.906\n",
      "epoch: 108, time: 2987.265s, loss: 0.322, train accuracy: 0.906\n",
      "epoch: 108, time: 2988.558s, loss: 0.387, train accuracy: 0.883\n",
      "epoch: 108, time: 2989.855s, loss: 0.234, train accuracy: 0.922\n",
      "epoch: 108, time: 2991.201s, loss: 0.308, train accuracy: 0.883\n",
      "epoch: 108, time: 2992.523s, loss: 0.281, train accuracy: 0.891\n",
      "epoch: 108, time: 2993.833s, loss: 0.310, train accuracy: 0.859\n",
      "epoch: 108, time: 2995.149s, loss: 0.301, train accuracy: 0.883\n",
      "epoch: 108, time: 2996.478s, loss: 0.295, train accuracy: 0.875\n",
      "epoch: 108, time: 2997.795s, loss: 0.276, train accuracy: 0.930\n",
      "epoch: 108, time: 2999.103s, loss: 0.218, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 109, time: 3002.046s, loss: 0.306, train accuracy: 0.891\n",
      "epoch: 109, time: 3003.378s, loss: 0.231, train accuracy: 0.914\n",
      "epoch: 109, time: 3004.706s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 109, time: 3006.002s, loss: 0.223, train accuracy: 0.906\n",
      "epoch: 109, time: 3007.339s, loss: 0.217, train accuracy: 0.930\n",
      "epoch: 109, time: 3008.661s, loss: 0.215, train accuracy: 0.922\n",
      "epoch: 109, time: 3009.953s, loss: 0.312, train accuracy: 0.898\n",
      "epoch: 109, time: 3011.312s, loss: 0.269, train accuracy: 0.898\n",
      "epoch: 109, time: 3012.637s, loss: 0.274, train accuracy: 0.914\n",
      "epoch: 109, time: 3013.968s, loss: 0.281, train accuracy: 0.891\n",
      "epoch: 109, time: 3015.282s, loss: 0.238, train accuracy: 0.922\n",
      "epoch: 109, time: 3016.600s, loss: 0.302, train accuracy: 0.891\n",
      "epoch: 109, time: 3017.907s, loss: 0.281, train accuracy: 0.883\n",
      "epoch: 109, time: 3019.209s, loss: 0.119, train accuracy: 0.961\n",
      "epoch: 109, time: 3020.507s, loss: 0.259, train accuracy: 0.922\n",
      "epoch: 109, time: 3021.802s, loss: 0.297, train accuracy: 0.891\n",
      "epoch: 109, time: 3023.129s, loss: 0.168, train accuracy: 0.938\n",
      "epoch: 109, time: 3024.458s, loss: 0.196, train accuracy: 0.945\n",
      "epoch: 109, time: 3025.779s, loss: 0.198, train accuracy: 0.930\n",
      "epoch: 109, time: 3027.111s, loss: 0.270, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 110, time: 3030.105s, loss: 0.221, train accuracy: 0.922\n",
      "epoch: 110, time: 3031.416s, loss: 0.216, train accuracy: 0.930\n",
      "epoch: 110, time: 3032.734s, loss: 0.208, train accuracy: 0.930\n",
      "epoch: 110, time: 3034.029s, loss: 0.325, train accuracy: 0.898\n",
      "epoch: 110, time: 3035.328s, loss: 0.245, train accuracy: 0.922\n",
      "epoch: 110, time: 3036.658s, loss: 0.177, train accuracy: 0.945\n",
      "epoch: 110, time: 3037.972s, loss: 0.194, train accuracy: 0.953\n",
      "epoch: 110, time: 3039.281s, loss: 0.308, train accuracy: 0.898\n",
      "epoch: 110, time: 3040.573s, loss: 0.244, train accuracy: 0.914\n",
      "epoch: 110, time: 3041.874s, loss: 0.146, train accuracy: 0.945\n",
      "epoch: 110, time: 3043.181s, loss: 0.264, train accuracy: 0.906\n",
      "epoch: 110, time: 3044.494s, loss: 0.286, train accuracy: 0.906\n",
      "epoch: 110, time: 3045.792s, loss: 0.220, train accuracy: 0.906\n",
      "epoch: 110, time: 3047.092s, loss: 0.430, train accuracy: 0.891\n",
      "epoch: 110, time: 3048.381s, loss: 0.282, train accuracy: 0.906\n",
      "epoch: 110, time: 3049.668s, loss: 0.243, train accuracy: 0.898\n",
      "epoch: 110, time: 3050.988s, loss: 0.256, train accuracy: 0.922\n",
      "epoch: 110, time: 3052.294s, loss: 0.231, train accuracy: 0.914\n",
      "epoch: 110, time: 3053.599s, loss: 0.266, train accuracy: 0.891\n",
      "epoch: 110, time: 3054.925s, loss: 0.236, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 111, time: 3057.914s, loss: 0.146, train accuracy: 0.969\n",
      "epoch: 111, time: 3059.273s, loss: 0.202, train accuracy: 0.945\n",
      "epoch: 111, time: 3060.580s, loss: 0.228, train accuracy: 0.930\n",
      "epoch: 111, time: 3061.875s, loss: 0.397, train accuracy: 0.859\n",
      "epoch: 111, time: 3063.177s, loss: 0.276, train accuracy: 0.875\n",
      "epoch: 111, time: 3064.492s, loss: 0.242, train accuracy: 0.906\n",
      "epoch: 111, time: 3065.812s, loss: 0.272, train accuracy: 0.891\n",
      "epoch: 111, time: 3067.112s, loss: 0.220, train accuracy: 0.938\n",
      "epoch: 111, time: 3068.420s, loss: 0.291, train accuracy: 0.891\n",
      "epoch: 111, time: 3069.731s, loss: 0.305, train accuracy: 0.914\n",
      "epoch: 111, time: 3071.032s, loss: 0.222, train accuracy: 0.914\n",
      "epoch: 111, time: 3072.365s, loss: 0.231, train accuracy: 0.906\n",
      "epoch: 111, time: 3073.692s, loss: 0.290, train accuracy: 0.875\n",
      "epoch: 111, time: 3075.012s, loss: 0.370, train accuracy: 0.906\n",
      "epoch: 111, time: 3076.326s, loss: 0.214, train accuracy: 0.930\n",
      "epoch: 111, time: 3077.641s, loss: 0.128, train accuracy: 0.969\n",
      "epoch: 111, time: 3078.937s, loss: 0.296, train accuracy: 0.883\n",
      "epoch: 111, time: 3080.251s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 111, time: 3081.580s, loss: 0.210, train accuracy: 0.938\n",
      "epoch: 111, time: 3082.936s, loss: 0.344, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 112, time: 3085.961s, loss: 0.253, train accuracy: 0.914\n",
      "epoch: 112, time: 3087.299s, loss: 0.266, train accuracy: 0.891\n",
      "epoch: 112, time: 3088.647s, loss: 0.208, train accuracy: 0.930\n",
      "epoch: 112, time: 3089.983s, loss: 0.156, train accuracy: 0.930\n",
      "epoch: 112, time: 3091.310s, loss: 0.396, train accuracy: 0.836\n",
      "epoch: 112, time: 3092.616s, loss: 0.315, train accuracy: 0.898\n",
      "epoch: 112, time: 3093.912s, loss: 0.249, train accuracy: 0.906\n",
      "epoch: 112, time: 3095.227s, loss: 0.331, train accuracy: 0.867\n",
      "epoch: 112, time: 3096.535s, loss: 0.258, train accuracy: 0.914\n",
      "epoch: 112, time: 3097.844s, loss: 0.254, train accuracy: 0.898\n",
      "epoch: 112, time: 3099.154s, loss: 0.119, train accuracy: 0.969\n",
      "epoch: 112, time: 3100.476s, loss: 0.257, train accuracy: 0.906\n",
      "epoch: 112, time: 3101.907s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 112, time: 3103.222s, loss: 0.219, train accuracy: 0.930\n",
      "epoch: 112, time: 3104.527s, loss: 0.190, train accuracy: 0.938\n",
      "epoch: 112, time: 3105.849s, loss: 0.234, train accuracy: 0.922\n",
      "epoch: 112, time: 3107.160s, loss: 0.382, train accuracy: 0.883\n",
      "epoch: 112, time: 3108.495s, loss: 0.217, train accuracy: 0.922\n",
      "epoch: 112, time: 3109.793s, loss: 0.224, train accuracy: 0.953\n",
      "epoch: 112, time: 3111.092s, loss: 0.222, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.832\n",
      "epoch: 113, time: 3114.076s, loss: 0.246, train accuracy: 0.938\n",
      "epoch: 113, time: 3115.418s, loss: 0.253, train accuracy: 0.883\n",
      "epoch: 113, time: 3116.718s, loss: 0.224, train accuracy: 0.922\n",
      "epoch: 113, time: 3118.044s, loss: 0.304, train accuracy: 0.883\n",
      "epoch: 113, time: 3119.367s, loss: 0.121, train accuracy: 0.953\n",
      "epoch: 113, time: 3120.661s, loss: 0.192, train accuracy: 0.922\n",
      "epoch: 113, time: 3121.980s, loss: 0.177, train accuracy: 0.938\n",
      "epoch: 113, time: 3123.311s, loss: 0.243, train accuracy: 0.883\n",
      "epoch: 113, time: 3124.598s, loss: 0.228, train accuracy: 0.898\n",
      "epoch: 113, time: 3125.927s, loss: 0.200, train accuracy: 0.898\n",
      "epoch: 113, time: 3127.216s, loss: 0.268, train accuracy: 0.906\n",
      "epoch: 113, time: 3128.509s, loss: 0.167, train accuracy: 0.922\n",
      "epoch: 113, time: 3129.881s, loss: 0.293, train accuracy: 0.922\n",
      "epoch: 113, time: 3131.196s, loss: 0.295, train accuracy: 0.891\n",
      "epoch: 113, time: 3132.496s, loss: 0.305, train accuracy: 0.891\n",
      "epoch: 113, time: 3133.827s, loss: 0.236, train accuracy: 0.898\n",
      "epoch: 113, time: 3135.162s, loss: 0.234, train accuracy: 0.922\n",
      "epoch: 113, time: 3136.452s, loss: 0.187, train accuracy: 0.938\n",
      "epoch: 113, time: 3137.783s, loss: 0.270, train accuracy: 0.914\n",
      "epoch: 113, time: 3139.134s, loss: 0.214, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.844\n",
      "epoch: 114, time: 3142.106s, loss: 0.276, train accuracy: 0.898\n",
      "epoch: 114, time: 3143.439s, loss: 0.219, train accuracy: 0.922\n",
      "epoch: 114, time: 3144.762s, loss: 0.165, train accuracy: 0.945\n",
      "epoch: 114, time: 3146.093s, loss: 0.232, train accuracy: 0.914\n",
      "epoch: 114, time: 3147.420s, loss: 0.277, train accuracy: 0.922\n",
      "epoch: 114, time: 3148.718s, loss: 0.231, train accuracy: 0.922\n",
      "epoch: 114, time: 3150.041s, loss: 0.213, train accuracy: 0.953\n",
      "epoch: 114, time: 3151.332s, loss: 0.296, train accuracy: 0.875\n",
      "epoch: 114, time: 3152.651s, loss: 0.212, train accuracy: 0.914\n",
      "epoch: 114, time: 3153.973s, loss: 0.242, train accuracy: 0.906\n",
      "epoch: 114, time: 3155.323s, loss: 0.175, train accuracy: 0.945\n",
      "epoch: 114, time: 3156.622s, loss: 0.238, train accuracy: 0.906\n",
      "epoch: 114, time: 3157.918s, loss: 0.384, train accuracy: 0.875\n",
      "epoch: 114, time: 3159.227s, loss: 0.168, train accuracy: 0.961\n",
      "epoch: 114, time: 3160.524s, loss: 0.212, train accuracy: 0.930\n",
      "epoch: 114, time: 3161.837s, loss: 0.348, train accuracy: 0.867\n",
      "epoch: 114, time: 3163.133s, loss: 0.229, train accuracy: 0.906\n",
      "epoch: 114, time: 3164.435s, loss: 0.222, train accuracy: 0.914\n",
      "epoch: 114, time: 3165.729s, loss: 0.213, train accuracy: 0.906\n",
      "epoch: 114, time: 3167.038s, loss: 0.203, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.848\n",
      "epoch: 115, time: 3170.002s, loss: 0.165, train accuracy: 0.945\n",
      "epoch: 115, time: 3171.348s, loss: 0.182, train accuracy: 0.922\n",
      "epoch: 115, time: 3172.650s, loss: 0.283, train accuracy: 0.891\n",
      "epoch: 115, time: 3173.957s, loss: 0.250, train accuracy: 0.914\n",
      "epoch: 115, time: 3175.262s, loss: 0.186, train accuracy: 0.938\n",
      "epoch: 115, time: 3176.579s, loss: 0.274, train accuracy: 0.867\n",
      "epoch: 115, time: 3177.892s, loss: 0.221, train accuracy: 0.938\n",
      "epoch: 115, time: 3179.191s, loss: 0.193, train accuracy: 0.914\n",
      "epoch: 115, time: 3180.507s, loss: 0.230, train accuracy: 0.898\n",
      "epoch: 115, time: 3181.804s, loss: 0.266, train accuracy: 0.891\n",
      "epoch: 115, time: 3183.111s, loss: 0.236, train accuracy: 0.906\n",
      "epoch: 115, time: 3184.415s, loss: 0.255, train accuracy: 0.906\n",
      "epoch: 115, time: 3185.729s, loss: 0.223, train accuracy: 0.930\n",
      "epoch: 115, time: 3187.068s, loss: 0.257, train accuracy: 0.906\n",
      "epoch: 115, time: 3188.360s, loss: 0.267, train accuracy: 0.875\n",
      "epoch: 115, time: 3189.659s, loss: 0.301, train accuracy: 0.906\n",
      "epoch: 115, time: 3190.958s, loss: 0.362, train accuracy: 0.883\n",
      "epoch: 115, time: 3192.257s, loss: 0.231, train accuracy: 0.922\n",
      "epoch: 115, time: 3193.611s, loss: 0.299, train accuracy: 0.875\n",
      "epoch: 115, time: 3194.955s, loss: 0.256, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 116, time: 3197.873s, loss: 0.234, train accuracy: 0.938\n",
      "epoch: 116, time: 3199.222s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 116, time: 3200.579s, loss: 0.198, train accuracy: 0.938\n",
      "epoch: 116, time: 3201.890s, loss: 0.219, train accuracy: 0.891\n",
      "epoch: 116, time: 3203.204s, loss: 0.236, train accuracy: 0.930\n",
      "epoch: 116, time: 3204.585s, loss: 0.090, train accuracy: 0.961\n",
      "epoch: 116, time: 3205.917s, loss: 0.141, train accuracy: 0.961\n",
      "epoch: 116, time: 3207.228s, loss: 0.318, train accuracy: 0.875\n",
      "epoch: 116, time: 3208.550s, loss: 0.256, train accuracy: 0.906\n",
      "epoch: 116, time: 3209.851s, loss: 0.254, train accuracy: 0.906\n",
      "epoch: 116, time: 3211.165s, loss: 0.205, train accuracy: 0.906\n",
      "epoch: 116, time: 3212.467s, loss: 0.242, train accuracy: 0.922\n",
      "epoch: 116, time: 3213.761s, loss: 0.235, train accuracy: 0.930\n",
      "epoch: 116, time: 3215.073s, loss: 0.277, train accuracy: 0.898\n",
      "epoch: 116, time: 3216.429s, loss: 0.231, train accuracy: 0.891\n",
      "epoch: 116, time: 3217.746s, loss: 0.335, train accuracy: 0.883\n",
      "epoch: 116, time: 3219.059s, loss: 0.260, train accuracy: 0.898\n",
      "epoch: 116, time: 3220.380s, loss: 0.231, train accuracy: 0.938\n",
      "epoch: 116, time: 3221.681s, loss: 0.165, train accuracy: 0.938\n",
      "epoch: 116, time: 3222.991s, loss: 0.301, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 117, time: 3225.971s, loss: 0.246, train accuracy: 0.891\n",
      "epoch: 117, time: 3227.286s, loss: 0.194, train accuracy: 0.930\n",
      "epoch: 117, time: 3228.577s, loss: 0.273, train accuracy: 0.875\n",
      "epoch: 117, time: 3229.907s, loss: 0.276, train accuracy: 0.914\n",
      "epoch: 117, time: 3231.204s, loss: 0.324, train accuracy: 0.891\n",
      "epoch: 117, time: 3232.526s, loss: 0.218, train accuracy: 0.906\n",
      "epoch: 117, time: 3233.828s, loss: 0.213, train accuracy: 0.922\n",
      "epoch: 117, time: 3235.160s, loss: 0.277, train accuracy: 0.914\n",
      "epoch: 117, time: 3236.458s, loss: 0.344, train accuracy: 0.891\n",
      "epoch: 117, time: 3237.780s, loss: 0.281, train accuracy: 0.906\n",
      "epoch: 117, time: 3239.106s, loss: 0.210, train accuracy: 0.930\n",
      "epoch: 117, time: 3240.398s, loss: 0.167, train accuracy: 0.953\n",
      "epoch: 117, time: 3241.682s, loss: 0.272, train accuracy: 0.867\n",
      "epoch: 117, time: 3243.002s, loss: 0.348, train accuracy: 0.891\n",
      "epoch: 117, time: 3244.352s, loss: 0.292, train accuracy: 0.859\n",
      "epoch: 117, time: 3245.673s, loss: 0.237, train accuracy: 0.938\n",
      "epoch: 117, time: 3247.002s, loss: 0.222, train accuracy: 0.906\n",
      "epoch: 117, time: 3248.398s, loss: 0.251, train accuracy: 0.891\n",
      "epoch: 117, time: 3249.689s, loss: 0.290, train accuracy: 0.867\n",
      "epoch: 117, time: 3250.987s, loss: 0.273, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 118, time: 3253.983s, loss: 0.356, train accuracy: 0.859\n",
      "epoch: 118, time: 3255.296s, loss: 0.280, train accuracy: 0.891\n",
      "epoch: 118, time: 3256.597s, loss: 0.305, train accuracy: 0.867\n",
      "epoch: 118, time: 3257.893s, loss: 0.299, train accuracy: 0.906\n",
      "epoch: 118, time: 3259.234s, loss: 0.175, train accuracy: 0.930\n",
      "epoch: 118, time: 3260.551s, loss: 0.218, train accuracy: 0.883\n",
      "epoch: 118, time: 3261.852s, loss: 0.207, train accuracy: 0.953\n",
      "epoch: 118, time: 3263.157s, loss: 0.150, train accuracy: 0.969\n",
      "epoch: 118, time: 3264.513s, loss: 0.279, train accuracy: 0.938\n",
      "epoch: 118, time: 3265.807s, loss: 0.260, train accuracy: 0.914\n",
      "epoch: 118, time: 3267.124s, loss: 0.294, train accuracy: 0.875\n",
      "epoch: 118, time: 3268.447s, loss: 0.151, train accuracy: 0.953\n",
      "epoch: 118, time: 3269.774s, loss: 0.284, train accuracy: 0.906\n",
      "epoch: 118, time: 3271.113s, loss: 0.330, train accuracy: 0.867\n",
      "epoch: 118, time: 3272.419s, loss: 0.349, train accuracy: 0.867\n",
      "epoch: 118, time: 3273.748s, loss: 0.167, train accuracy: 0.922\n",
      "epoch: 118, time: 3275.071s, loss: 0.145, train accuracy: 0.961\n",
      "epoch: 118, time: 3276.374s, loss: 0.262, train accuracy: 0.898\n",
      "epoch: 118, time: 3277.685s, loss: 0.320, train accuracy: 0.891\n",
      "epoch: 118, time: 3278.977s, loss: 0.337, train accuracy: 0.875\n",
      "Accuracy on the test set: 0.835\n",
      "epoch: 119, time: 3281.957s, loss: 0.353, train accuracy: 0.883\n",
      "epoch: 119, time: 3283.288s, loss: 0.178, train accuracy: 0.938\n",
      "epoch: 119, time: 3284.636s, loss: 0.282, train accuracy: 0.906\n",
      "epoch: 119, time: 3285.929s, loss: 0.251, train accuracy: 0.875\n",
      "epoch: 119, time: 3287.242s, loss: 0.302, train accuracy: 0.875\n",
      "epoch: 119, time: 3288.557s, loss: 0.145, train accuracy: 0.969\n",
      "epoch: 119, time: 3289.863s, loss: 0.296, train accuracy: 0.906\n",
      "epoch: 119, time: 3291.198s, loss: 0.237, train accuracy: 0.914\n",
      "epoch: 119, time: 3292.492s, loss: 0.248, train accuracy: 0.914\n",
      "epoch: 119, time: 3293.792s, loss: 0.195, train accuracy: 0.906\n",
      "epoch: 119, time: 3295.118s, loss: 0.138, train accuracy: 0.961\n",
      "epoch: 119, time: 3296.436s, loss: 0.311, train accuracy: 0.883\n",
      "epoch: 119, time: 3297.729s, loss: 0.260, train accuracy: 0.883\n",
      "epoch: 119, time: 3299.046s, loss: 0.202, train accuracy: 0.914\n",
      "epoch: 119, time: 3300.362s, loss: 0.286, train accuracy: 0.906\n",
      "epoch: 119, time: 3301.657s, loss: 0.144, train accuracy: 0.945\n",
      "epoch: 119, time: 3302.997s, loss: 0.162, train accuracy: 0.922\n",
      "epoch: 119, time: 3304.379s, loss: 0.234, train accuracy: 0.922\n",
      "epoch: 119, time: 3305.765s, loss: 0.263, train accuracy: 0.891\n",
      "epoch: 119, time: 3307.194s, loss: 0.309, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 120, time: 3310.196s, loss: 0.125, train accuracy: 0.938\n",
      "epoch: 120, time: 3311.579s, loss: 0.143, train accuracy: 0.953\n",
      "epoch: 120, time: 3312.950s, loss: 0.204, train accuracy: 0.922\n",
      "epoch: 120, time: 3314.314s, loss: 0.289, train accuracy: 0.914\n",
      "epoch: 120, time: 3315.630s, loss: 0.226, train accuracy: 0.945\n",
      "epoch: 120, time: 3316.986s, loss: 0.341, train accuracy: 0.898\n",
      "epoch: 120, time: 3318.347s, loss: 0.582, train accuracy: 0.797\n",
      "epoch: 120, time: 3319.681s, loss: 0.749, train accuracy: 0.766\n",
      "epoch: 120, time: 3321.025s, loss: 0.473, train accuracy: 0.844\n",
      "epoch: 120, time: 3322.411s, loss: 0.433, train accuracy: 0.844\n",
      "epoch: 120, time: 3323.839s, loss: 0.290, train accuracy: 0.898\n",
      "epoch: 120, time: 3325.275s, loss: 0.426, train accuracy: 0.875\n",
      "epoch: 120, time: 3326.638s, loss: 0.291, train accuracy: 0.930\n",
      "epoch: 120, time: 3328.015s, loss: 0.259, train accuracy: 0.891\n",
      "epoch: 120, time: 3329.349s, loss: 0.297, train accuracy: 0.898\n",
      "epoch: 120, time: 3330.661s, loss: 0.400, train accuracy: 0.859\n",
      "epoch: 120, time: 3331.973s, loss: 0.426, train accuracy: 0.828\n",
      "epoch: 120, time: 3333.312s, loss: 0.343, train accuracy: 0.883\n",
      "epoch: 120, time: 3334.651s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 120, time: 3335.964s, loss: 0.298, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.832\n",
      "epoch: 121, time: 3338.928s, loss: 0.262, train accuracy: 0.914\n",
      "epoch: 121, time: 3340.254s, loss: 0.320, train accuracy: 0.898\n",
      "epoch: 121, time: 3341.596s, loss: 0.353, train accuracy: 0.875\n",
      "epoch: 121, time: 3342.892s, loss: 0.324, train accuracy: 0.891\n",
      "epoch: 121, time: 3344.212s, loss: 0.194, train accuracy: 0.922\n",
      "epoch: 121, time: 3345.522s, loss: 0.250, train accuracy: 0.914\n",
      "epoch: 121, time: 3346.829s, loss: 0.187, train accuracy: 0.922\n",
      "epoch: 121, time: 3348.125s, loss: 0.236, train accuracy: 0.914\n",
      "epoch: 121, time: 3349.463s, loss: 0.202, train accuracy: 0.914\n",
      "epoch: 121, time: 3350.775s, loss: 0.190, train accuracy: 0.930\n",
      "epoch: 121, time: 3352.096s, loss: 0.321, train accuracy: 0.898\n",
      "epoch: 121, time: 3353.437s, loss: 0.245, train accuracy: 0.945\n",
      "epoch: 121, time: 3354.736s, loss: 0.182, train accuracy: 0.938\n",
      "epoch: 121, time: 3356.033s, loss: 0.216, train accuracy: 0.922\n",
      "epoch: 121, time: 3357.376s, loss: 0.447, train accuracy: 0.867\n",
      "epoch: 121, time: 3358.693s, loss: 0.190, train accuracy: 0.906\n",
      "epoch: 121, time: 3360.010s, loss: 0.228, train accuracy: 0.938\n",
      "epoch: 121, time: 3361.317s, loss: 0.330, train accuracy: 0.852\n",
      "epoch: 121, time: 3362.644s, loss: 0.223, train accuracy: 0.914\n",
      "epoch: 121, time: 3363.950s, loss: 0.315, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 122, time: 3366.917s, loss: 0.137, train accuracy: 0.961\n",
      "epoch: 122, time: 3368.254s, loss: 0.217, train accuracy: 0.914\n",
      "epoch: 122, time: 3369.596s, loss: 0.201, train accuracy: 0.938\n",
      "epoch: 122, time: 3370.951s, loss: 0.244, train accuracy: 0.891\n",
      "epoch: 122, time: 3372.267s, loss: 0.260, train accuracy: 0.875\n",
      "epoch: 122, time: 3373.562s, loss: 0.221, train accuracy: 0.898\n",
      "epoch: 122, time: 3374.864s, loss: 0.248, train accuracy: 0.914\n",
      "epoch: 122, time: 3376.199s, loss: 0.189, train accuracy: 0.953\n",
      "epoch: 122, time: 3377.510s, loss: 0.165, train accuracy: 0.938\n",
      "epoch: 122, time: 3378.837s, loss: 0.146, train accuracy: 0.938\n",
      "epoch: 122, time: 3380.148s, loss: 0.172, train accuracy: 0.930\n",
      "epoch: 122, time: 3381.481s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 122, time: 3382.781s, loss: 0.304, train accuracy: 0.906\n",
      "epoch: 122, time: 3384.085s, loss: 0.359, train accuracy: 0.875\n",
      "epoch: 122, time: 3385.395s, loss: 0.255, train accuracy: 0.922\n",
      "epoch: 122, time: 3386.713s, loss: 0.199, train accuracy: 0.922\n",
      "epoch: 122, time: 3388.025s, loss: 0.208, train accuracy: 0.906\n",
      "epoch: 122, time: 3389.321s, loss: 0.280, train accuracy: 0.883\n",
      "epoch: 122, time: 3390.637s, loss: 0.208, train accuracy: 0.914\n",
      "epoch: 122, time: 3391.929s, loss: 0.362, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 123, time: 3394.884s, loss: 0.176, train accuracy: 0.922\n",
      "epoch: 123, time: 3396.250s, loss: 0.247, train accuracy: 0.945\n",
      "epoch: 123, time: 3397.582s, loss: 0.259, train accuracy: 0.906\n",
      "epoch: 123, time: 3398.897s, loss: 0.221, train accuracy: 0.914\n",
      "epoch: 123, time: 3400.196s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 123, time: 3401.517s, loss: 0.255, train accuracy: 0.906\n",
      "epoch: 123, time: 3402.827s, loss: 0.249, train accuracy: 0.922\n",
      "epoch: 123, time: 3404.155s, loss: 0.185, train accuracy: 0.945\n",
      "epoch: 123, time: 3405.487s, loss: 0.148, train accuracy: 0.961\n",
      "epoch: 123, time: 3406.783s, loss: 0.216, train accuracy: 0.922\n",
      "epoch: 123, time: 3408.092s, loss: 0.228, train accuracy: 0.914\n",
      "epoch: 123, time: 3409.422s, loss: 0.429, train accuracy: 0.859\n",
      "epoch: 123, time: 3410.720s, loss: 0.113, train accuracy: 0.961\n",
      "epoch: 123, time: 3412.033s, loss: 0.164, train accuracy: 0.945\n",
      "epoch: 123, time: 3413.333s, loss: 0.247, train accuracy: 0.898\n",
      "epoch: 123, time: 3414.655s, loss: 0.205, train accuracy: 0.914\n",
      "epoch: 123, time: 3415.969s, loss: 0.248, train accuracy: 0.914\n",
      "epoch: 123, time: 3417.282s, loss: 0.167, train accuracy: 0.930\n",
      "epoch: 123, time: 3418.573s, loss: 0.220, train accuracy: 0.922\n",
      "epoch: 123, time: 3419.883s, loss: 0.226, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 124, time: 3422.845s, loss: 0.182, train accuracy: 0.938\n",
      "epoch: 124, time: 3424.207s, loss: 0.116, train accuracy: 0.961\n",
      "epoch: 124, time: 3425.524s, loss: 0.188, train accuracy: 0.914\n",
      "epoch: 124, time: 3426.837s, loss: 0.221, train accuracy: 0.898\n",
      "epoch: 124, time: 3428.165s, loss: 0.175, train accuracy: 0.930\n",
      "epoch: 124, time: 3429.473s, loss: 0.134, train accuracy: 0.961\n",
      "epoch: 124, time: 3430.781s, loss: 0.153, train accuracy: 0.945\n",
      "epoch: 124, time: 3432.111s, loss: 0.344, train accuracy: 0.898\n",
      "epoch: 124, time: 3433.423s, loss: 0.277, train accuracy: 0.906\n",
      "epoch: 124, time: 3434.723s, loss: 0.279, train accuracy: 0.898\n",
      "epoch: 124, time: 3436.025s, loss: 0.176, train accuracy: 0.953\n",
      "epoch: 124, time: 3437.355s, loss: 0.189, train accuracy: 0.930\n",
      "epoch: 124, time: 3438.673s, loss: 0.188, train accuracy: 0.930\n",
      "epoch: 124, time: 3439.983s, loss: 0.364, train accuracy: 0.859\n",
      "epoch: 124, time: 3441.277s, loss: 0.133, train accuracy: 0.945\n",
      "epoch: 124, time: 3442.575s, loss: 0.182, train accuracy: 0.938\n",
      "epoch: 124, time: 3443.869s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 124, time: 3445.191s, loss: 0.271, train accuracy: 0.875\n",
      "epoch: 124, time: 3446.520s, loss: 0.233, train accuracy: 0.883\n",
      "epoch: 124, time: 3447.861s, loss: 0.206, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 125, time: 3450.831s, loss: 0.185, train accuracy: 0.930\n",
      "epoch: 125, time: 3452.181s, loss: 0.177, train accuracy: 0.930\n",
      "epoch: 125, time: 3453.504s, loss: 0.256, train accuracy: 0.922\n",
      "epoch: 125, time: 3454.799s, loss: 0.302, train accuracy: 0.906\n",
      "epoch: 125, time: 3456.112s, loss: 0.121, train accuracy: 0.961\n",
      "epoch: 125, time: 3457.485s, loss: 0.253, train accuracy: 0.883\n",
      "epoch: 125, time: 3458.805s, loss: 0.149, train accuracy: 0.961\n",
      "epoch: 125, time: 3460.102s, loss: 0.177, train accuracy: 0.930\n",
      "epoch: 125, time: 3461.411s, loss: 0.200, train accuracy: 0.945\n",
      "epoch: 125, time: 3462.720s, loss: 0.296, train accuracy: 0.875\n",
      "epoch: 125, time: 3464.014s, loss: 0.164, train accuracy: 0.938\n",
      "epoch: 125, time: 3465.358s, loss: 0.118, train accuracy: 0.945\n",
      "epoch: 125, time: 3466.685s, loss: 0.214, train accuracy: 0.969\n",
      "epoch: 125, time: 3467.977s, loss: 0.163, train accuracy: 0.953\n",
      "epoch: 125, time: 3469.305s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 125, time: 3470.599s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 125, time: 3471.914s, loss: 0.189, train accuracy: 0.914\n",
      "epoch: 125, time: 3473.201s, loss: 0.269, train accuracy: 0.906\n",
      "epoch: 125, time: 3474.499s, loss: 0.234, train accuracy: 0.938\n",
      "epoch: 125, time: 3475.820s, loss: 0.162, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 126, time: 3478.733s, loss: 0.187, train accuracy: 0.914\n",
      "epoch: 126, time: 3480.072s, loss: 0.346, train accuracy: 0.883\n",
      "epoch: 126, time: 3481.417s, loss: 0.350, train accuracy: 0.852\n",
      "epoch: 126, time: 3482.726s, loss: 0.266, train accuracy: 0.891\n",
      "epoch: 126, time: 3484.068s, loss: 0.200, train accuracy: 0.914\n",
      "epoch: 126, time: 3485.387s, loss: 0.222, train accuracy: 0.914\n",
      "epoch: 126, time: 3486.714s, loss: 0.211, train accuracy: 0.906\n",
      "epoch: 126, time: 3488.053s, loss: 0.163, train accuracy: 0.922\n",
      "epoch: 126, time: 3489.348s, loss: 0.178, train accuracy: 0.945\n",
      "epoch: 126, time: 3490.644s, loss: 0.246, train accuracy: 0.906\n",
      "epoch: 126, time: 3491.976s, loss: 0.229, train accuracy: 0.906\n",
      "epoch: 126, time: 3493.282s, loss: 0.278, train accuracy: 0.906\n",
      "epoch: 126, time: 3494.606s, loss: 0.277, train accuracy: 0.883\n",
      "epoch: 126, time: 3495.912s, loss: 0.232, train accuracy: 0.914\n",
      "epoch: 126, time: 3497.264s, loss: 0.281, train accuracy: 0.922\n",
      "epoch: 126, time: 3498.571s, loss: 0.175, train accuracy: 0.961\n",
      "epoch: 126, time: 3499.892s, loss: 0.101, train accuracy: 0.961\n",
      "epoch: 126, time: 3501.191s, loss: 0.252, train accuracy: 0.922\n",
      "epoch: 126, time: 3502.489s, loss: 0.208, train accuracy: 0.914\n",
      "epoch: 126, time: 3503.838s, loss: 0.264, train accuracy: 0.883\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 127, time: 3506.795s, loss: 0.207, train accuracy: 0.906\n",
      "epoch: 127, time: 3508.134s, loss: 0.208, train accuracy: 0.906\n",
      "epoch: 127, time: 3509.429s, loss: 0.263, train accuracy: 0.914\n",
      "epoch: 127, time: 3510.754s, loss: 0.132, train accuracy: 0.938\n",
      "epoch: 127, time: 3512.074s, loss: 0.217, train accuracy: 0.938\n",
      "epoch: 127, time: 3513.399s, loss: 0.224, train accuracy: 0.914\n",
      "epoch: 127, time: 3514.697s, loss: 0.158, train accuracy: 0.945\n",
      "epoch: 127, time: 3516.017s, loss: 0.272, train accuracy: 0.914\n",
      "epoch: 127, time: 3517.325s, loss: 0.294, train accuracy: 0.883\n",
      "epoch: 127, time: 3518.637s, loss: 0.284, train accuracy: 0.914\n",
      "epoch: 127, time: 3519.930s, loss: 0.335, train accuracy: 0.867\n",
      "epoch: 127, time: 3521.239s, loss: 0.231, train accuracy: 0.906\n",
      "epoch: 127, time: 3522.583s, loss: 0.204, train accuracy: 0.930\n",
      "epoch: 127, time: 3523.915s, loss: 0.182, train accuracy: 0.938\n",
      "epoch: 127, time: 3525.234s, loss: 0.184, train accuracy: 0.945\n",
      "epoch: 127, time: 3526.551s, loss: 0.199, train accuracy: 0.930\n",
      "epoch: 127, time: 3527.877s, loss: 0.158, train accuracy: 0.938\n",
      "epoch: 127, time: 3529.171s, loss: 0.154, train accuracy: 0.953\n",
      "epoch: 127, time: 3530.498s, loss: 0.217, train accuracy: 0.953\n",
      "epoch: 127, time: 3531.841s, loss: 0.169, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.846\n",
      "epoch: 128, time: 3534.797s, loss: 0.188, train accuracy: 0.930\n",
      "epoch: 128, time: 3536.133s, loss: 0.221, train accuracy: 0.891\n",
      "epoch: 128, time: 3537.443s, loss: 0.162, train accuracy: 0.969\n",
      "epoch: 128, time: 3538.739s, loss: 0.208, train accuracy: 0.914\n",
      "epoch: 128, time: 3540.056s, loss: 0.146, train accuracy: 0.953\n",
      "epoch: 128, time: 3541.377s, loss: 0.311, train accuracy: 0.883\n",
      "epoch: 128, time: 3542.694s, loss: 0.128, train accuracy: 0.938\n",
      "epoch: 128, time: 3544.000s, loss: 0.179, train accuracy: 0.914\n",
      "epoch: 128, time: 3545.312s, loss: 0.229, train accuracy: 0.938\n",
      "epoch: 128, time: 3546.637s, loss: 0.138, train accuracy: 0.961\n",
      "epoch: 128, time: 3547.968s, loss: 0.189, train accuracy: 0.922\n",
      "epoch: 128, time: 3549.315s, loss: 0.154, train accuracy: 0.977\n",
      "epoch: 128, time: 3550.643s, loss: 0.218, train accuracy: 0.953\n",
      "epoch: 128, time: 3551.993s, loss: 0.216, train accuracy: 0.938\n",
      "epoch: 128, time: 3553.291s, loss: 0.182, train accuracy: 0.945\n",
      "epoch: 128, time: 3554.599s, loss: 0.218, train accuracy: 0.922\n",
      "epoch: 128, time: 3555.913s, loss: 0.292, train accuracy: 0.914\n",
      "epoch: 128, time: 3557.208s, loss: 0.202, train accuracy: 0.930\n",
      "epoch: 128, time: 3558.535s, loss: 0.226, train accuracy: 0.891\n",
      "epoch: 128, time: 3559.848s, loss: 0.208, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 129, time: 3562.712s, loss: 0.192, train accuracy: 0.945\n",
      "epoch: 129, time: 3564.013s, loss: 0.227, train accuracy: 0.898\n",
      "epoch: 129, time: 3565.312s, loss: 0.217, train accuracy: 0.930\n",
      "epoch: 129, time: 3566.670s, loss: 0.182, train accuracy: 0.922\n",
      "epoch: 129, time: 3567.992s, loss: 0.213, train accuracy: 0.922\n",
      "epoch: 129, time: 3569.302s, loss: 0.302, train accuracy: 0.891\n",
      "epoch: 129, time: 3570.647s, loss: 0.163, train accuracy: 0.930\n",
      "epoch: 129, time: 3571.932s, loss: 0.265, train accuracy: 0.898\n",
      "epoch: 129, time: 3573.284s, loss: 0.255, train accuracy: 0.891\n",
      "epoch: 129, time: 3574.611s, loss: 0.312, train accuracy: 0.914\n",
      "epoch: 129, time: 3575.928s, loss: 0.124, train accuracy: 0.953\n",
      "epoch: 129, time: 3577.261s, loss: 0.142, train accuracy: 0.930\n",
      "epoch: 129, time: 3578.582s, loss: 0.274, train accuracy: 0.914\n",
      "epoch: 129, time: 3579.903s, loss: 0.154, train accuracy: 0.961\n",
      "epoch: 129, time: 3581.220s, loss: 0.291, train accuracy: 0.898\n",
      "epoch: 129, time: 3582.513s, loss: 0.354, train accuracy: 0.883\n",
      "epoch: 129, time: 3583.804s, loss: 0.145, train accuracy: 0.961\n",
      "epoch: 129, time: 3585.137s, loss: 0.223, train accuracy: 0.906\n",
      "epoch: 129, time: 3586.472s, loss: 0.407, train accuracy: 0.852\n",
      "epoch: 129, time: 3587.801s, loss: 0.225, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 130, time: 3590.765s, loss: 0.165, train accuracy: 0.938\n",
      "epoch: 130, time: 3592.144s, loss: 0.181, train accuracy: 0.938\n",
      "epoch: 130, time: 3593.458s, loss: 0.107, train accuracy: 0.961\n",
      "epoch: 130, time: 3594.811s, loss: 0.171, train accuracy: 0.945\n",
      "epoch: 130, time: 3596.130s, loss: 0.389, train accuracy: 0.875\n",
      "epoch: 130, time: 3597.423s, loss: 0.142, train accuracy: 0.945\n",
      "epoch: 130, time: 3598.761s, loss: 0.129, train accuracy: 0.961\n",
      "epoch: 130, time: 3600.112s, loss: 0.176, train accuracy: 0.914\n",
      "epoch: 130, time: 3601.412s, loss: 0.214, train accuracy: 0.922\n",
      "epoch: 130, time: 3602.735s, loss: 0.218, train accuracy: 0.914\n",
      "epoch: 130, time: 3604.005s, loss: 0.248, train accuracy: 0.883\n",
      "epoch: 130, time: 3605.367s, loss: 0.224, train accuracy: 0.922\n",
      "epoch: 130, time: 3606.678s, loss: 0.202, train accuracy: 0.938\n",
      "epoch: 130, time: 3607.957s, loss: 0.184, train accuracy: 0.922\n",
      "epoch: 130, time: 3609.215s, loss: 0.199, train accuracy: 0.953\n",
      "epoch: 130, time: 3610.472s, loss: 0.258, train accuracy: 0.898\n",
      "epoch: 130, time: 3611.731s, loss: 0.181, train accuracy: 0.922\n",
      "epoch: 130, time: 3612.985s, loss: 0.191, train accuracy: 0.938\n",
      "epoch: 130, time: 3614.236s, loss: 0.304, train accuracy: 0.867\n",
      "epoch: 130, time: 3615.517s, loss: 0.247, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 131, time: 3618.359s, loss: 0.208, train accuracy: 0.914\n",
      "epoch: 131, time: 3619.629s, loss: 0.201, train accuracy: 0.945\n",
      "epoch: 131, time: 3620.916s, loss: 0.200, train accuracy: 0.945\n",
      "epoch: 131, time: 3622.296s, loss: 0.275, train accuracy: 0.922\n",
      "epoch: 131, time: 3623.641s, loss: 0.132, train accuracy: 0.969\n",
      "epoch: 131, time: 3624.980s, loss: 0.168, train accuracy: 0.930\n",
      "epoch: 131, time: 3626.305s, loss: 0.246, train accuracy: 0.914\n",
      "epoch: 131, time: 3627.617s, loss: 0.207, train accuracy: 0.930\n",
      "epoch: 131, time: 3628.903s, loss: 0.320, train accuracy: 0.867\n",
      "epoch: 131, time: 3630.165s, loss: 0.192, train accuracy: 0.930\n",
      "epoch: 131, time: 3631.429s, loss: 0.174, train accuracy: 0.914\n",
      "epoch: 131, time: 3632.683s, loss: 0.184, train accuracy: 0.922\n",
      "epoch: 131, time: 3633.935s, loss: 0.167, train accuracy: 0.930\n",
      "epoch: 131, time: 3635.185s, loss: 0.232, train accuracy: 0.922\n",
      "epoch: 131, time: 3636.461s, loss: 0.195, train accuracy: 0.930\n",
      "epoch: 131, time: 3637.735s, loss: 0.176, train accuracy: 0.938\n",
      "epoch: 131, time: 3638.980s, loss: 0.129, train accuracy: 0.945\n",
      "epoch: 131, time: 3640.300s, loss: 0.247, train accuracy: 0.922\n",
      "epoch: 131, time: 3641.571s, loss: 0.246, train accuracy: 0.891\n",
      "epoch: 131, time: 3642.826s, loss: 0.257, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 132, time: 3645.688s, loss: 0.150, train accuracy: 0.953\n",
      "epoch: 132, time: 3646.975s, loss: 0.194, train accuracy: 0.914\n",
      "epoch: 132, time: 3648.222s, loss: 0.112, train accuracy: 0.945\n",
      "epoch: 132, time: 3649.470s, loss: 0.182, train accuracy: 0.898\n",
      "epoch: 132, time: 3650.717s, loss: 0.182, train accuracy: 0.945\n",
      "epoch: 132, time: 3651.963s, loss: 0.210, train accuracy: 0.914\n",
      "epoch: 132, time: 3653.210s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 132, time: 3654.466s, loss: 0.143, train accuracy: 0.945\n",
      "epoch: 132, time: 3655.719s, loss: 0.150, train accuracy: 0.945\n",
      "epoch: 132, time: 3656.974s, loss: 0.161, train accuracy: 0.930\n",
      "epoch: 132, time: 3658.219s, loss: 0.252, train accuracy: 0.891\n",
      "epoch: 132, time: 3659.457s, loss: 0.197, train accuracy: 0.906\n",
      "epoch: 132, time: 3660.705s, loss: 0.208, train accuracy: 0.945\n",
      "epoch: 132, time: 3662.008s, loss: 0.221, train accuracy: 0.914\n",
      "epoch: 132, time: 3663.252s, loss: 0.301, train accuracy: 0.914\n",
      "epoch: 132, time: 3664.513s, loss: 0.121, train accuracy: 0.977\n",
      "epoch: 132, time: 3665.778s, loss: 0.210, train accuracy: 0.922\n",
      "epoch: 132, time: 3667.062s, loss: 0.115, train accuracy: 0.969\n",
      "epoch: 132, time: 3668.303s, loss: 0.228, train accuracy: 0.914\n",
      "epoch: 132, time: 3669.553s, loss: 0.306, train accuracy: 0.867\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 133, time: 3672.434s, loss: 0.187, train accuracy: 0.938\n",
      "epoch: 133, time: 3673.688s, loss: 0.268, train accuracy: 0.906\n",
      "epoch: 133, time: 3674.934s, loss: 0.278, train accuracy: 0.906\n",
      "epoch: 133, time: 3676.191s, loss: 0.107, train accuracy: 0.977\n",
      "epoch: 133, time: 3677.435s, loss: 0.243, train accuracy: 0.914\n",
      "epoch: 133, time: 3678.696s, loss: 0.186, train accuracy: 0.914\n",
      "epoch: 133, time: 3679.935s, loss: 0.264, train accuracy: 0.891\n",
      "epoch: 133, time: 3681.174s, loss: 0.188, train accuracy: 0.930\n",
      "epoch: 133, time: 3682.419s, loss: 0.104, train accuracy: 0.961\n",
      "epoch: 133, time: 3683.696s, loss: 0.265, train accuracy: 0.906\n",
      "epoch: 133, time: 3684.938s, loss: 0.137, train accuracy: 0.945\n",
      "epoch: 133, time: 3686.217s, loss: 0.315, train accuracy: 0.867\n",
      "epoch: 133, time: 3687.491s, loss: 0.234, train accuracy: 0.922\n",
      "epoch: 133, time: 3688.881s, loss: 0.196, train accuracy: 0.945\n",
      "epoch: 133, time: 3690.126s, loss: 0.158, train accuracy: 0.930\n",
      "epoch: 133, time: 3691.368s, loss: 0.204, train accuracy: 0.922\n",
      "epoch: 133, time: 3692.687s, loss: 0.113, train accuracy: 0.977\n",
      "epoch: 133, time: 3693.930s, loss: 0.181, train accuracy: 0.961\n",
      "epoch: 133, time: 3695.187s, loss: 0.252, train accuracy: 0.906\n",
      "epoch: 133, time: 3696.454s, loss: 0.202, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 134, time: 3699.311s, loss: 0.227, train accuracy: 0.906\n",
      "epoch: 134, time: 3700.580s, loss: 0.155, train accuracy: 0.953\n",
      "epoch: 134, time: 3701.826s, loss: 0.206, train accuracy: 0.938\n",
      "epoch: 134, time: 3703.072s, loss: 0.194, train accuracy: 0.945\n",
      "epoch: 134, time: 3704.355s, loss: 0.181, train accuracy: 0.953\n",
      "epoch: 134, time: 3705.612s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 134, time: 3706.852s, loss: 0.267, train accuracy: 0.922\n",
      "epoch: 134, time: 3708.104s, loss: 0.220, train accuracy: 0.930\n",
      "epoch: 134, time: 3709.344s, loss: 0.255, train accuracy: 0.922\n",
      "epoch: 134, time: 3710.594s, loss: 0.211, train accuracy: 0.906\n",
      "epoch: 134, time: 3712.004s, loss: 0.129, train accuracy: 0.969\n",
      "epoch: 134, time: 3713.269s, loss: 0.194, train accuracy: 0.945\n",
      "epoch: 134, time: 3714.516s, loss: 0.198, train accuracy: 0.938\n",
      "epoch: 134, time: 3715.780s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 134, time: 3717.036s, loss: 0.237, train accuracy: 0.906\n",
      "epoch: 134, time: 3718.277s, loss: 0.258, train accuracy: 0.906\n",
      "epoch: 134, time: 3719.515s, loss: 0.123, train accuracy: 0.945\n",
      "epoch: 134, time: 3720.763s, loss: 0.205, train accuracy: 0.930\n",
      "epoch: 134, time: 3722.010s, loss: 0.229, train accuracy: 0.914\n",
      "epoch: 134, time: 3723.274s, loss: 0.326, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 135, time: 3726.054s, loss: 0.273, train accuracy: 0.898\n",
      "epoch: 135, time: 3727.377s, loss: 0.139, train accuracy: 0.961\n",
      "epoch: 135, time: 3728.677s, loss: 0.187, train accuracy: 0.930\n",
      "epoch: 135, time: 3730.046s, loss: 0.193, train accuracy: 0.922\n",
      "epoch: 135, time: 3731.394s, loss: 0.346, train accuracy: 0.906\n",
      "epoch: 135, time: 3732.705s, loss: 0.204, train accuracy: 0.922\n",
      "epoch: 135, time: 3734.014s, loss: 0.233, train accuracy: 0.914\n",
      "epoch: 135, time: 3735.316s, loss: 0.247, train accuracy: 0.898\n",
      "epoch: 135, time: 3736.632s, loss: 0.125, train accuracy: 0.945\n",
      "epoch: 135, time: 3737.940s, loss: 0.395, train accuracy: 0.844\n",
      "epoch: 135, time: 3739.311s, loss: 0.248, train accuracy: 0.930\n",
      "epoch: 135, time: 3740.606s, loss: 0.172, train accuracy: 0.945\n",
      "epoch: 135, time: 3741.898s, loss: 0.162, train accuracy: 0.945\n",
      "epoch: 135, time: 3743.202s, loss: 0.196, train accuracy: 0.938\n",
      "epoch: 135, time: 3744.501s, loss: 0.158, train accuracy: 0.938\n",
      "epoch: 135, time: 3745.822s, loss: 0.230, train accuracy: 0.914\n",
      "epoch: 135, time: 3747.144s, loss: 0.205, train accuracy: 0.930\n",
      "epoch: 135, time: 3748.468s, loss: 0.177, train accuracy: 0.953\n",
      "epoch: 135, time: 3749.761s, loss: 0.166, train accuracy: 0.930\n",
      "epoch: 135, time: 3751.057s, loss: 0.212, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.845\n",
      "epoch: 136, time: 3753.968s, loss: 0.148, train accuracy: 0.953\n",
      "epoch: 136, time: 3755.321s, loss: 0.174, train accuracy: 0.922\n",
      "epoch: 136, time: 3756.623s, loss: 0.161, train accuracy: 0.938\n",
      "epoch: 136, time: 3757.918s, loss: 0.176, train accuracy: 0.930\n",
      "epoch: 136, time: 3759.239s, loss: 0.236, train accuracy: 0.898\n",
      "epoch: 136, time: 3760.537s, loss: 0.157, train accuracy: 0.930\n",
      "epoch: 136, time: 3761.856s, loss: 0.251, train accuracy: 0.875\n",
      "epoch: 136, time: 3763.167s, loss: 0.165, train accuracy: 0.922\n",
      "epoch: 136, time: 3764.499s, loss: 0.190, train accuracy: 0.961\n",
      "epoch: 136, time: 3765.795s, loss: 0.269, train accuracy: 0.906\n",
      "epoch: 136, time: 3767.119s, loss: 0.293, train accuracy: 0.898\n",
      "epoch: 136, time: 3768.502s, loss: 0.196, train accuracy: 0.922\n",
      "epoch: 136, time: 3769.869s, loss: 0.243, train accuracy: 0.891\n",
      "epoch: 136, time: 3771.182s, loss: 0.208, train accuracy: 0.891\n",
      "epoch: 136, time: 3772.513s, loss: 0.156, train accuracy: 0.953\n",
      "epoch: 136, time: 3773.846s, loss: 0.201, train accuracy: 0.938\n",
      "epoch: 136, time: 3775.185s, loss: 0.162, train accuracy: 0.961\n",
      "epoch: 136, time: 3776.476s, loss: 0.299, train accuracy: 0.906\n",
      "epoch: 136, time: 3777.827s, loss: 0.175, train accuracy: 0.906\n",
      "epoch: 136, time: 3779.130s, loss: 1.081, train accuracy: 0.773\n",
      "Accuracy on the test set: 0.651\n",
      "epoch: 137, time: 3782.076s, loss: 1.271, train accuracy: 0.617\n",
      "epoch: 137, time: 3783.400s, loss: 0.760, train accuracy: 0.703\n",
      "epoch: 137, time: 3784.707s, loss: 0.532, train accuracy: 0.789\n",
      "epoch: 137, time: 3786.015s, loss: 0.474, train accuracy: 0.820\n",
      "epoch: 137, time: 3787.344s, loss: 0.541, train accuracy: 0.844\n",
      "epoch: 137, time: 3788.635s, loss: 0.437, train accuracy: 0.836\n",
      "epoch: 137, time: 3789.928s, loss: 0.673, train accuracy: 0.742\n",
      "epoch: 137, time: 3791.260s, loss: 0.341, train accuracy: 0.898\n",
      "epoch: 137, time: 3792.630s, loss: 0.475, train accuracy: 0.852\n",
      "epoch: 137, time: 3793.933s, loss: 0.260, train accuracy: 0.906\n",
      "epoch: 137, time: 3795.224s, loss: 0.258, train accuracy: 0.883\n",
      "epoch: 137, time: 3796.525s, loss: 0.301, train accuracy: 0.906\n",
      "epoch: 137, time: 3797.878s, loss: 0.537, train accuracy: 0.805\n",
      "epoch: 137, time: 3799.209s, loss: 0.510, train accuracy: 0.820\n",
      "epoch: 137, time: 3800.518s, loss: 0.451, train accuracy: 0.820\n",
      "epoch: 137, time: 3801.834s, loss: 0.414, train accuracy: 0.844\n",
      "epoch: 137, time: 3803.142s, loss: 0.428, train accuracy: 0.875\n",
      "epoch: 137, time: 3804.438s, loss: 0.206, train accuracy: 0.938\n",
      "epoch: 137, time: 3805.745s, loss: 0.407, train accuracy: 0.875\n",
      "epoch: 137, time: 3807.038s, loss: 0.281, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.831\n",
      "epoch: 138, time: 3810.010s, loss: 0.342, train accuracy: 0.875\n",
      "epoch: 138, time: 3811.335s, loss: 0.239, train accuracy: 0.906\n",
      "epoch: 138, time: 3812.651s, loss: 0.228, train accuracy: 0.922\n",
      "epoch: 138, time: 3813.988s, loss: 0.178, train accuracy: 0.945\n",
      "epoch: 138, time: 3815.281s, loss: 0.351, train accuracy: 0.836\n",
      "epoch: 138, time: 3816.593s, loss: 0.226, train accuracy: 0.914\n",
      "epoch: 138, time: 3817.914s, loss: 0.259, train accuracy: 0.914\n",
      "epoch: 138, time: 3819.223s, loss: 0.757, train accuracy: 0.875\n",
      "epoch: 138, time: 3820.530s, loss: 0.353, train accuracy: 0.883\n",
      "epoch: 138, time: 3821.846s, loss: 0.298, train accuracy: 0.891\n",
      "epoch: 138, time: 3823.144s, loss: 0.388, train accuracy: 0.852\n",
      "epoch: 138, time: 3824.499s, loss: 0.233, train accuracy: 0.922\n",
      "epoch: 138, time: 3825.830s, loss: 0.280, train accuracy: 0.906\n",
      "epoch: 138, time: 3827.132s, loss: 0.242, train accuracy: 0.922\n",
      "epoch: 138, time: 3828.429s, loss: 0.176, train accuracy: 0.914\n",
      "epoch: 138, time: 3829.755s, loss: 0.193, train accuracy: 0.938\n",
      "epoch: 138, time: 3831.051s, loss: 0.234, train accuracy: 0.898\n",
      "epoch: 138, time: 3832.377s, loss: 0.186, train accuracy: 0.930\n",
      "epoch: 138, time: 3833.684s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 138, time: 3835.007s, loss: 0.178, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 139, time: 3837.947s, loss: 0.158, train accuracy: 0.953\n",
      "epoch: 139, time: 3839.280s, loss: 0.227, train accuracy: 0.906\n",
      "epoch: 139, time: 3840.577s, loss: 0.179, train accuracy: 0.938\n",
      "epoch: 139, time: 3841.897s, loss: 0.199, train accuracy: 0.906\n",
      "epoch: 139, time: 3843.219s, loss: 0.215, train accuracy: 0.914\n",
      "epoch: 139, time: 3844.508s, loss: 0.354, train accuracy: 0.891\n",
      "epoch: 139, time: 3845.822s, loss: 0.196, train accuracy: 0.938\n",
      "epoch: 139, time: 3847.133s, loss: 0.181, train accuracy: 0.938\n",
      "epoch: 139, time: 3848.442s, loss: 0.307, train accuracy: 0.875\n",
      "epoch: 139, time: 3849.758s, loss: 0.279, train accuracy: 0.891\n",
      "epoch: 139, time: 3851.102s, loss: 0.250, train accuracy: 0.906\n",
      "epoch: 139, time: 3852.407s, loss: 0.266, train accuracy: 0.898\n",
      "epoch: 139, time: 3853.737s, loss: 0.201, train accuracy: 0.922\n",
      "epoch: 139, time: 3855.031s, loss: 0.371, train accuracy: 0.891\n",
      "epoch: 139, time: 3856.394s, loss: 0.167, train accuracy: 0.938\n",
      "epoch: 139, time: 3857.694s, loss: 0.183, train accuracy: 0.930\n",
      "epoch: 139, time: 3859.008s, loss: 0.218, train accuracy: 0.898\n",
      "epoch: 139, time: 3860.303s, loss: 0.227, train accuracy: 0.945\n",
      "epoch: 139, time: 3861.598s, loss: 0.190, train accuracy: 0.922\n",
      "epoch: 139, time: 3862.936s, loss: 0.160, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.845\n",
      "epoch: 140, time: 3865.972s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 140, time: 3867.291s, loss: 0.237, train accuracy: 0.898\n",
      "epoch: 140, time: 3868.592s, loss: 0.118, train accuracy: 0.961\n",
      "epoch: 140, time: 3869.883s, loss: 0.219, train accuracy: 0.930\n",
      "epoch: 140, time: 3871.188s, loss: 0.185, train accuracy: 0.938\n",
      "epoch: 140, time: 3872.513s, loss: 0.155, train accuracy: 0.961\n",
      "epoch: 140, time: 3873.800s, loss: 0.265, train accuracy: 0.906\n",
      "epoch: 140, time: 3875.115s, loss: 0.201, train accuracy: 0.906\n",
      "epoch: 140, time: 3876.444s, loss: 0.221, train accuracy: 0.945\n",
      "epoch: 140, time: 3877.776s, loss: 0.215, train accuracy: 0.922\n",
      "epoch: 140, time: 3879.076s, loss: 0.242, train accuracy: 0.945\n",
      "epoch: 140, time: 3880.384s, loss: 0.230, train accuracy: 0.914\n",
      "epoch: 140, time: 3881.690s, loss: 0.186, train accuracy: 0.906\n",
      "epoch: 140, time: 3882.991s, loss: 0.211, train accuracy: 0.914\n",
      "epoch: 140, time: 3884.332s, loss: 0.243, train accuracy: 0.961\n",
      "epoch: 140, time: 3885.654s, loss: 0.164, train accuracy: 0.938\n",
      "epoch: 140, time: 3886.969s, loss: 0.214, train accuracy: 0.938\n",
      "epoch: 140, time: 3888.298s, loss: 0.252, train accuracy: 0.914\n",
      "epoch: 140, time: 3889.596s, loss: 0.209, train accuracy: 0.930\n",
      "epoch: 140, time: 3890.923s, loss: 0.204, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 141, time: 3893.905s, loss: 0.243, train accuracy: 0.922\n",
      "epoch: 141, time: 3895.212s, loss: 0.152, train accuracy: 0.945\n",
      "epoch: 141, time: 3896.513s, loss: 0.175, train accuracy: 0.922\n",
      "epoch: 141, time: 3897.835s, loss: 0.172, train accuracy: 0.922\n",
      "epoch: 141, time: 3899.175s, loss: 0.189, train accuracy: 0.922\n",
      "epoch: 141, time: 3900.469s, loss: 0.276, train accuracy: 0.906\n",
      "epoch: 141, time: 3901.766s, loss: 0.120, train accuracy: 0.969\n",
      "epoch: 141, time: 3903.061s, loss: 0.080, train accuracy: 0.984\n",
      "epoch: 141, time: 3904.381s, loss: 0.120, train accuracy: 0.961\n",
      "epoch: 141, time: 3905.681s, loss: 0.201, train accuracy: 0.930\n",
      "epoch: 141, time: 3907.043s, loss: 0.164, train accuracy: 0.945\n",
      "epoch: 141, time: 3908.360s, loss: 0.137, train accuracy: 0.953\n",
      "epoch: 141, time: 3909.650s, loss: 0.241, train accuracy: 0.914\n",
      "epoch: 141, time: 3910.943s, loss: 0.173, train accuracy: 0.930\n",
      "epoch: 141, time: 3912.252s, loss: 0.247, train accuracy: 0.930\n",
      "epoch: 141, time: 3913.564s, loss: 0.195, train accuracy: 0.945\n",
      "epoch: 141, time: 3914.885s, loss: 0.172, train accuracy: 0.945\n",
      "epoch: 141, time: 3916.215s, loss: 0.253, train accuracy: 0.922\n",
      "epoch: 141, time: 3917.568s, loss: 0.248, train accuracy: 0.906\n",
      "epoch: 141, time: 3918.890s, loss: 0.269, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 142, time: 3921.996s, loss: 0.172, train accuracy: 0.945\n",
      "epoch: 142, time: 3923.319s, loss: 0.162, train accuracy: 0.922\n",
      "epoch: 142, time: 3924.618s, loss: 0.230, train accuracy: 0.914\n",
      "epoch: 142, time: 3925.926s, loss: 0.142, train accuracy: 0.961\n",
      "epoch: 142, time: 3927.242s, loss: 0.182, train accuracy: 0.922\n",
      "epoch: 142, time: 3928.568s, loss: 0.137, train accuracy: 0.945\n",
      "epoch: 142, time: 3929.922s, loss: 0.125, train accuracy: 0.969\n",
      "epoch: 142, time: 3931.264s, loss: 0.266, train accuracy: 0.914\n",
      "epoch: 142, time: 3932.595s, loss: 0.119, train accuracy: 0.945\n",
      "epoch: 142, time: 3933.896s, loss: 0.244, train accuracy: 0.898\n",
      "epoch: 142, time: 3935.205s, loss: 0.243, train accuracy: 0.938\n",
      "epoch: 142, time: 3936.509s, loss: 0.225, train accuracy: 0.898\n",
      "epoch: 142, time: 3937.866s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 142, time: 3939.202s, loss: 0.148, train accuracy: 0.938\n",
      "epoch: 142, time: 3940.518s, loss: 0.173, train accuracy: 0.922\n",
      "epoch: 142, time: 3941.812s, loss: 0.258, train accuracy: 0.883\n",
      "epoch: 142, time: 3943.134s, loss: 0.142, train accuracy: 0.938\n",
      "epoch: 142, time: 3944.446s, loss: 0.213, train accuracy: 0.914\n",
      "epoch: 142, time: 3945.783s, loss: 0.161, train accuracy: 0.930\n",
      "epoch: 142, time: 3947.086s, loss: 0.243, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 143, time: 3950.040s, loss: 0.157, train accuracy: 0.953\n",
      "epoch: 143, time: 3951.366s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 143, time: 3952.674s, loss: 0.236, train accuracy: 0.906\n",
      "epoch: 143, time: 3953.987s, loss: 0.176, train accuracy: 0.938\n",
      "epoch: 143, time: 3955.285s, loss: 0.148, train accuracy: 0.945\n",
      "epoch: 143, time: 3956.610s, loss: 0.164, train accuracy: 0.930\n",
      "epoch: 143, time: 3957.939s, loss: 0.141, train accuracy: 0.945\n",
      "epoch: 143, time: 3959.246s, loss: 0.198, train accuracy: 0.938\n",
      "epoch: 143, time: 3960.559s, loss: 0.183, train accuracy: 0.938\n",
      "epoch: 143, time: 3961.855s, loss: 0.141, train accuracy: 0.969\n",
      "epoch: 143, time: 3963.157s, loss: 0.168, train accuracy: 0.922\n",
      "epoch: 143, time: 3964.474s, loss: 0.181, train accuracy: 0.922\n",
      "epoch: 143, time: 3965.778s, loss: 0.201, train accuracy: 0.930\n",
      "epoch: 143, time: 3967.082s, loss: 0.251, train accuracy: 0.906\n",
      "epoch: 143, time: 3968.394s, loss: 0.131, train accuracy: 0.938\n",
      "epoch: 143, time: 3969.713s, loss: 0.142, train accuracy: 0.938\n",
      "epoch: 143, time: 3971.032s, loss: 0.256, train accuracy: 0.938\n",
      "epoch: 143, time: 3972.359s, loss: 0.252, train accuracy: 0.891\n",
      "epoch: 143, time: 3973.655s, loss: 0.290, train accuracy: 0.891\n",
      "epoch: 143, time: 3974.986s, loss: 0.150, train accuracy: 0.945\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 144, time: 3977.941s, loss: 0.253, train accuracy: 0.922\n",
      "epoch: 144, time: 3979.300s, loss: 0.135, train accuracy: 0.969\n",
      "epoch: 144, time: 3980.608s, loss: 0.221, train accuracy: 0.922\n",
      "epoch: 144, time: 3981.937s, loss: 0.288, train accuracy: 0.891\n",
      "epoch: 144, time: 3983.252s, loss: 0.236, train accuracy: 0.914\n",
      "epoch: 144, time: 3984.557s, loss: 0.151, train accuracy: 0.930\n",
      "epoch: 144, time: 3985.863s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 144, time: 3987.201s, loss: 0.224, train accuracy: 0.906\n",
      "epoch: 144, time: 3988.521s, loss: 0.235, train accuracy: 0.930\n",
      "epoch: 144, time: 3989.857s, loss: 0.289, train accuracy: 0.922\n",
      "epoch: 144, time: 3991.198s, loss: 0.224, train accuracy: 0.914\n",
      "epoch: 144, time: 3992.518s, loss: 0.252, train accuracy: 0.914\n",
      "epoch: 144, time: 3993.832s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 144, time: 3995.150s, loss: 0.169, train accuracy: 0.938\n",
      "epoch: 144, time: 3996.465s, loss: 0.205, train accuracy: 0.938\n",
      "epoch: 144, time: 3997.788s, loss: 0.330, train accuracy: 0.914\n",
      "epoch: 144, time: 3999.098s, loss: 0.127, train accuracy: 0.930\n",
      "epoch: 144, time: 4000.424s, loss: 0.230, train accuracy: 0.930\n",
      "epoch: 144, time: 4001.735s, loss: 0.120, train accuracy: 0.977\n",
      "epoch: 144, time: 4003.070s, loss: 0.179, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 145, time: 4006.086s, loss: 0.155, train accuracy: 0.953\n",
      "epoch: 145, time: 4007.461s, loss: 0.241, train accuracy: 0.922\n",
      "epoch: 145, time: 4008.783s, loss: 0.249, train accuracy: 0.898\n",
      "epoch: 145, time: 4010.101s, loss: 0.157, train accuracy: 0.945\n",
      "epoch: 145, time: 4011.411s, loss: 0.158, train accuracy: 0.938\n",
      "epoch: 145, time: 4012.740s, loss: 0.252, train accuracy: 0.930\n",
      "epoch: 145, time: 4014.037s, loss: 0.134, train accuracy: 0.977\n",
      "epoch: 145, time: 4015.360s, loss: 0.124, train accuracy: 0.945\n",
      "epoch: 145, time: 4016.685s, loss: 0.162, train accuracy: 0.945\n",
      "epoch: 145, time: 4018.007s, loss: 0.231, train accuracy: 0.914\n",
      "epoch: 145, time: 4019.306s, loss: 0.297, train accuracy: 0.875\n",
      "epoch: 145, time: 4020.601s, loss: 0.240, train accuracy: 0.938\n",
      "epoch: 145, time: 4021.891s, loss: 0.159, train accuracy: 0.953\n",
      "epoch: 145, time: 4023.203s, loss: 0.152, train accuracy: 0.961\n",
      "epoch: 145, time: 4024.512s, loss: 0.210, train accuracy: 0.930\n",
      "epoch: 145, time: 4025.839s, loss: 0.159, train accuracy: 0.930\n",
      "epoch: 145, time: 4027.147s, loss: 0.181, train accuracy: 0.945\n",
      "epoch: 145, time: 4028.484s, loss: 0.176, train accuracy: 0.945\n",
      "epoch: 145, time: 4029.795s, loss: 0.202, train accuracy: 0.945\n",
      "epoch: 145, time: 4031.101s, loss: 0.192, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 146, time: 4033.966s, loss: 0.185, train accuracy: 0.953\n",
      "epoch: 146, time: 4035.276s, loss: 0.118, train accuracy: 0.961\n",
      "epoch: 146, time: 4036.615s, loss: 0.152, train accuracy: 0.953\n",
      "epoch: 146, time: 4037.952s, loss: 0.151, train accuracy: 0.953\n",
      "epoch: 146, time: 4039.275s, loss: 0.156, train accuracy: 0.945\n",
      "epoch: 146, time: 4040.590s, loss: 0.168, train accuracy: 0.945\n",
      "epoch: 146, time: 4041.886s, loss: 0.328, train accuracy: 0.867\n",
      "epoch: 146, time: 4043.183s, loss: 0.115, train accuracy: 0.961\n",
      "epoch: 146, time: 4044.486s, loss: 0.224, train accuracy: 0.930\n",
      "epoch: 146, time: 4045.821s, loss: 0.168, train accuracy: 0.938\n",
      "epoch: 146, time: 4047.133s, loss: 0.151, train accuracy: 0.953\n",
      "epoch: 146, time: 4048.418s, loss: 0.196, train accuracy: 0.930\n",
      "epoch: 146, time: 4049.720s, loss: 0.187, train accuracy: 0.945\n",
      "epoch: 146, time: 4051.091s, loss: 0.265, train accuracy: 0.914\n",
      "epoch: 146, time: 4052.451s, loss: 0.155, train accuracy: 0.930\n",
      "epoch: 146, time: 4053.777s, loss: 0.228, train accuracy: 0.906\n",
      "epoch: 146, time: 4055.094s, loss: 0.200, train accuracy: 0.922\n",
      "epoch: 146, time: 4056.391s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 146, time: 4057.706s, loss: 0.218, train accuracy: 0.898\n",
      "epoch: 146, time: 4058.998s, loss: 0.127, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.776\n",
      "epoch: 147, time: 4061.941s, loss: 0.238, train accuracy: 0.914\n",
      "epoch: 147, time: 4063.273s, loss: 0.232, train accuracy: 0.922\n",
      "epoch: 147, time: 4064.572s, loss: 0.252, train accuracy: 0.914\n",
      "epoch: 147, time: 4065.886s, loss: 0.255, train accuracy: 0.898\n",
      "epoch: 147, time: 4067.183s, loss: 0.285, train accuracy: 0.898\n",
      "epoch: 147, time: 4068.499s, loss: 0.185, train accuracy: 0.906\n",
      "epoch: 147, time: 4069.828s, loss: 0.164, train accuracy: 0.938\n",
      "epoch: 147, time: 4071.178s, loss: 0.211, train accuracy: 0.898\n",
      "epoch: 147, time: 4072.474s, loss: 0.307, train accuracy: 0.875\n",
      "epoch: 147, time: 4073.807s, loss: 0.168, train accuracy: 0.930\n",
      "epoch: 147, time: 4075.132s, loss: 0.169, train accuracy: 0.922\n",
      "epoch: 147, time: 4076.429s, loss: 0.208, train accuracy: 0.938\n",
      "epoch: 147, time: 4077.753s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 147, time: 4079.073s, loss: 0.211, train accuracy: 0.922\n",
      "epoch: 147, time: 4080.381s, loss: 0.221, train accuracy: 0.930\n",
      "epoch: 147, time: 4081.743s, loss: 0.259, train accuracy: 0.906\n",
      "epoch: 147, time: 4083.054s, loss: 0.356, train accuracy: 0.875\n",
      "epoch: 147, time: 4084.373s, loss: 0.244, train accuracy: 0.891\n",
      "epoch: 147, time: 4085.667s, loss: 0.327, train accuracy: 0.891\n",
      "epoch: 147, time: 4086.960s, loss: 0.240, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 148, time: 4089.946s, loss: 0.240, train accuracy: 0.914\n",
      "epoch: 148, time: 4091.259s, loss: 0.190, train accuracy: 0.914\n",
      "epoch: 148, time: 4092.562s, loss: 0.149, train accuracy: 0.953\n",
      "epoch: 148, time: 4093.884s, loss: 0.154, train accuracy: 0.930\n",
      "epoch: 148, time: 4095.201s, loss: 0.217, train accuracy: 0.914\n",
      "epoch: 148, time: 4096.504s, loss: 0.211, train accuracy: 0.930\n",
      "epoch: 148, time: 4097.875s, loss: 0.215, train accuracy: 0.922\n",
      "epoch: 148, time: 4099.191s, loss: 0.323, train accuracy: 0.891\n",
      "epoch: 148, time: 4100.511s, loss: 0.163, train accuracy: 0.922\n",
      "epoch: 148, time: 4101.825s, loss: 0.134, train accuracy: 0.945\n",
      "epoch: 148, time: 4103.132s, loss: 0.193, train accuracy: 0.938\n",
      "epoch: 148, time: 4104.434s, loss: 0.176, train accuracy: 0.922\n",
      "epoch: 148, time: 4105.734s, loss: 0.164, train accuracy: 0.914\n",
      "epoch: 148, time: 4107.064s, loss: 0.280, train accuracy: 0.898\n",
      "epoch: 148, time: 4108.411s, loss: 0.247, train accuracy: 0.922\n",
      "epoch: 148, time: 4109.714s, loss: 0.195, train accuracy: 0.922\n",
      "epoch: 148, time: 4111.021s, loss: 0.235, train accuracy: 0.898\n",
      "epoch: 148, time: 4112.323s, loss: 0.234, train accuracy: 0.906\n",
      "epoch: 148, time: 4113.643s, loss: 0.231, train accuracy: 0.906\n",
      "epoch: 148, time: 4114.954s, loss: 0.241, train accuracy: 0.891\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 149, time: 4117.976s, loss: 0.223, train accuracy: 0.922\n",
      "epoch: 149, time: 4119.313s, loss: 0.204, train accuracy: 0.914\n",
      "epoch: 149, time: 4120.628s, loss: 0.109, train accuracy: 0.961\n",
      "epoch: 149, time: 4121.931s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 149, time: 4123.265s, loss: 0.139, train accuracy: 0.945\n",
      "epoch: 149, time: 4124.582s, loss: 0.170, train accuracy: 0.938\n",
      "epoch: 149, time: 4125.904s, loss: 0.184, train accuracy: 0.922\n",
      "epoch: 149, time: 4127.201s, loss: 0.091, train accuracy: 0.969\n",
      "epoch: 149, time: 4128.517s, loss: 0.196, train accuracy: 0.945\n",
      "epoch: 149, time: 4129.829s, loss: 0.224, train accuracy: 0.945\n",
      "epoch: 149, time: 4131.125s, loss: 0.219, train accuracy: 0.945\n",
      "epoch: 149, time: 4132.461s, loss: 0.135, train accuracy: 0.945\n",
      "epoch: 149, time: 4133.790s, loss: 0.101, train accuracy: 0.961\n",
      "epoch: 149, time: 4135.093s, loss: 0.125, train accuracy: 0.953\n",
      "epoch: 149, time: 4136.388s, loss: 0.143, train accuracy: 0.938\n",
      "epoch: 149, time: 4137.689s, loss: 0.219, train accuracy: 0.938\n",
      "epoch: 149, time: 4139.017s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 149, time: 4140.331s, loss: 0.155, train accuracy: 0.945\n",
      "epoch: 149, time: 4141.652s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 149, time: 4142.972s, loss: 0.227, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 150, time: 4145.923s, loss: 0.161, train accuracy: 0.945\n",
      "epoch: 150, time: 4147.234s, loss: 0.146, train accuracy: 0.953\n",
      "epoch: 150, time: 4148.543s, loss: 0.071, train accuracy: 0.984\n",
      "epoch: 150, time: 4149.855s, loss: 0.206, train accuracy: 0.922\n",
      "epoch: 150, time: 4151.186s, loss: 0.176, train accuracy: 0.961\n",
      "epoch: 150, time: 4152.483s, loss: 0.186, train accuracy: 0.930\n",
      "epoch: 150, time: 4153.808s, loss: 0.194, train accuracy: 0.945\n",
      "epoch: 150, time: 4155.109s, loss: 0.196, train accuracy: 0.930\n",
      "epoch: 150, time: 4156.422s, loss: 0.158, train accuracy: 0.938\n",
      "epoch: 150, time: 4157.751s, loss: 0.179, train accuracy: 0.930\n",
      "epoch: 150, time: 4159.044s, loss: 0.274, train accuracy: 0.891\n",
      "epoch: 150, time: 4160.340s, loss: 0.194, train accuracy: 0.938\n",
      "epoch: 150, time: 4161.664s, loss: 0.156, train accuracy: 0.930\n",
      "epoch: 150, time: 4162.978s, loss: 0.178, train accuracy: 0.914\n",
      "epoch: 150, time: 4164.306s, loss: 0.233, train accuracy: 0.898\n",
      "epoch: 150, time: 4165.633s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 150, time: 4166.954s, loss: 0.249, train accuracy: 0.906\n",
      "epoch: 150, time: 4168.313s, loss: 0.209, train accuracy: 0.930\n",
      "epoch: 150, time: 4169.608s, loss: 0.179, train accuracy: 0.930\n",
      "epoch: 150, time: 4170.921s, loss: 0.237, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 151, time: 4174.020s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 151, time: 4175.404s, loss: 0.197, train accuracy: 0.945\n",
      "epoch: 151, time: 4176.717s, loss: 0.095, train accuracy: 0.969\n",
      "epoch: 151, time: 4178.059s, loss: 0.219, train accuracy: 0.922\n",
      "epoch: 151, time: 4179.359s, loss: 0.338, train accuracy: 0.867\n",
      "epoch: 151, time: 4180.677s, loss: 0.129, train accuracy: 0.961\n",
      "epoch: 151, time: 4181.986s, loss: 0.294, train accuracy: 0.875\n",
      "epoch: 151, time: 4183.299s, loss: 0.220, train accuracy: 0.922\n",
      "epoch: 151, time: 4184.611s, loss: 0.208, train accuracy: 0.922\n",
      "epoch: 151, time: 4185.919s, loss: 0.197, train accuracy: 0.938\n",
      "epoch: 151, time: 4187.212s, loss: 0.214, train accuracy: 0.930\n",
      "epoch: 151, time: 4188.525s, loss: 0.221, train accuracy: 0.898\n",
      "epoch: 151, time: 4189.845s, loss: 0.173, train accuracy: 0.930\n",
      "epoch: 151, time: 4191.169s, loss: 0.198, train accuracy: 0.914\n",
      "epoch: 151, time: 4192.475s, loss: 0.226, train accuracy: 0.906\n",
      "epoch: 151, time: 4193.814s, loss: 0.179, train accuracy: 0.930\n",
      "epoch: 151, time: 4195.145s, loss: 0.246, train accuracy: 0.922\n",
      "epoch: 151, time: 4196.448s, loss: 0.156, train accuracy: 0.945\n",
      "epoch: 151, time: 4197.778s, loss: 0.184, train accuracy: 0.938\n",
      "epoch: 151, time: 4199.091s, loss: 0.268, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.845\n",
      "epoch: 152, time: 4202.030s, loss: 0.138, train accuracy: 0.953\n",
      "epoch: 152, time: 4203.368s, loss: 0.207, train accuracy: 0.922\n",
      "epoch: 152, time: 4204.667s, loss: 0.193, train accuracy: 0.938\n",
      "epoch: 152, time: 4205.964s, loss: 0.168, train accuracy: 0.922\n",
      "epoch: 152, time: 4207.276s, loss: 0.134, train accuracy: 0.945\n",
      "epoch: 152, time: 4208.632s, loss: 0.174, train accuracy: 0.938\n",
      "epoch: 152, time: 4209.949s, loss: 0.242, train accuracy: 0.898\n",
      "epoch: 152, time: 4211.251s, loss: 0.178, train accuracy: 0.922\n",
      "epoch: 152, time: 4212.585s, loss: 0.169, train accuracy: 0.945\n",
      "epoch: 152, time: 4213.986s, loss: 0.121, train accuracy: 0.953\n",
      "epoch: 152, time: 4215.286s, loss: 0.248, train accuracy: 0.914\n",
      "epoch: 152, time: 4216.604s, loss: 0.209, train accuracy: 0.906\n",
      "epoch: 152, time: 4217.945s, loss: 0.184, train accuracy: 0.945\n",
      "epoch: 152, time: 4219.252s, loss: 0.096, train accuracy: 0.984\n",
      "epoch: 152, time: 4220.598s, loss: 0.243, train accuracy: 0.930\n",
      "epoch: 152, time: 4221.904s, loss: 0.157, train accuracy: 0.961\n",
      "epoch: 152, time: 4223.245s, loss: 0.184, train accuracy: 0.906\n",
      "epoch: 152, time: 4224.562s, loss: 0.220, train accuracy: 0.930\n",
      "epoch: 152, time: 4225.889s, loss: 0.166, train accuracy: 0.930\n",
      "epoch: 152, time: 4227.200s, loss: 0.151, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 153, time: 4230.157s, loss: 0.080, train accuracy: 0.969\n",
      "epoch: 153, time: 4231.519s, loss: 0.154, train accuracy: 0.945\n",
      "epoch: 153, time: 4232.861s, loss: 0.321, train accuracy: 0.914\n",
      "epoch: 153, time: 4234.167s, loss: 0.149, train accuracy: 0.953\n",
      "epoch: 153, time: 4235.489s, loss: 0.297, train accuracy: 0.891\n",
      "epoch: 153, time: 4236.797s, loss: 0.266, train accuracy: 0.883\n",
      "epoch: 153, time: 4238.097s, loss: 0.121, train accuracy: 0.945\n",
      "epoch: 153, time: 4239.402s, loss: 0.183, train accuracy: 0.938\n",
      "epoch: 153, time: 4240.715s, loss: 0.220, train accuracy: 0.922\n",
      "epoch: 153, time: 4242.014s, loss: 0.103, train accuracy: 0.961\n",
      "epoch: 153, time: 4243.336s, loss: 0.181, train accuracy: 0.930\n",
      "epoch: 153, time: 4244.650s, loss: 0.097, train accuracy: 0.953\n",
      "epoch: 153, time: 4245.975s, loss: 0.144, train accuracy: 0.953\n",
      "epoch: 153, time: 4247.291s, loss: 0.201, train accuracy: 0.938\n",
      "epoch: 153, time: 4248.591s, loss: 0.179, train accuracy: 0.930\n",
      "epoch: 153, time: 4249.938s, loss: 0.266, train accuracy: 0.898\n",
      "epoch: 153, time: 4251.258s, loss: 0.299, train accuracy: 0.867\n",
      "epoch: 153, time: 4252.573s, loss: 0.151, train accuracy: 0.922\n",
      "epoch: 153, time: 4253.894s, loss: 0.223, train accuracy: 0.938\n",
      "epoch: 153, time: 4255.203s, loss: 0.284, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.835\n",
      "epoch: 154, time: 4258.172s, loss: 0.205, train accuracy: 0.938\n",
      "epoch: 154, time: 4259.503s, loss: 0.132, train accuracy: 0.953\n",
      "epoch: 154, time: 4260.836s, loss: 0.149, train accuracy: 0.953\n",
      "epoch: 154, time: 4262.131s, loss: 0.158, train accuracy: 0.938\n",
      "epoch: 154, time: 4263.436s, loss: 0.148, train accuracy: 0.945\n",
      "epoch: 154, time: 4264.736s, loss: 0.184, train accuracy: 0.930\n",
      "epoch: 154, time: 4266.036s, loss: 0.194, train accuracy: 0.938\n",
      "epoch: 154, time: 4267.331s, loss: 0.250, train accuracy: 0.938\n",
      "epoch: 154, time: 4268.663s, loss: 0.134, train accuracy: 0.945\n",
      "epoch: 154, time: 4269.993s, loss: 0.161, train accuracy: 0.961\n",
      "epoch: 154, time: 4271.316s, loss: 0.151, train accuracy: 0.938\n",
      "epoch: 154, time: 4272.626s, loss: 0.271, train accuracy: 0.938\n",
      "epoch: 154, time: 4273.929s, loss: 0.080, train accuracy: 0.969\n",
      "epoch: 154, time: 4275.234s, loss: 0.200, train accuracy: 0.945\n",
      "epoch: 154, time: 4276.552s, loss: 0.212, train accuracy: 0.945\n",
      "epoch: 154, time: 4277.873s, loss: 0.206, train accuracy: 0.922\n",
      "epoch: 154, time: 4279.188s, loss: 0.299, train accuracy: 0.914\n",
      "epoch: 154, time: 4280.484s, loss: 0.146, train accuracy: 0.953\n",
      "epoch: 154, time: 4281.812s, loss: 0.172, train accuracy: 0.898\n",
      "epoch: 154, time: 4283.143s, loss: 0.113, train accuracy: 0.977\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 155, time: 4286.076s, loss: 0.201, train accuracy: 0.922\n",
      "epoch: 155, time: 4287.415s, loss: 0.153, train accuracy: 0.930\n",
      "epoch: 155, time: 4288.715s, loss: 0.147, train accuracy: 0.969\n",
      "epoch: 155, time: 4290.031s, loss: 0.262, train accuracy: 0.914\n",
      "epoch: 155, time: 4291.341s, loss: 0.277, train accuracy: 0.906\n",
      "epoch: 155, time: 4292.702s, loss: 0.110, train accuracy: 0.969\n",
      "epoch: 155, time: 4294.061s, loss: 0.115, train accuracy: 0.961\n",
      "epoch: 155, time: 4295.355s, loss: 0.203, train accuracy: 0.914\n",
      "epoch: 155, time: 4296.686s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 155, time: 4297.995s, loss: 0.143, train accuracy: 0.938\n",
      "epoch: 155, time: 4299.361s, loss: 0.196, train accuracy: 0.922\n",
      "epoch: 155, time: 4300.656s, loss: 0.208, train accuracy: 0.914\n",
      "epoch: 155, time: 4301.982s, loss: 0.248, train accuracy: 0.922\n",
      "epoch: 155, time: 4303.277s, loss: 0.159, train accuracy: 0.930\n",
      "epoch: 155, time: 4304.616s, loss: 0.257, train accuracy: 0.914\n",
      "epoch: 155, time: 4305.915s, loss: 0.249, train accuracy: 0.914\n",
      "epoch: 155, time: 4307.232s, loss: 0.189, train accuracy: 0.922\n",
      "epoch: 155, time: 4308.573s, loss: 0.302, train accuracy: 0.906\n",
      "epoch: 155, time: 4309.891s, loss: 0.215, train accuracy: 0.906\n",
      "epoch: 155, time: 4311.201s, loss: 0.216, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 156, time: 4314.134s, loss: 0.172, train accuracy: 0.938\n",
      "epoch: 156, time: 4315.495s, loss: 0.194, train accuracy: 0.938\n",
      "epoch: 156, time: 4316.854s, loss: 0.187, train accuracy: 0.930\n",
      "epoch: 156, time: 4318.193s, loss: 0.152, train accuracy: 0.945\n",
      "epoch: 156, time: 4319.506s, loss: 0.199, train accuracy: 0.930\n",
      "epoch: 156, time: 4320.824s, loss: 0.161, train accuracy: 0.930\n",
      "epoch: 156, time: 4322.140s, loss: 0.308, train accuracy: 0.906\n",
      "epoch: 156, time: 4323.492s, loss: 0.247, train accuracy: 0.891\n",
      "epoch: 156, time: 4324.846s, loss: 0.190, train accuracy: 0.922\n",
      "epoch: 156, time: 4326.138s, loss: 0.135, train accuracy: 0.938\n",
      "epoch: 156, time: 4327.507s, loss: 0.218, train accuracy: 0.938\n",
      "epoch: 156, time: 4328.839s, loss: 0.178, train accuracy: 0.930\n",
      "epoch: 156, time: 4330.157s, loss: 0.188, train accuracy: 0.945\n",
      "epoch: 156, time: 4331.456s, loss: 0.224, train accuracy: 0.891\n",
      "epoch: 156, time: 4332.753s, loss: 0.114, train accuracy: 0.961\n",
      "epoch: 156, time: 4334.058s, loss: 0.241, train accuracy: 0.898\n",
      "epoch: 156, time: 4335.372s, loss: 0.194, train accuracy: 0.922\n",
      "epoch: 156, time: 4336.685s, loss: 0.191, train accuracy: 0.961\n",
      "epoch: 156, time: 4337.998s, loss: 0.226, train accuracy: 0.914\n",
      "epoch: 156, time: 4339.297s, loss: 0.108, train accuracy: 0.977\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 157, time: 4342.264s, loss: 0.163, train accuracy: 0.938\n",
      "epoch: 157, time: 4343.578s, loss: 0.272, train accuracy: 0.930\n",
      "epoch: 157, time: 4344.908s, loss: 0.291, train accuracy: 0.898\n",
      "epoch: 157, time: 4346.210s, loss: 0.224, train accuracy: 0.891\n",
      "epoch: 157, time: 4347.510s, loss: 0.173, train accuracy: 0.953\n",
      "epoch: 157, time: 4348.861s, loss: 0.222, train accuracy: 0.922\n",
      "epoch: 157, time: 4350.181s, loss: 0.199, train accuracy: 0.922\n",
      "epoch: 157, time: 4351.513s, loss: 0.136, train accuracy: 0.945\n",
      "epoch: 157, time: 4352.869s, loss: 0.126, train accuracy: 0.945\n",
      "epoch: 157, time: 4354.213s, loss: 0.132, train accuracy: 0.953\n",
      "epoch: 157, time: 4355.540s, loss: 0.233, train accuracy: 0.914\n",
      "epoch: 157, time: 4356.828s, loss: 0.155, train accuracy: 0.922\n",
      "epoch: 157, time: 4358.133s, loss: 0.227, train accuracy: 0.891\n",
      "epoch: 157, time: 4359.431s, loss: 0.086, train accuracy: 0.961\n",
      "epoch: 157, time: 4360.757s, loss: 0.155, train accuracy: 0.945\n",
      "epoch: 157, time: 4362.083s, loss: 0.129, train accuracy: 0.945\n",
      "epoch: 157, time: 4363.387s, loss: 0.116, train accuracy: 0.961\n",
      "epoch: 157, time: 4364.689s, loss: 0.125, train accuracy: 0.945\n",
      "epoch: 157, time: 4366.004s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 157, time: 4367.297s, loss: 0.202, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 158, time: 4370.326s, loss: 0.096, train accuracy: 0.961\n",
      "epoch: 158, time: 4371.654s, loss: 0.105, train accuracy: 0.961\n",
      "epoch: 158, time: 4372.993s, loss: 0.151, train accuracy: 0.953\n",
      "epoch: 158, time: 4374.327s, loss: 0.129, train accuracy: 0.945\n",
      "epoch: 158, time: 4375.623s, loss: 0.106, train accuracy: 0.969\n",
      "epoch: 158, time: 4376.933s, loss: 0.159, train accuracy: 0.953\n",
      "epoch: 158, time: 4378.244s, loss: 0.189, train accuracy: 0.938\n",
      "epoch: 158, time: 4379.559s, loss: 0.159, train accuracy: 0.953\n",
      "epoch: 158, time: 4380.905s, loss: 0.162, train accuracy: 0.953\n",
      "epoch: 158, time: 4382.219s, loss: 0.146, train accuracy: 0.961\n",
      "epoch: 158, time: 4383.513s, loss: 0.360, train accuracy: 0.883\n",
      "epoch: 158, time: 4384.860s, loss: 0.259, train accuracy: 0.914\n",
      "epoch: 158, time: 4386.204s, loss: 0.233, train accuracy: 0.883\n",
      "epoch: 158, time: 4387.508s, loss: 0.211, train accuracy: 0.922\n",
      "epoch: 158, time: 4388.847s, loss: 0.154, train accuracy: 0.961\n",
      "epoch: 158, time: 4390.195s, loss: 0.197, train accuracy: 0.930\n",
      "epoch: 158, time: 4391.498s, loss: 0.156, train accuracy: 0.961\n",
      "epoch: 158, time: 4392.795s, loss: 0.190, train accuracy: 0.938\n",
      "epoch: 158, time: 4394.122s, loss: 0.112, train accuracy: 0.977\n",
      "epoch: 158, time: 4395.442s, loss: 0.120, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 159, time: 4398.417s, loss: 0.136, train accuracy: 0.938\n",
      "epoch: 159, time: 4399.737s, loss: 0.140, train accuracy: 0.938\n",
      "epoch: 159, time: 4401.035s, loss: 0.232, train accuracy: 0.914\n",
      "epoch: 159, time: 4402.349s, loss: 0.111, train accuracy: 0.953\n",
      "epoch: 159, time: 4403.669s, loss: 0.175, train accuracy: 0.953\n",
      "epoch: 159, time: 4404.968s, loss: 0.226, train accuracy: 0.922\n",
      "epoch: 159, time: 4406.274s, loss: 0.130, train accuracy: 0.945\n",
      "epoch: 159, time: 4407.647s, loss: 0.108, train accuracy: 0.969\n",
      "epoch: 159, time: 4408.976s, loss: 0.174, train accuracy: 0.945\n",
      "epoch: 159, time: 4410.303s, loss: 0.112, train accuracy: 0.953\n",
      "epoch: 159, time: 4411.599s, loss: 0.194, train accuracy: 0.930\n",
      "epoch: 159, time: 4412.942s, loss: 0.179, train accuracy: 0.938\n",
      "epoch: 159, time: 4414.283s, loss: 0.210, train accuracy: 0.906\n",
      "epoch: 159, time: 4415.597s, loss: 0.197, train accuracy: 0.945\n",
      "epoch: 159, time: 4416.904s, loss: 0.152, train accuracy: 0.938\n",
      "epoch: 159, time: 4418.199s, loss: 0.145, train accuracy: 0.938\n",
      "epoch: 159, time: 4419.523s, loss: 0.147, train accuracy: 0.938\n",
      "epoch: 159, time: 4420.844s, loss: 0.166, train accuracy: 0.945\n",
      "epoch: 159, time: 4422.180s, loss: 0.107, train accuracy: 0.945\n",
      "epoch: 159, time: 4423.483s, loss: 0.220, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 160, time: 4426.408s, loss: 0.110, train accuracy: 0.969\n",
      "epoch: 160, time: 4427.751s, loss: 0.156, train accuracy: 0.953\n",
      "epoch: 160, time: 4429.167s, loss: 0.199, train accuracy: 0.930\n",
      "epoch: 160, time: 4430.477s, loss: 0.090, train accuracy: 0.961\n",
      "epoch: 160, time: 4431.790s, loss: 0.252, train accuracy: 0.898\n",
      "epoch: 160, time: 4433.173s, loss: 0.226, train accuracy: 0.914\n",
      "epoch: 160, time: 4434.481s, loss: 0.258, train accuracy: 0.891\n",
      "epoch: 160, time: 4435.827s, loss: 0.176, train accuracy: 0.922\n",
      "epoch: 160, time: 4437.163s, loss: 0.156, train accuracy: 0.945\n",
      "epoch: 160, time: 4438.483s, loss: 0.281, train accuracy: 0.906\n",
      "epoch: 160, time: 4439.824s, loss: 0.277, train accuracy: 0.891\n",
      "epoch: 160, time: 4441.155s, loss: 0.310, train accuracy: 0.875\n",
      "epoch: 160, time: 4442.489s, loss: 0.199, train accuracy: 0.938\n",
      "epoch: 160, time: 4443.788s, loss: 0.230, train accuracy: 0.922\n",
      "epoch: 160, time: 4445.114s, loss: 0.203, train accuracy: 0.930\n",
      "epoch: 160, time: 4446.414s, loss: 0.218, train accuracy: 0.930\n",
      "epoch: 160, time: 4447.708s, loss: 0.204, train accuracy: 0.922\n",
      "epoch: 160, time: 4449.015s, loss: 0.139, train accuracy: 0.969\n",
      "epoch: 160, time: 4450.318s, loss: 0.265, train accuracy: 0.898\n",
      "epoch: 160, time: 4451.621s, loss: 0.184, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 161, time: 4454.585s, loss: 0.098, train accuracy: 0.969\n",
      "epoch: 161, time: 4455.926s, loss: 0.125, train accuracy: 0.930\n",
      "epoch: 161, time: 4457.308s, loss: 0.124, train accuracy: 0.938\n",
      "epoch: 161, time: 4458.667s, loss: 0.147, train accuracy: 0.930\n",
      "epoch: 161, time: 4460.033s, loss: 0.181, train accuracy: 0.945\n",
      "epoch: 161, time: 4461.415s, loss: 0.162, train accuracy: 0.953\n",
      "epoch: 161, time: 4462.721s, loss: 0.243, train accuracy: 0.914\n",
      "epoch: 161, time: 4464.019s, loss: 0.177, train accuracy: 0.930\n",
      "epoch: 161, time: 4465.325s, loss: 0.144, train accuracy: 0.961\n",
      "epoch: 161, time: 4466.624s, loss: 0.137, train accuracy: 0.938\n",
      "epoch: 161, time: 4467.930s, loss: 0.235, train accuracy: 0.922\n",
      "epoch: 161, time: 4469.233s, loss: 0.250, train accuracy: 0.922\n",
      "epoch: 161, time: 4470.528s, loss: 0.285, train accuracy: 0.914\n",
      "epoch: 161, time: 4471.859s, loss: 0.051, train accuracy: 0.992\n",
      "epoch: 161, time: 4473.171s, loss: 0.197, train accuracy: 0.930\n",
      "epoch: 161, time: 4474.487s, loss: 0.192, train accuracy: 0.953\n",
      "epoch: 161, time: 4475.802s, loss: 0.191, train accuracy: 0.914\n",
      "epoch: 161, time: 4477.160s, loss: 0.135, train accuracy: 0.945\n",
      "epoch: 161, time: 4478.458s, loss: 0.133, train accuracy: 0.930\n",
      "epoch: 161, time: 4479.787s, loss: 0.185, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.846\n",
      "epoch: 162, time: 4482.750s, loss: 0.195, train accuracy: 0.914\n",
      "epoch: 162, time: 4484.096s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 162, time: 4485.419s, loss: 0.163, train accuracy: 0.953\n",
      "epoch: 162, time: 4486.724s, loss: 0.129, train accuracy: 0.953\n",
      "epoch: 162, time: 4488.028s, loss: 0.116, train accuracy: 0.961\n",
      "epoch: 162, time: 4489.355s, loss: 0.267, train accuracy: 0.891\n",
      "epoch: 162, time: 4490.683s, loss: 0.220, train accuracy: 0.938\n",
      "epoch: 162, time: 4492.003s, loss: 0.160, train accuracy: 0.953\n",
      "epoch: 162, time: 4493.312s, loss: 0.167, train accuracy: 0.922\n",
      "epoch: 162, time: 4494.629s, loss: 0.149, train accuracy: 0.938\n",
      "epoch: 162, time: 4495.929s, loss: 0.169, train accuracy: 0.945\n",
      "epoch: 162, time: 4497.246s, loss: 0.119, train accuracy: 0.953\n",
      "epoch: 162, time: 4498.535s, loss: 0.128, train accuracy: 0.969\n",
      "epoch: 162, time: 4499.871s, loss: 0.199, train accuracy: 0.945\n",
      "epoch: 162, time: 4501.177s, loss: 0.162, train accuracy: 0.945\n",
      "epoch: 162, time: 4502.488s, loss: 0.277, train accuracy: 0.914\n",
      "epoch: 162, time: 4503.825s, loss: 0.291, train accuracy: 0.875\n",
      "epoch: 162, time: 4505.149s, loss: 0.120, train accuracy: 0.953\n",
      "epoch: 162, time: 4506.462s, loss: 0.176, train accuracy: 0.953\n",
      "epoch: 162, time: 4507.774s, loss: 0.202, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 163, time: 4510.720s, loss: 0.136, train accuracy: 0.938\n",
      "epoch: 163, time: 4512.074s, loss: 0.147, train accuracy: 0.953\n",
      "epoch: 163, time: 4513.398s, loss: 0.194, train accuracy: 0.930\n",
      "epoch: 163, time: 4514.695s, loss: 0.116, train accuracy: 0.961\n",
      "epoch: 163, time: 4516.014s, loss: 0.131, train accuracy: 0.953\n",
      "epoch: 163, time: 4517.324s, loss: 0.162, train accuracy: 0.945\n",
      "epoch: 163, time: 4518.628s, loss: 0.089, train accuracy: 0.969\n",
      "epoch: 163, time: 4519.928s, loss: 0.296, train accuracy: 0.930\n",
      "epoch: 163, time: 4521.245s, loss: 0.171, train accuracy: 0.922\n",
      "epoch: 163, time: 4522.568s, loss: 0.208, train accuracy: 0.906\n",
      "epoch: 163, time: 4523.902s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 163, time: 4525.202s, loss: 0.225, train accuracy: 0.914\n",
      "epoch: 163, time: 4526.506s, loss: 0.104, train accuracy: 0.953\n",
      "epoch: 163, time: 4527.821s, loss: 0.143, train accuracy: 0.930\n",
      "epoch: 163, time: 4529.176s, loss: 0.114, train accuracy: 0.945\n",
      "epoch: 163, time: 4530.473s, loss: 0.229, train accuracy: 0.953\n",
      "epoch: 163, time: 4531.791s, loss: 0.168, train accuracy: 0.922\n",
      "epoch: 163, time: 4533.166s, loss: 0.115, train accuracy: 0.953\n",
      "epoch: 163, time: 4534.517s, loss: 0.185, train accuracy: 0.945\n",
      "epoch: 163, time: 4535.912s, loss: 0.174, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.835\n",
      "epoch: 164, time: 4538.889s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 164, time: 4540.247s, loss: 0.090, train accuracy: 0.977\n",
      "epoch: 164, time: 4541.554s, loss: 0.058, train accuracy: 1.000\n",
      "epoch: 164, time: 4542.866s, loss: 0.178, train accuracy: 0.922\n",
      "epoch: 164, time: 4544.168s, loss: 0.146, train accuracy: 0.930\n",
      "epoch: 164, time: 4545.463s, loss: 0.181, train accuracy: 0.953\n",
      "epoch: 164, time: 4546.772s, loss: 0.161, train accuracy: 0.945\n",
      "epoch: 164, time: 4548.068s, loss: 0.161, train accuracy: 0.945\n",
      "epoch: 164, time: 4549.379s, loss: 0.138, train accuracy: 0.945\n",
      "epoch: 164, time: 4550.688s, loss: 0.130, train accuracy: 0.945\n",
      "epoch: 164, time: 4551.988s, loss: 0.200, train accuracy: 0.914\n",
      "epoch: 164, time: 4553.288s, loss: 0.283, train accuracy: 0.906\n",
      "epoch: 164, time: 4554.585s, loss: 0.163, train accuracy: 0.914\n",
      "epoch: 164, time: 4555.909s, loss: 0.161, train accuracy: 0.961\n",
      "epoch: 164, time: 4557.211s, loss: 0.107, train accuracy: 0.961\n",
      "epoch: 164, time: 4558.507s, loss: 0.266, train accuracy: 0.898\n",
      "epoch: 164, time: 4559.808s, loss: 0.239, train accuracy: 0.898\n",
      "epoch: 164, time: 4561.119s, loss: 0.219, train accuracy: 0.930\n",
      "epoch: 164, time: 4562.425s, loss: 0.123, train accuracy: 0.961\n",
      "epoch: 164, time: 4563.904s, loss: 0.195, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 165, time: 4566.823s, loss: 0.137, train accuracy: 0.938\n",
      "epoch: 165, time: 4568.199s, loss: 0.141, train accuracy: 0.930\n",
      "epoch: 165, time: 4569.526s, loss: 0.163, train accuracy: 0.961\n",
      "epoch: 165, time: 4570.843s, loss: 0.339, train accuracy: 0.883\n",
      "epoch: 165, time: 4572.170s, loss: 0.125, train accuracy: 0.938\n",
      "epoch: 165, time: 4573.494s, loss: 0.136, train accuracy: 0.945\n",
      "epoch: 165, time: 4574.793s, loss: 0.173, train accuracy: 0.938\n",
      "epoch: 165, time: 4576.119s, loss: 0.137, train accuracy: 0.953\n",
      "epoch: 165, time: 4577.415s, loss: 0.096, train accuracy: 0.953\n",
      "epoch: 165, time: 4578.775s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 165, time: 4580.116s, loss: 0.159, train accuracy: 0.953\n",
      "epoch: 165, time: 4581.404s, loss: 0.122, train accuracy: 0.961\n",
      "epoch: 165, time: 4582.722s, loss: 0.153, train accuracy: 0.930\n",
      "epoch: 165, time: 4584.018s, loss: 0.228, train accuracy: 0.914\n",
      "epoch: 165, time: 4585.316s, loss: 0.208, train accuracy: 0.922\n",
      "epoch: 165, time: 4586.648s, loss: 0.169, train accuracy: 0.930\n",
      "epoch: 165, time: 4587.952s, loss: 0.199, train accuracy: 0.930\n",
      "epoch: 165, time: 4589.238s, loss: 0.113, train accuracy: 0.969\n",
      "epoch: 165, time: 4590.582s, loss: 0.203, train accuracy: 0.922\n",
      "epoch: 165, time: 4591.898s, loss: 0.131, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 166, time: 4594.858s, loss: 0.163, train accuracy: 0.938\n",
      "epoch: 166, time: 4596.197s, loss: 0.084, train accuracy: 0.969\n",
      "epoch: 166, time: 4597.512s, loss: 0.161, train accuracy: 0.945\n",
      "epoch: 166, time: 4598.853s, loss: 0.153, train accuracy: 0.938\n",
      "epoch: 166, time: 4600.173s, loss: 0.094, train accuracy: 0.969\n",
      "epoch: 166, time: 4601.492s, loss: 0.230, train accuracy: 0.922\n",
      "epoch: 166, time: 4602.811s, loss: 0.121, train accuracy: 0.938\n",
      "epoch: 166, time: 4604.131s, loss: 0.160, train accuracy: 0.945\n",
      "epoch: 166, time: 4605.453s, loss: 0.147, train accuracy: 0.953\n",
      "epoch: 166, time: 4606.790s, loss: 0.124, train accuracy: 0.938\n",
      "epoch: 166, time: 4608.087s, loss: 0.130, train accuracy: 0.953\n",
      "epoch: 166, time: 4609.401s, loss: 0.201, train accuracy: 0.945\n",
      "epoch: 166, time: 4610.708s, loss: 0.203, train accuracy: 0.945\n",
      "epoch: 166, time: 4612.075s, loss: 0.104, train accuracy: 0.953\n",
      "epoch: 166, time: 4613.373s, loss: 0.177, train accuracy: 0.938\n",
      "epoch: 166, time: 4614.681s, loss: 0.141, train accuracy: 0.930\n",
      "epoch: 166, time: 4615.992s, loss: 0.102, train accuracy: 0.969\n",
      "epoch: 166, time: 4617.298s, loss: 0.251, train accuracy: 0.914\n",
      "epoch: 166, time: 4618.590s, loss: 0.178, train accuracy: 0.938\n",
      "epoch: 166, time: 4619.942s, loss: 0.243, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 167, time: 4622.891s, loss: 0.189, train accuracy: 0.953\n",
      "epoch: 167, time: 4624.207s, loss: 0.193, train accuracy: 0.930\n",
      "epoch: 167, time: 4625.511s, loss: 0.105, train accuracy: 0.977\n",
      "epoch: 167, time: 4626.816s, loss: 0.258, train accuracy: 0.922\n",
      "epoch: 167, time: 4628.109s, loss: 0.125, train accuracy: 0.938\n",
      "epoch: 167, time: 4629.413s, loss: 0.143, train accuracy: 0.945\n",
      "epoch: 167, time: 4630.739s, loss: 0.185, train accuracy: 0.930\n",
      "epoch: 167, time: 4632.039s, loss: 0.210, train accuracy: 0.914\n",
      "epoch: 167, time: 4633.364s, loss: 0.165, train accuracy: 0.922\n",
      "epoch: 167, time: 4634.666s, loss: 0.219, train accuracy: 0.945\n",
      "epoch: 167, time: 4636.011s, loss: 0.132, train accuracy: 0.961\n",
      "epoch: 167, time: 4637.309s, loss: 0.186, train accuracy: 0.930\n",
      "epoch: 167, time: 4638.612s, loss: 0.136, train accuracy: 0.961\n",
      "epoch: 167, time: 4639.925s, loss: 0.191, train accuracy: 0.930\n",
      "epoch: 167, time: 4641.232s, loss: 0.154, train accuracy: 0.938\n",
      "epoch: 167, time: 4642.542s, loss: 0.229, train accuracy: 0.898\n",
      "epoch: 167, time: 4643.886s, loss: 0.102, train accuracy: 0.969\n",
      "epoch: 167, time: 4645.187s, loss: 0.110, train accuracy: 0.953\n",
      "epoch: 167, time: 4646.494s, loss: 0.099, train accuracy: 0.961\n",
      "epoch: 167, time: 4647.817s, loss: 0.149, train accuracy: 0.961\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 168, time: 4650.830s, loss: 0.147, train accuracy: 0.938\n",
      "epoch: 168, time: 4652.172s, loss: 0.162, train accuracy: 0.930\n",
      "epoch: 168, time: 4653.502s, loss: 0.110, train accuracy: 0.961\n",
      "epoch: 168, time: 4654.822s, loss: 0.134, train accuracy: 0.953\n",
      "epoch: 168, time: 4656.194s, loss: 0.113, train accuracy: 0.953\n",
      "epoch: 168, time: 4657.540s, loss: 0.068, train accuracy: 0.977\n",
      "epoch: 168, time: 4658.835s, loss: 0.241, train accuracy: 0.922\n",
      "epoch: 168, time: 4660.174s, loss: 0.221, train accuracy: 0.898\n",
      "epoch: 168, time: 4661.481s, loss: 0.109, train accuracy: 0.961\n",
      "epoch: 168, time: 4662.782s, loss: 0.109, train accuracy: 0.961\n",
      "epoch: 168, time: 4664.091s, loss: 0.199, train accuracy: 0.945\n",
      "epoch: 168, time: 4665.407s, loss: 0.243, train accuracy: 0.922\n",
      "epoch: 168, time: 4666.719s, loss: 0.218, train accuracy: 0.930\n",
      "epoch: 168, time: 4668.019s, loss: 0.210, train accuracy: 0.922\n",
      "epoch: 168, time: 4669.381s, loss: 0.228, train accuracy: 0.914\n",
      "epoch: 168, time: 4670.681s, loss: 0.067, train accuracy: 0.977\n",
      "epoch: 168, time: 4672.000s, loss: 0.277, train accuracy: 0.883\n",
      "epoch: 168, time: 4673.314s, loss: 0.173, train accuracy: 0.922\n",
      "epoch: 168, time: 4674.631s, loss: 0.143, train accuracy: 0.961\n",
      "epoch: 168, time: 4675.947s, loss: 0.233, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 169, time: 4678.921s, loss: 0.143, train accuracy: 0.945\n",
      "epoch: 169, time: 4680.256s, loss: 0.171, train accuracy: 0.945\n",
      "epoch: 169, time: 4681.554s, loss: 0.152, train accuracy: 0.945\n",
      "epoch: 169, time: 4682.848s, loss: 0.230, train accuracy: 0.922\n",
      "epoch: 169, time: 4684.182s, loss: 0.061, train accuracy: 0.969\n",
      "epoch: 169, time: 4685.483s, loss: 0.220, train accuracy: 0.938\n",
      "epoch: 169, time: 4686.801s, loss: 0.113, train accuracy: 0.969\n",
      "epoch: 169, time: 4688.125s, loss: 0.120, train accuracy: 0.945\n",
      "epoch: 169, time: 4689.433s, loss: 0.210, train accuracy: 0.914\n",
      "epoch: 169, time: 4690.737s, loss: 0.170, train accuracy: 0.945\n",
      "epoch: 169, time: 4692.070s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 169, time: 4693.385s, loss: 0.176, train accuracy: 0.938\n",
      "epoch: 169, time: 4694.688s, loss: 0.128, train accuracy: 0.961\n",
      "epoch: 169, time: 4696.010s, loss: 0.277, train accuracy: 0.914\n",
      "epoch: 169, time: 4697.338s, loss: 0.413, train accuracy: 0.898\n",
      "epoch: 169, time: 4698.646s, loss: 0.393, train accuracy: 0.875\n",
      "epoch: 169, time: 4699.987s, loss: 0.307, train accuracy: 0.875\n",
      "epoch: 169, time: 4701.301s, loss: 0.345, train accuracy: 0.891\n",
      "epoch: 169, time: 4702.611s, loss: 0.269, train accuracy: 0.883\n",
      "epoch: 169, time: 4703.909s, loss: 0.410, train accuracy: 0.852\n",
      "Accuracy on the test set: 0.815\n",
      "epoch: 170, time: 4706.876s, loss: 0.298, train accuracy: 0.867\n",
      "epoch: 170, time: 4708.212s, loss: 0.484, train accuracy: 0.828\n",
      "epoch: 170, time: 4709.524s, loss: 0.308, train accuracy: 0.914\n",
      "epoch: 170, time: 4710.825s, loss: 0.378, train accuracy: 0.859\n",
      "epoch: 170, time: 4712.144s, loss: 0.157, train accuracy: 0.945\n",
      "epoch: 170, time: 4713.443s, loss: 0.296, train accuracy: 0.883\n",
      "epoch: 170, time: 4714.746s, loss: 0.341, train accuracy: 0.883\n",
      "epoch: 170, time: 4716.057s, loss: 0.224, train accuracy: 0.914\n",
      "epoch: 170, time: 4717.384s, loss: 0.309, train accuracy: 0.883\n",
      "epoch: 170, time: 4718.673s, loss: 0.232, train accuracy: 0.922\n",
      "epoch: 170, time: 4719.974s, loss: 0.418, train accuracy: 0.852\n",
      "epoch: 170, time: 4721.283s, loss: 0.223, train accuracy: 0.953\n",
      "epoch: 170, time: 4722.579s, loss: 0.290, train accuracy: 0.906\n",
      "epoch: 170, time: 4723.895s, loss: 0.220, train accuracy: 0.922\n",
      "epoch: 170, time: 4725.191s, loss: 0.129, train accuracy: 0.953\n",
      "epoch: 170, time: 4726.501s, loss: 0.217, train accuracy: 0.922\n",
      "epoch: 170, time: 4727.822s, loss: 0.159, train accuracy: 0.930\n",
      "epoch: 170, time: 4729.123s, loss: 0.166, train accuracy: 0.922\n",
      "epoch: 170, time: 4730.432s, loss: 0.093, train accuracy: 0.961\n",
      "epoch: 170, time: 4731.753s, loss: 0.216, train accuracy: 0.898\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 171, time: 4734.736s, loss: 0.113, train accuracy: 0.961\n",
      "epoch: 171, time: 4736.052s, loss: 0.195, train accuracy: 0.945\n",
      "epoch: 171, time: 4737.359s, loss: 0.232, train accuracy: 0.922\n",
      "epoch: 171, time: 4738.664s, loss: 0.170, train accuracy: 0.953\n",
      "epoch: 171, time: 4739.975s, loss: 0.074, train accuracy: 0.984\n",
      "epoch: 171, time: 4741.300s, loss: 0.189, train accuracy: 0.914\n",
      "epoch: 171, time: 4742.619s, loss: 0.301, train accuracy: 0.883\n",
      "epoch: 171, time: 4743.936s, loss: 0.213, train accuracy: 0.906\n",
      "epoch: 171, time: 4745.232s, loss: 0.149, train accuracy: 0.938\n",
      "epoch: 171, time: 4746.551s, loss: 0.191, train accuracy: 0.922\n",
      "epoch: 171, time: 4747.890s, loss: 0.160, train accuracy: 0.938\n",
      "epoch: 171, time: 4749.189s, loss: 0.164, train accuracy: 0.953\n",
      "epoch: 171, time: 4750.529s, loss: 0.123, train accuracy: 0.953\n",
      "epoch: 171, time: 4751.825s, loss: 0.136, train accuracy: 0.945\n",
      "epoch: 171, time: 4753.146s, loss: 0.194, train accuracy: 0.922\n",
      "epoch: 171, time: 4754.495s, loss: 0.138, train accuracy: 0.945\n",
      "epoch: 171, time: 4755.796s, loss: 0.101, train accuracy: 0.953\n",
      "epoch: 171, time: 4757.085s, loss: 0.135, train accuracy: 0.945\n",
      "epoch: 171, time: 4758.413s, loss: 0.142, train accuracy: 0.938\n",
      "epoch: 171, time: 4759.711s, loss: 0.172, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 172, time: 4762.683s, loss: 0.111, train accuracy: 0.969\n",
      "epoch: 172, time: 4764.013s, loss: 0.149, train accuracy: 0.961\n",
      "epoch: 172, time: 4765.352s, loss: 0.121, train accuracy: 0.977\n",
      "epoch: 172, time: 4766.657s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 172, time: 4767.992s, loss: 0.113, train accuracy: 0.977\n",
      "epoch: 172, time: 4769.309s, loss: 0.181, train accuracy: 0.938\n",
      "epoch: 172, time: 4770.636s, loss: 0.125, train accuracy: 0.953\n",
      "epoch: 172, time: 4771.956s, loss: 0.108, train accuracy: 0.961\n",
      "epoch: 172, time: 4773.256s, loss: 0.144, train accuracy: 0.961\n",
      "epoch: 172, time: 4774.567s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 172, time: 4775.888s, loss: 0.147, train accuracy: 0.953\n",
      "epoch: 172, time: 4777.217s, loss: 0.080, train accuracy: 0.977\n",
      "epoch: 172, time: 4778.560s, loss: 0.187, train accuracy: 0.930\n",
      "epoch: 172, time: 4779.876s, loss: 0.105, train accuracy: 0.953\n",
      "epoch: 172, time: 4781.181s, loss: 0.141, train accuracy: 0.953\n",
      "epoch: 172, time: 4782.532s, loss: 0.086, train accuracy: 0.977\n",
      "epoch: 172, time: 4783.834s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 172, time: 4785.128s, loss: 0.174, train accuracy: 0.945\n",
      "epoch: 172, time: 4786.429s, loss: 0.136, train accuracy: 0.969\n",
      "epoch: 172, time: 4787.758s, loss: 0.157, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 173, time: 4790.692s, loss: 0.201, train accuracy: 0.930\n",
      "epoch: 173, time: 4792.042s, loss: 0.144, train accuracy: 0.953\n",
      "epoch: 173, time: 4793.342s, loss: 0.164, train accuracy: 0.938\n",
      "epoch: 173, time: 4794.660s, loss: 0.056, train accuracy: 0.984\n",
      "epoch: 173, time: 4795.969s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 173, time: 4797.291s, loss: 0.201, train accuracy: 0.945\n",
      "epoch: 173, time: 4798.605s, loss: 0.106, train accuracy: 0.953\n",
      "epoch: 173, time: 4799.913s, loss: 0.152, train accuracy: 0.945\n",
      "epoch: 173, time: 4801.233s, loss: 0.218, train accuracy: 0.953\n",
      "epoch: 173, time: 4802.552s, loss: 0.085, train accuracy: 0.977\n",
      "epoch: 173, time: 4803.863s, loss: 0.261, train accuracy: 0.930\n",
      "epoch: 173, time: 4805.222s, loss: 0.179, train accuracy: 0.922\n",
      "epoch: 173, time: 4806.523s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 173, time: 4807.854s, loss: 0.199, train accuracy: 0.938\n",
      "epoch: 173, time: 4809.164s, loss: 0.129, train accuracy: 0.953\n",
      "epoch: 173, time: 4810.498s, loss: 0.168, train accuracy: 0.961\n",
      "epoch: 173, time: 4811.806s, loss: 0.192, train accuracy: 0.930\n",
      "epoch: 173, time: 4813.098s, loss: 0.125, train accuracy: 0.969\n",
      "epoch: 173, time: 4814.420s, loss: 0.119, train accuracy: 0.977\n",
      "epoch: 173, time: 4815.747s, loss: 0.079, train accuracy: 0.977\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 174, time: 4818.728s, loss: 0.123, train accuracy: 0.969\n",
      "epoch: 174, time: 4820.084s, loss: 0.222, train accuracy: 0.914\n",
      "epoch: 174, time: 4821.399s, loss: 0.105, train accuracy: 0.961\n",
      "epoch: 174, time: 4822.703s, loss: 0.156, train accuracy: 0.953\n",
      "epoch: 174, time: 4824.029s, loss: 0.153, train accuracy: 0.945\n",
      "epoch: 174, time: 4825.329s, loss: 0.211, train accuracy: 0.938\n",
      "epoch: 174, time: 4826.679s, loss: 0.117, train accuracy: 0.961\n",
      "epoch: 174, time: 4827.977s, loss: 0.099, train accuracy: 0.977\n",
      "epoch: 174, time: 4829.281s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 174, time: 4830.600s, loss: 0.234, train accuracy: 0.914\n",
      "epoch: 174, time: 4831.895s, loss: 0.247, train accuracy: 0.898\n",
      "epoch: 174, time: 4833.195s, loss: 0.072, train accuracy: 0.984\n",
      "epoch: 174, time: 4834.513s, loss: 0.173, train accuracy: 0.914\n",
      "epoch: 174, time: 4835.857s, loss: 0.113, train accuracy: 0.961\n",
      "epoch: 174, time: 4837.151s, loss: 0.097, train accuracy: 0.984\n",
      "epoch: 174, time: 4838.458s, loss: 0.161, train accuracy: 0.953\n",
      "epoch: 174, time: 4839.758s, loss: 0.121, train accuracy: 0.953\n",
      "epoch: 174, time: 4841.092s, loss: 0.188, train accuracy: 0.938\n",
      "epoch: 174, time: 4842.382s, loss: 0.152, train accuracy: 0.922\n",
      "epoch: 174, time: 4843.713s, loss: 0.156, train accuracy: 0.945\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 175, time: 4846.639s, loss: 0.127, train accuracy: 0.961\n",
      "epoch: 175, time: 4847.949s, loss: 0.181, train accuracy: 0.922\n",
      "epoch: 175, time: 4849.255s, loss: 0.121, train accuracy: 0.953\n",
      "epoch: 175, time: 4850.574s, loss: 0.103, train accuracy: 0.961\n",
      "epoch: 175, time: 4851.872s, loss: 0.192, train accuracy: 0.922\n",
      "epoch: 175, time: 4853.176s, loss: 0.151, train accuracy: 0.938\n",
      "epoch: 175, time: 4854.505s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 175, time: 4855.801s, loss: 0.211, train accuracy: 0.922\n",
      "epoch: 175, time: 4857.100s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 175, time: 4858.421s, loss: 0.076, train accuracy: 0.969\n",
      "epoch: 175, time: 4859.730s, loss: 0.235, train accuracy: 0.938\n",
      "epoch: 175, time: 4861.033s, loss: 0.168, train accuracy: 0.930\n",
      "epoch: 175, time: 4862.356s, loss: 0.182, train accuracy: 0.922\n",
      "epoch: 175, time: 4863.661s, loss: 0.205, train accuracy: 0.922\n",
      "epoch: 175, time: 4864.985s, loss: 0.173, train accuracy: 0.938\n",
      "epoch: 175, time: 4866.358s, loss: 0.108, train accuracy: 0.922\n",
      "epoch: 175, time: 4867.705s, loss: 0.303, train accuracy: 0.883\n",
      "epoch: 175, time: 4869.005s, loss: 0.112, train accuracy: 0.953\n",
      "epoch: 175, time: 4870.294s, loss: 0.141, train accuracy: 0.953\n",
      "epoch: 175, time: 4871.621s, loss: 0.178, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 176, time: 4874.591s, loss: 0.102, train accuracy: 0.969\n",
      "epoch: 176, time: 4875.906s, loss: 0.127, train accuracy: 0.953\n",
      "epoch: 176, time: 4877.231s, loss: 0.136, train accuracy: 0.953\n",
      "epoch: 176, time: 4878.547s, loss: 0.138, train accuracy: 0.945\n",
      "epoch: 176, time: 4879.864s, loss: 0.214, train accuracy: 0.906\n",
      "epoch: 176, time: 4881.222s, loss: 0.145, train accuracy: 0.945\n",
      "epoch: 176, time: 4882.540s, loss: 0.064, train accuracy: 0.984\n",
      "epoch: 176, time: 4883.899s, loss: 0.082, train accuracy: 0.977\n",
      "epoch: 176, time: 4885.229s, loss: 0.179, train accuracy: 0.953\n",
      "epoch: 176, time: 4886.569s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 176, time: 4887.889s, loss: 0.126, train accuracy: 0.945\n",
      "epoch: 176, time: 4889.235s, loss: 0.132, train accuracy: 0.945\n",
      "epoch: 176, time: 4890.557s, loss: 0.123, train accuracy: 0.961\n",
      "epoch: 176, time: 4891.875s, loss: 0.172, train accuracy: 0.938\n",
      "epoch: 176, time: 4893.176s, loss: 0.088, train accuracy: 0.977\n",
      "epoch: 176, time: 4894.492s, loss: 0.186, train accuracy: 0.906\n",
      "epoch: 176, time: 4895.804s, loss: 0.086, train accuracy: 0.977\n",
      "epoch: 176, time: 4897.145s, loss: 0.216, train accuracy: 0.930\n",
      "epoch: 176, time: 4898.490s, loss: 0.174, train accuracy: 0.922\n",
      "epoch: 176, time: 4899.836s, loss: 0.137, train accuracy: 0.969\n",
      "Accuracy on the test set: 0.844\n",
      "epoch: 177, time: 4902.779s, loss: 0.141, train accuracy: 0.938\n",
      "epoch: 177, time: 4904.103s, loss: 0.086, train accuracy: 0.977\n",
      "epoch: 177, time: 4905.424s, loss: 0.126, train accuracy: 0.969\n",
      "epoch: 177, time: 4906.742s, loss: 0.198, train accuracy: 0.953\n",
      "epoch: 177, time: 4908.052s, loss: 0.200, train accuracy: 0.930\n",
      "epoch: 177, time: 4909.367s, loss: 0.151, train accuracy: 0.945\n",
      "epoch: 177, time: 4910.679s, loss: 0.186, train accuracy: 0.938\n",
      "epoch: 177, time: 4912.007s, loss: 0.116, train accuracy: 0.953\n",
      "epoch: 177, time: 4913.315s, loss: 0.175, train accuracy: 0.945\n",
      "epoch: 177, time: 4914.621s, loss: 0.198, train accuracy: 0.930\n",
      "epoch: 177, time: 4915.939s, loss: 0.174, train accuracy: 0.945\n",
      "epoch: 177, time: 4917.262s, loss: 0.130, train accuracy: 0.961\n",
      "epoch: 177, time: 4918.569s, loss: 0.202, train accuracy: 0.938\n",
      "epoch: 177, time: 4919.867s, loss: 0.084, train accuracy: 0.969\n",
      "epoch: 177, time: 4921.215s, loss: 0.129, train accuracy: 0.953\n",
      "epoch: 177, time: 4922.574s, loss: 0.116, train accuracy: 0.953\n",
      "epoch: 177, time: 4923.881s, loss: 0.269, train accuracy: 0.906\n",
      "epoch: 177, time: 4925.283s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 177, time: 4926.575s, loss: 0.101, train accuracy: 0.961\n",
      "epoch: 177, time: 4927.877s, loss: 0.198, train accuracy: 0.914\n",
      "Accuracy on the test set: 0.845\n",
      "epoch: 178, time: 4930.847s, loss: 0.110, train accuracy: 0.969\n",
      "epoch: 178, time: 4932.171s, loss: 0.054, train accuracy: 0.984\n",
      "epoch: 178, time: 4933.491s, loss: 0.107, train accuracy: 0.969\n",
      "epoch: 178, time: 4934.788s, loss: 0.121, train accuracy: 0.961\n",
      "epoch: 178, time: 4936.096s, loss: 0.179, train accuracy: 0.945\n",
      "epoch: 178, time: 4937.412s, loss: 0.210, train accuracy: 0.906\n",
      "epoch: 178, time: 4938.723s, loss: 0.188, train accuracy: 0.945\n",
      "epoch: 178, time: 4940.042s, loss: 0.102, train accuracy: 0.969\n",
      "epoch: 178, time: 4941.341s, loss: 0.110, train accuracy: 0.961\n",
      "epoch: 178, time: 4942.659s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 178, time: 4943.972s, loss: 0.132, train accuracy: 0.930\n",
      "epoch: 178, time: 4945.273s, loss: 0.117, train accuracy: 0.961\n",
      "epoch: 178, time: 4946.584s, loss: 0.119, train accuracy: 0.938\n",
      "epoch: 178, time: 4947.902s, loss: 0.114, train accuracy: 0.945\n",
      "epoch: 178, time: 4949.203s, loss: 0.206, train accuracy: 0.945\n",
      "epoch: 178, time: 4950.502s, loss: 0.127, train accuracy: 0.969\n",
      "epoch: 178, time: 4951.806s, loss: 0.086, train accuracy: 0.969\n",
      "epoch: 178, time: 4953.100s, loss: 0.212, train accuracy: 0.906\n",
      "epoch: 178, time: 4954.396s, loss: 0.129, train accuracy: 0.938\n",
      "epoch: 178, time: 4955.733s, loss: 0.115, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 179, time: 4958.678s, loss: 0.168, train accuracy: 0.945\n",
      "epoch: 179, time: 4960.047s, loss: 0.142, train accuracy: 0.945\n",
      "epoch: 179, time: 4961.371s, loss: 0.107, train accuracy: 0.961\n",
      "epoch: 179, time: 4962.669s, loss: 0.193, train accuracy: 0.945\n",
      "epoch: 179, time: 4963.979s, loss: 0.128, train accuracy: 0.953\n",
      "epoch: 179, time: 4965.310s, loss: 0.188, train accuracy: 0.898\n",
      "epoch: 179, time: 4966.662s, loss: 0.311, train accuracy: 0.891\n",
      "epoch: 179, time: 4967.975s, loss: 0.087, train accuracy: 0.969\n",
      "epoch: 179, time: 4969.282s, loss: 0.190, train accuracy: 0.945\n",
      "epoch: 179, time: 4970.619s, loss: 0.185, train accuracy: 0.906\n",
      "epoch: 179, time: 4971.936s, loss: 0.082, train accuracy: 0.961\n",
      "epoch: 179, time: 4973.249s, loss: 0.118, train accuracy: 0.961\n",
      "epoch: 179, time: 4974.597s, loss: 0.156, train accuracy: 0.945\n",
      "epoch: 179, time: 4975.905s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 179, time: 4977.198s, loss: 0.267, train accuracy: 0.922\n",
      "epoch: 179, time: 4978.501s, loss: 0.148, train accuracy: 0.961\n",
      "epoch: 179, time: 4979.803s, loss: 0.166, train accuracy: 0.945\n",
      "epoch: 179, time: 4981.118s, loss: 0.125, train accuracy: 0.945\n",
      "epoch: 179, time: 4982.418s, loss: 0.206, train accuracy: 0.922\n",
      "epoch: 179, time: 4983.712s, loss: 0.149, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 180, time: 4986.661s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 180, time: 4987.979s, loss: 0.087, train accuracy: 0.977\n",
      "epoch: 180, time: 4989.278s, loss: 0.227, train accuracy: 0.906\n",
      "epoch: 180, time: 4990.577s, loss: 0.163, train accuracy: 0.938\n",
      "epoch: 180, time: 4991.920s, loss: 0.132, train accuracy: 0.938\n",
      "epoch: 180, time: 4993.213s, loss: 0.111, train accuracy: 0.953\n",
      "epoch: 180, time: 4994.529s, loss: 0.128, train accuracy: 0.953\n",
      "epoch: 180, time: 4995.841s, loss: 0.127, train accuracy: 0.953\n",
      "epoch: 180, time: 4997.140s, loss: 0.108, train accuracy: 0.961\n",
      "epoch: 180, time: 4998.443s, loss: 0.113, train accuracy: 0.961\n",
      "epoch: 180, time: 4999.736s, loss: 0.143, train accuracy: 0.953\n",
      "epoch: 180, time: 5001.061s, loss: 0.100, train accuracy: 0.953\n",
      "epoch: 180, time: 5002.398s, loss: 0.097, train accuracy: 0.984\n",
      "epoch: 180, time: 5003.691s, loss: 0.126, train accuracy: 0.969\n",
      "epoch: 180, time: 5004.983s, loss: 0.160, train accuracy: 0.922\n",
      "epoch: 180, time: 5006.290s, loss: 0.157, train accuracy: 0.930\n",
      "epoch: 180, time: 5007.613s, loss: 0.221, train accuracy: 0.914\n",
      "epoch: 180, time: 5008.951s, loss: 0.145, train accuracy: 0.945\n",
      "epoch: 180, time: 5010.280s, loss: 0.149, train accuracy: 0.969\n",
      "epoch: 180, time: 5011.584s, loss: 0.204, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 181, time: 5014.583s, loss: 0.109, train accuracy: 0.961\n",
      "epoch: 181, time: 5015.922s, loss: 0.097, train accuracy: 0.977\n",
      "epoch: 181, time: 5017.223s, loss: 0.126, train accuracy: 0.953\n",
      "epoch: 181, time: 5018.535s, loss: 0.079, train accuracy: 0.977\n",
      "epoch: 181, time: 5019.886s, loss: 0.121, train accuracy: 0.953\n",
      "epoch: 181, time: 5021.186s, loss: 0.124, train accuracy: 0.938\n",
      "epoch: 181, time: 5022.497s, loss: 0.155, train accuracy: 0.945\n",
      "epoch: 181, time: 5023.805s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 181, time: 5025.145s, loss: 0.164, train accuracy: 0.945\n",
      "epoch: 181, time: 5026.448s, loss: 0.146, train accuracy: 0.945\n",
      "epoch: 181, time: 5027.794s, loss: 0.095, train accuracy: 0.953\n",
      "epoch: 181, time: 5029.119s, loss: 0.108, train accuracy: 0.953\n",
      "epoch: 181, time: 5030.544s, loss: 0.297, train accuracy: 0.914\n",
      "epoch: 181, time: 5031.922s, loss: 0.168, train accuracy: 0.938\n",
      "epoch: 181, time: 5033.236s, loss: 0.203, train accuracy: 0.914\n",
      "epoch: 181, time: 5034.537s, loss: 0.133, train accuracy: 0.930\n",
      "epoch: 181, time: 5035.844s, loss: 0.167, train accuracy: 0.945\n",
      "epoch: 181, time: 5037.164s, loss: 0.223, train accuracy: 0.930\n",
      "epoch: 181, time: 5038.481s, loss: 0.138, train accuracy: 0.953\n",
      "epoch: 181, time: 5039.783s, loss: 0.120, train accuracy: 0.945\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 182, time: 5042.703s, loss: 0.096, train accuracy: 0.961\n",
      "epoch: 182, time: 5044.031s, loss: 0.076, train accuracy: 0.969\n",
      "epoch: 182, time: 5045.344s, loss: 0.181, train accuracy: 0.906\n",
      "epoch: 182, time: 5046.660s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 182, time: 5047.992s, loss: 0.178, train accuracy: 0.930\n",
      "epoch: 182, time: 5049.309s, loss: 0.095, train accuracy: 0.953\n",
      "epoch: 182, time: 5050.640s, loss: 0.095, train accuracy: 0.961\n",
      "epoch: 182, time: 5051.977s, loss: 0.121, train accuracy: 0.938\n",
      "epoch: 182, time: 5053.303s, loss: 0.112, train accuracy: 0.961\n",
      "epoch: 182, time: 5054.619s, loss: 0.158, train accuracy: 0.930\n",
      "epoch: 182, time: 5055.956s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 182, time: 5057.251s, loss: 0.136, train accuracy: 0.961\n",
      "epoch: 182, time: 5058.581s, loss: 0.160, train accuracy: 0.945\n",
      "epoch: 182, time: 5059.875s, loss: 0.151, train accuracy: 0.938\n",
      "epoch: 182, time: 5061.211s, loss: 0.146, train accuracy: 0.945\n",
      "epoch: 182, time: 5062.533s, loss: 0.141, train accuracy: 0.961\n",
      "epoch: 182, time: 5063.848s, loss: 0.232, train accuracy: 0.898\n",
      "epoch: 182, time: 5065.199s, loss: 0.091, train accuracy: 0.953\n",
      "epoch: 182, time: 5066.542s, loss: 0.105, train accuracy: 0.938\n",
      "epoch: 182, time: 5067.860s, loss: 0.160, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 183, time: 5070.811s, loss: 0.134, train accuracy: 0.938\n",
      "epoch: 183, time: 5072.135s, loss: 0.072, train accuracy: 0.984\n",
      "epoch: 183, time: 5073.454s, loss: 0.061, train accuracy: 0.984\n",
      "epoch: 183, time: 5074.752s, loss: 0.196, train accuracy: 0.938\n",
      "epoch: 183, time: 5076.067s, loss: 0.108, train accuracy: 0.961\n",
      "epoch: 183, time: 5077.415s, loss: 0.149, train accuracy: 0.953\n",
      "epoch: 183, time: 5078.737s, loss: 0.234, train accuracy: 0.898\n",
      "epoch: 183, time: 5080.047s, loss: 0.121, train accuracy: 0.961\n",
      "epoch: 183, time: 5081.361s, loss: 0.135, train accuracy: 0.922\n",
      "epoch: 183, time: 5082.687s, loss: 0.153, train accuracy: 0.930\n",
      "epoch: 183, time: 5084.003s, loss: 0.132, train accuracy: 0.945\n",
      "epoch: 183, time: 5085.352s, loss: 0.185, train accuracy: 0.922\n",
      "epoch: 183, time: 5086.658s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 183, time: 5087.970s, loss: 0.117, train accuracy: 0.961\n",
      "epoch: 183, time: 5089.277s, loss: 0.123, train accuracy: 0.953\n",
      "epoch: 183, time: 5090.583s, loss: 0.092, train accuracy: 0.961\n",
      "epoch: 183, time: 5091.907s, loss: 0.200, train accuracy: 0.914\n",
      "epoch: 183, time: 5093.223s, loss: 0.134, train accuracy: 0.961\n",
      "epoch: 183, time: 5094.524s, loss: 0.243, train accuracy: 0.914\n",
      "epoch: 183, time: 5095.818s, loss: 0.087, train accuracy: 0.961\n",
      "Accuracy on the test set: 0.844\n",
      "epoch: 184, time: 5098.766s, loss: 0.177, train accuracy: 0.930\n",
      "epoch: 184, time: 5100.097s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 184, time: 5101.401s, loss: 0.124, train accuracy: 0.938\n",
      "epoch: 184, time: 5102.720s, loss: 0.213, train accuracy: 0.930\n",
      "epoch: 184, time: 5104.036s, loss: 0.095, train accuracy: 0.969\n",
      "epoch: 184, time: 5105.338s, loss: 0.106, train accuracy: 0.977\n",
      "epoch: 184, time: 5106.663s, loss: 0.118, train accuracy: 0.961\n",
      "epoch: 184, time: 5107.990s, loss: 0.112, train accuracy: 0.969\n",
      "epoch: 184, time: 5109.321s, loss: 0.136, train accuracy: 0.953\n",
      "epoch: 184, time: 5110.615s, loss: 0.134, train accuracy: 0.953\n",
      "epoch: 184, time: 5111.956s, loss: 0.143, train accuracy: 0.945\n",
      "epoch: 184, time: 5113.283s, loss: 0.146, train accuracy: 0.930\n",
      "epoch: 184, time: 5114.582s, loss: 0.233, train accuracy: 0.906\n",
      "epoch: 184, time: 5115.887s, loss: 0.069, train accuracy: 0.984\n",
      "epoch: 184, time: 5117.196s, loss: 0.175, train accuracy: 0.891\n",
      "epoch: 184, time: 5118.523s, loss: 0.213, train accuracy: 0.898\n",
      "epoch: 184, time: 5119.834s, loss: 0.145, train accuracy: 0.938\n",
      "epoch: 184, time: 5121.129s, loss: 0.098, train accuracy: 0.969\n",
      "epoch: 184, time: 5122.427s, loss: 0.092, train accuracy: 0.977\n",
      "epoch: 184, time: 5123.763s, loss: 0.102, train accuracy: 0.969\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 185, time: 5126.741s, loss: 0.117, train accuracy: 0.961\n",
      "epoch: 185, time: 5128.061s, loss: 0.122, train accuracy: 0.953\n",
      "epoch: 185, time: 5129.375s, loss: 0.051, train accuracy: 0.992\n",
      "epoch: 185, time: 5130.690s, loss: 0.191, train accuracy: 0.930\n",
      "epoch: 185, time: 5132.036s, loss: 0.214, train accuracy: 0.906\n",
      "epoch: 185, time: 5133.349s, loss: 0.136, train accuracy: 0.945\n",
      "epoch: 185, time: 5134.647s, loss: 0.203, train accuracy: 0.914\n",
      "epoch: 185, time: 5135.962s, loss: 0.150, train accuracy: 0.945\n",
      "epoch: 185, time: 5137.293s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 185, time: 5138.659s, loss: 0.131, train accuracy: 0.953\n",
      "epoch: 185, time: 5139.992s, loss: 0.189, train accuracy: 0.922\n",
      "epoch: 185, time: 5141.350s, loss: 0.114, train accuracy: 0.953\n",
      "epoch: 185, time: 5142.647s, loss: 0.185, train accuracy: 0.953\n",
      "epoch: 185, time: 5143.951s, loss: 0.190, train accuracy: 0.945\n",
      "epoch: 185, time: 5145.265s, loss: 0.090, train accuracy: 0.961\n",
      "epoch: 185, time: 5146.558s, loss: 0.180, train accuracy: 0.938\n",
      "epoch: 185, time: 5147.898s, loss: 0.167, train accuracy: 0.953\n",
      "epoch: 185, time: 5149.199s, loss: 0.212, train accuracy: 0.930\n",
      "epoch: 185, time: 5150.526s, loss: 0.127, train accuracy: 0.938\n",
      "epoch: 185, time: 5151.840s, loss: 0.152, train accuracy: 0.961\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 186, time: 5154.799s, loss: 0.100, train accuracy: 0.969\n",
      "epoch: 186, time: 5156.114s, loss: 0.201, train accuracy: 0.922\n",
      "epoch: 186, time: 5157.414s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 186, time: 5158.705s, loss: 0.173, train accuracy: 0.945\n",
      "epoch: 186, time: 5160.061s, loss: 0.165, train accuracy: 0.938\n",
      "epoch: 186, time: 5161.357s, loss: 0.130, train accuracy: 0.969\n",
      "epoch: 186, time: 5162.679s, loss: 0.107, train accuracy: 0.953\n",
      "epoch: 186, time: 5164.005s, loss: 0.178, train accuracy: 0.930\n",
      "epoch: 186, time: 5165.335s, loss: 0.115, train accuracy: 0.969\n",
      "epoch: 186, time: 5166.681s, loss: 0.141, train accuracy: 0.938\n",
      "epoch: 186, time: 5167.986s, loss: 0.125, train accuracy: 0.953\n",
      "epoch: 186, time: 5169.322s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 186, time: 5170.614s, loss: 0.192, train accuracy: 0.938\n",
      "epoch: 186, time: 5171.941s, loss: 0.095, train accuracy: 0.977\n",
      "epoch: 186, time: 5173.280s, loss: 0.095, train accuracy: 0.977\n",
      "epoch: 186, time: 5174.591s, loss: 0.222, train accuracy: 0.922\n",
      "epoch: 186, time: 5175.896s, loss: 0.157, train accuracy: 0.938\n",
      "epoch: 186, time: 5177.244s, loss: 0.157, train accuracy: 0.945\n",
      "epoch: 186, time: 5178.537s, loss: 0.135, train accuracy: 0.945\n",
      "epoch: 186, time: 5179.849s, loss: 0.148, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 187, time: 5182.821s, loss: 0.147, train accuracy: 0.953\n",
      "epoch: 187, time: 5184.154s, loss: 0.075, train accuracy: 0.977\n",
      "epoch: 187, time: 5185.470s, loss: 0.132, train accuracy: 0.945\n",
      "epoch: 187, time: 5186.810s, loss: 0.074, train accuracy: 0.992\n",
      "epoch: 187, time: 5188.130s, loss: 0.103, train accuracy: 0.938\n",
      "epoch: 187, time: 5189.446s, loss: 0.160, train accuracy: 0.945\n",
      "epoch: 187, time: 5190.741s, loss: 0.088, train accuracy: 0.977\n",
      "epoch: 187, time: 5192.041s, loss: 0.142, train accuracy: 0.945\n",
      "epoch: 187, time: 5193.365s, loss: 0.195, train accuracy: 0.922\n",
      "epoch: 187, time: 5194.675s, loss: 0.200, train accuracy: 0.938\n",
      "epoch: 187, time: 5195.978s, loss: 0.157, train accuracy: 0.938\n",
      "epoch: 187, time: 5197.286s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 187, time: 5198.583s, loss: 0.169, train accuracy: 0.930\n",
      "epoch: 187, time: 5199.897s, loss: 0.148, train accuracy: 0.953\n",
      "epoch: 187, time: 5201.196s, loss: 0.185, train accuracy: 0.922\n",
      "epoch: 187, time: 5202.497s, loss: 0.184, train accuracy: 0.938\n",
      "epoch: 187, time: 5203.804s, loss: 0.151, train accuracy: 0.945\n",
      "epoch: 187, time: 5205.113s, loss: 0.142, train accuracy: 0.930\n",
      "epoch: 187, time: 5206.462s, loss: 0.120, train accuracy: 0.930\n",
      "epoch: 187, time: 5207.770s, loss: 0.153, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.839\n",
      "epoch: 188, time: 5210.714s, loss: 0.097, train accuracy: 0.977\n",
      "epoch: 188, time: 5212.038s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 188, time: 5213.345s, loss: 0.117, train accuracy: 0.938\n",
      "epoch: 188, time: 5214.688s, loss: 0.139, train accuracy: 0.930\n",
      "epoch: 188, time: 5215.992s, loss: 0.145, train accuracy: 0.953\n",
      "epoch: 188, time: 5217.292s, loss: 0.205, train accuracy: 0.914\n",
      "epoch: 188, time: 5218.592s, loss: 0.206, train accuracy: 0.930\n",
      "epoch: 188, time: 5219.892s, loss: 0.093, train accuracy: 0.977\n",
      "epoch: 188, time: 5221.221s, loss: 0.091, train accuracy: 0.961\n",
      "epoch: 188, time: 5222.548s, loss: 0.186, train accuracy: 0.953\n",
      "epoch: 188, time: 5223.882s, loss: 0.145, train accuracy: 0.922\n",
      "epoch: 188, time: 5225.190s, loss: 0.124, train accuracy: 0.938\n",
      "epoch: 188, time: 5226.497s, loss: 0.097, train accuracy: 0.961\n",
      "epoch: 188, time: 5227.866s, loss: 0.206, train accuracy: 0.930\n",
      "epoch: 188, time: 5229.176s, loss: 0.123, train accuracy: 0.945\n",
      "epoch: 188, time: 5230.490s, loss: 0.175, train accuracy: 0.938\n",
      "epoch: 188, time: 5231.816s, loss: 0.110, train accuracy: 0.961\n",
      "epoch: 188, time: 5233.139s, loss: 0.075, train accuracy: 0.961\n",
      "epoch: 188, time: 5234.443s, loss: 0.104, train accuracy: 0.945\n",
      "epoch: 188, time: 5235.747s, loss: 0.133, train accuracy: 0.953\n",
      "Accuracy on the test set: 0.842\n",
      "epoch: 189, time: 5238.696s, loss: 0.074, train accuracy: 0.961\n",
      "epoch: 189, time: 5240.020s, loss: 0.119, train accuracy: 0.953\n",
      "epoch: 189, time: 5241.317s, loss: 0.194, train accuracy: 0.930\n",
      "epoch: 189, time: 5242.639s, loss: 0.150, train accuracy: 0.953\n",
      "epoch: 189, time: 5243.946s, loss: 0.095, train accuracy: 0.977\n",
      "epoch: 189, time: 5245.245s, loss: 0.135, train accuracy: 0.945\n",
      "epoch: 189, time: 5246.538s, loss: 0.227, train accuracy: 0.898\n",
      "epoch: 189, time: 5247.852s, loss: 0.219, train accuracy: 0.930\n",
      "epoch: 189, time: 5249.154s, loss: 0.088, train accuracy: 0.977\n",
      "epoch: 189, time: 5250.473s, loss: 0.154, train accuracy: 0.922\n",
      "epoch: 189, time: 5251.793s, loss: 0.181, train accuracy: 0.922\n",
      "epoch: 189, time: 5253.141s, loss: 0.184, train accuracy: 0.961\n",
      "epoch: 189, time: 5254.454s, loss: 0.177, train accuracy: 0.938\n",
      "epoch: 189, time: 5255.766s, loss: 0.165, train accuracy: 0.930\n",
      "epoch: 189, time: 5257.097s, loss: 0.069, train accuracy: 0.984\n",
      "epoch: 189, time: 5258.401s, loss: 0.183, train accuracy: 0.938\n",
      "epoch: 189, time: 5259.708s, loss: 0.110, train accuracy: 0.961\n",
      "epoch: 189, time: 5261.042s, loss: 0.144, train accuracy: 0.938\n",
      "epoch: 189, time: 5262.448s, loss: 0.160, train accuracy: 0.945\n",
      "epoch: 189, time: 5263.743s, loss: 0.121, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.837\n",
      "epoch: 190, time: 5266.704s, loss: 0.111, train accuracy: 0.961\n",
      "epoch: 190, time: 5268.026s, loss: 0.120, train accuracy: 0.953\n",
      "epoch: 190, time: 5269.341s, loss: 0.093, train accuracy: 0.977\n",
      "epoch: 190, time: 5270.641s, loss: 0.171, train accuracy: 0.930\n",
      "epoch: 190, time: 5271.935s, loss: 0.066, train accuracy: 0.977\n",
      "epoch: 190, time: 5273.250s, loss: 0.106, train accuracy: 0.953\n",
      "epoch: 190, time: 5274.564s, loss: 0.134, train accuracy: 0.953\n",
      "epoch: 190, time: 5275.907s, loss: 0.150, train accuracy: 0.945\n",
      "epoch: 190, time: 5277.198s, loss: 0.083, train accuracy: 0.984\n",
      "epoch: 190, time: 5278.523s, loss: 0.245, train accuracy: 0.898\n",
      "epoch: 190, time: 5279.811s, loss: 0.127, train accuracy: 0.945\n",
      "epoch: 190, time: 5281.105s, loss: 0.150, train accuracy: 0.930\n",
      "epoch: 190, time: 5282.411s, loss: 0.128, train accuracy: 0.953\n",
      "epoch: 190, time: 5283.725s, loss: 0.069, train accuracy: 0.984\n",
      "epoch: 190, time: 5285.043s, loss: 0.172, train accuracy: 0.938\n",
      "epoch: 190, time: 5286.424s, loss: 0.142, train accuracy: 0.938\n",
      "epoch: 190, time: 5287.758s, loss: 0.288, train accuracy: 0.891\n",
      "epoch: 190, time: 5289.121s, loss: 0.164, train accuracy: 0.945\n",
      "epoch: 190, time: 5290.421s, loss: 0.185, train accuracy: 0.938\n",
      "epoch: 190, time: 5291.721s, loss: 0.187, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.840\n",
      "epoch: 191, time: 5294.629s, loss: 0.180, train accuracy: 0.953\n",
      "epoch: 191, time: 5295.959s, loss: 0.196, train accuracy: 0.922\n",
      "epoch: 191, time: 5297.281s, loss: 0.118, train accuracy: 0.922\n",
      "epoch: 191, time: 5298.596s, loss: 0.125, train accuracy: 0.953\n",
      "epoch: 191, time: 5299.919s, loss: 0.180, train accuracy: 0.930\n",
      "epoch: 191, time: 5301.211s, loss: 0.217, train accuracy: 0.945\n",
      "epoch: 191, time: 5302.505s, loss: 0.076, train accuracy: 0.969\n",
      "epoch: 191, time: 5303.825s, loss: 0.146, train accuracy: 0.953\n",
      "epoch: 191, time: 5305.157s, loss: 0.107, train accuracy: 0.961\n",
      "epoch: 191, time: 5306.451s, loss: 0.085, train accuracy: 0.969\n",
      "epoch: 191, time: 5307.843s, loss: 0.127, train accuracy: 0.961\n",
      "epoch: 191, time: 5309.153s, loss: 0.126, train accuracy: 0.945\n",
      "epoch: 191, time: 5310.448s, loss: 0.126, train accuracy: 0.945\n",
      "epoch: 191, time: 5311.757s, loss: 0.169, train accuracy: 0.961\n",
      "epoch: 191, time: 5313.077s, loss: 0.085, train accuracy: 0.977\n",
      "epoch: 191, time: 5314.435s, loss: 0.157, train accuracy: 0.945\n",
      "epoch: 191, time: 5315.727s, loss: 0.186, train accuracy: 0.945\n",
      "epoch: 191, time: 5317.029s, loss: 0.097, train accuracy: 0.977\n",
      "epoch: 191, time: 5318.374s, loss: 0.118, train accuracy: 0.961\n",
      "epoch: 191, time: 5319.690s, loss: 0.191, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 192, time: 5322.662s, loss: 0.091, train accuracy: 0.961\n",
      "epoch: 192, time: 5323.976s, loss: 0.172, train accuracy: 0.930\n",
      "epoch: 192, time: 5325.280s, loss: 0.125, train accuracy: 0.961\n",
      "epoch: 192, time: 5326.598s, loss: 0.200, train accuracy: 0.914\n",
      "epoch: 192, time: 5327.913s, loss: 0.108, train accuracy: 0.953\n",
      "epoch: 192, time: 5329.230s, loss: 0.117, train accuracy: 0.961\n",
      "epoch: 192, time: 5330.553s, loss: 0.118, train accuracy: 0.953\n",
      "epoch: 192, time: 5331.861s, loss: 0.137, train accuracy: 0.945\n",
      "epoch: 192, time: 5333.186s, loss: 0.088, train accuracy: 0.969\n",
      "epoch: 192, time: 5334.516s, loss: 0.123, train accuracy: 0.953\n",
      "epoch: 192, time: 5335.827s, loss: 0.293, train accuracy: 0.922\n",
      "epoch: 192, time: 5337.156s, loss: 0.236, train accuracy: 0.922\n",
      "epoch: 192, time: 5338.474s, loss: 0.120, train accuracy: 0.953\n",
      "epoch: 192, time: 5339.770s, loss: 0.143, train accuracy: 0.945\n",
      "epoch: 192, time: 5341.105s, loss: 0.115, train accuracy: 0.961\n",
      "epoch: 192, time: 5342.416s, loss: 0.103, train accuracy: 0.977\n",
      "epoch: 192, time: 5343.751s, loss: 0.123, train accuracy: 0.969\n",
      "epoch: 192, time: 5345.082s, loss: 0.136, train accuracy: 0.914\n",
      "epoch: 192, time: 5346.387s, loss: 0.103, train accuracy: 0.977\n",
      "epoch: 192, time: 5347.682s, loss: 0.143, train accuracy: 0.938\n",
      "Accuracy on the test set: 0.841\n",
      "epoch: 193, time: 5350.596s, loss: 0.108, train accuracy: 0.953\n",
      "epoch: 193, time: 5351.911s, loss: 0.101, train accuracy: 0.961\n",
      "epoch: 193, time: 5353.213s, loss: 0.160, train accuracy: 0.922\n",
      "epoch: 193, time: 5354.604s, loss: 0.080, train accuracy: 0.984\n",
      "epoch: 193, time: 5355.934s, loss: 0.211, train accuracy: 0.961\n",
      "epoch: 193, time: 5357.246s, loss: 0.127, train accuracy: 0.953\n",
      "epoch: 193, time: 5358.544s, loss: 0.112, train accuracy: 0.961\n",
      "epoch: 193, time: 5359.860s, loss: 0.170, train accuracy: 0.930\n",
      "epoch: 193, time: 5361.165s, loss: 0.075, train accuracy: 0.977\n",
      "epoch: 193, time: 5362.534s, loss: 0.157, train accuracy: 0.922\n",
      "epoch: 193, time: 5363.888s, loss: 0.143, train accuracy: 0.961\n",
      "epoch: 193, time: 5365.219s, loss: 0.090, train accuracy: 0.992\n",
      "epoch: 193, time: 5366.532s, loss: 0.166, train accuracy: 0.938\n",
      "epoch: 193, time: 5367.826s, loss: 0.150, train accuracy: 0.938\n",
      "epoch: 193, time: 5369.129s, loss: 0.103, train accuracy: 0.969\n",
      "epoch: 193, time: 5370.432s, loss: 0.162, train accuracy: 0.938\n",
      "epoch: 193, time: 5371.759s, loss: 0.244, train accuracy: 0.922\n",
      "epoch: 193, time: 5373.059s, loss: 0.160, train accuracy: 0.930\n",
      "epoch: 193, time: 5374.364s, loss: 0.232, train accuracy: 0.898\n",
      "epoch: 193, time: 5375.685s, loss: 0.197, train accuracy: 0.906\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 194, time: 5378.607s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 194, time: 5379.928s, loss: 0.081, train accuracy: 0.961\n",
      "epoch: 194, time: 5381.226s, loss: 0.067, train accuracy: 0.977\n",
      "epoch: 194, time: 5382.572s, loss: 0.133, train accuracy: 0.969\n",
      "epoch: 194, time: 5383.929s, loss: 0.079, train accuracy: 0.977\n",
      "epoch: 194, time: 5385.242s, loss: 0.067, train accuracy: 0.992\n",
      "epoch: 194, time: 5386.540s, loss: 0.091, train accuracy: 0.977\n",
      "epoch: 194, time: 5387.851s, loss: 0.202, train accuracy: 0.945\n",
      "epoch: 194, time: 5389.196s, loss: 0.109, train accuracy: 0.961\n",
      "epoch: 194, time: 5390.512s, loss: 0.185, train accuracy: 0.914\n",
      "epoch: 194, time: 5391.883s, loss: 0.080, train accuracy: 0.969\n",
      "epoch: 194, time: 5393.196s, loss: 0.227, train accuracy: 0.938\n",
      "epoch: 194, time: 5394.497s, loss: 0.117, train accuracy: 0.969\n",
      "epoch: 194, time: 5395.795s, loss: 0.141, train accuracy: 0.938\n",
      "epoch: 194, time: 5397.133s, loss: 0.160, train accuracy: 0.961\n",
      "epoch: 194, time: 5398.436s, loss: 0.155, train accuracy: 0.938\n",
      "epoch: 194, time: 5399.770s, loss: 0.132, train accuracy: 0.930\n",
      "epoch: 194, time: 5401.076s, loss: 0.161, train accuracy: 0.938\n",
      "epoch: 194, time: 5402.380s, loss: 0.083, train accuracy: 0.977\n",
      "epoch: 194, time: 5403.681s, loss: 0.157, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.844\n",
      "epoch: 195, time: 5406.598s, loss: 0.074, train accuracy: 0.961\n",
      "epoch: 195, time: 5407.944s, loss: 0.129, train accuracy: 0.953\n",
      "epoch: 195, time: 5409.272s, loss: 0.149, train accuracy: 0.930\n",
      "epoch: 195, time: 5410.581s, loss: 0.244, train accuracy: 0.922\n",
      "epoch: 195, time: 5411.895s, loss: 0.169, train accuracy: 0.938\n",
      "epoch: 195, time: 5413.235s, loss: 0.106, train accuracy: 0.969\n",
      "epoch: 195, time: 5414.533s, loss: 0.119, train accuracy: 0.945\n",
      "epoch: 195, time: 5415.882s, loss: 0.173, train accuracy: 0.938\n",
      "epoch: 195, time: 5417.185s, loss: 0.224, train accuracy: 0.930\n",
      "epoch: 195, time: 5418.492s, loss: 0.142, train accuracy: 0.953\n",
      "epoch: 195, time: 5419.817s, loss: 0.107, train accuracy: 0.969\n",
      "epoch: 195, time: 5421.132s, loss: 0.076, train accuracy: 0.961\n",
      "epoch: 195, time: 5422.456s, loss: 0.130, train accuracy: 0.938\n",
      "epoch: 195, time: 5423.787s, loss: 0.118, train accuracy: 0.969\n",
      "epoch: 195, time: 5425.102s, loss: 0.111, train accuracy: 0.945\n",
      "epoch: 195, time: 5426.404s, loss: 0.092, train accuracy: 0.969\n",
      "epoch: 195, time: 5427.718s, loss: 0.142, train accuracy: 0.945\n",
      "epoch: 195, time: 5429.023s, loss: 0.099, train accuracy: 0.977\n",
      "epoch: 195, time: 5430.317s, loss: 0.125, train accuracy: 0.945\n",
      "epoch: 195, time: 5431.630s, loss: 0.239, train accuracy: 0.922\n",
      "Accuracy on the test set: 0.836\n",
      "epoch: 196, time: 5434.610s, loss: 0.098, train accuracy: 0.961\n",
      "epoch: 196, time: 5435.920s, loss: 0.140, train accuracy: 0.969\n",
      "epoch: 196, time: 5437.217s, loss: 0.202, train accuracy: 0.953\n",
      "epoch: 196, time: 5438.515s, loss: 0.161, train accuracy: 0.938\n",
      "epoch: 196, time: 5439.818s, loss: 0.104, train accuracy: 0.953\n",
      "epoch: 196, time: 5441.119s, loss: 0.162, train accuracy: 0.930\n",
      "epoch: 196, time: 5442.415s, loss: 0.178, train accuracy: 0.938\n",
      "epoch: 196, time: 5443.731s, loss: 0.140, train accuracy: 0.938\n",
      "epoch: 196, time: 5445.036s, loss: 0.068, train accuracy: 0.977\n",
      "epoch: 196, time: 5446.345s, loss: 0.137, train accuracy: 0.945\n",
      "epoch: 196, time: 5447.650s, loss: 0.159, train accuracy: 0.945\n",
      "epoch: 196, time: 5448.979s, loss: 0.082, train accuracy: 0.977\n",
      "epoch: 196, time: 5450.296s, loss: 0.205, train accuracy: 0.906\n",
      "epoch: 196, time: 5451.604s, loss: 0.070, train accuracy: 0.961\n",
      "epoch: 196, time: 5452.902s, loss: 0.198, train accuracy: 0.922\n",
      "epoch: 196, time: 5454.273s, loss: 0.206, train accuracy: 0.922\n",
      "epoch: 196, time: 5455.591s, loss: 0.187, train accuracy: 0.938\n",
      "epoch: 196, time: 5456.911s, loss: 0.102, train accuracy: 0.977\n",
      "epoch: 196, time: 5458.228s, loss: 0.189, train accuracy: 0.945\n",
      "epoch: 196, time: 5459.543s, loss: 0.185, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.843\n",
      "epoch: 197, time: 5462.511s, loss: 0.089, train accuracy: 0.977\n",
      "epoch: 197, time: 5463.869s, loss: 0.098, train accuracy: 0.945\n",
      "epoch: 197, time: 5465.169s, loss: 0.122, train accuracy: 0.969\n",
      "epoch: 197, time: 5466.511s, loss: 0.075, train accuracy: 0.984\n",
      "epoch: 197, time: 5467.829s, loss: 0.159, train accuracy: 0.922\n",
      "epoch: 197, time: 5469.129s, loss: 0.107, train accuracy: 0.961\n",
      "epoch: 197, time: 5470.454s, loss: 0.067, train accuracy: 0.977\n",
      "epoch: 197, time: 5471.779s, loss: 0.105, train accuracy: 0.969\n",
      "epoch: 197, time: 5473.099s, loss: 0.161, train accuracy: 0.930\n",
      "epoch: 197, time: 5474.411s, loss: 0.067, train accuracy: 0.977\n",
      "epoch: 197, time: 5475.730s, loss: 0.085, train accuracy: 0.969\n",
      "epoch: 197, time: 5477.029s, loss: 0.164, train accuracy: 0.945\n",
      "epoch: 197, time: 5478.325s, loss: 0.160, train accuracy: 0.938\n",
      "epoch: 197, time: 5479.651s, loss: 0.150, train accuracy: 0.930\n",
      "epoch: 197, time: 5480.983s, loss: 0.124, train accuracy: 0.961\n",
      "epoch: 197, time: 5482.307s, loss: 0.171, train accuracy: 0.938\n",
      "epoch: 197, time: 5483.613s, loss: 0.127, train accuracy: 0.938\n",
      "epoch: 197, time: 5484.911s, loss: 0.272, train accuracy: 0.891\n",
      "epoch: 197, time: 5486.236s, loss: 0.181, train accuracy: 0.930\n",
      "epoch: 197, time: 5487.538s, loss: 0.170, train accuracy: 0.930\n",
      "Accuracy on the test set: 0.838\n",
      "epoch: 198, time: 5490.478s, loss: 0.106, train accuracy: 0.953\n",
      "epoch: 198, time: 5491.834s, loss: 0.131, train accuracy: 0.953\n",
      "epoch: 198, time: 5493.140s, loss: 0.161, train accuracy: 0.930\n",
      "epoch: 198, time: 5494.530s, loss: 0.064, train accuracy: 0.984\n",
      "epoch: 198, time: 5495.832s, loss: 0.138, train accuracy: 0.945\n",
      "epoch: 198, time: 5497.130s, loss: 0.120, train accuracy: 0.953\n",
      "epoch: 198, time: 5498.447s, loss: 0.183, train accuracy: 0.945\n",
      "epoch: 198, time: 5499.765s, loss: 0.161, train accuracy: 0.922\n",
      "epoch: 198, time: 5501.064s, loss: 0.163, train accuracy: 0.945\n",
      "epoch: 198, time: 5502.395s, loss: 0.123, train accuracy: 0.953\n",
      "epoch: 198, time: 5503.744s, loss: 0.081, train accuracy: 0.961\n",
      "epoch: 198, time: 5505.075s, loss: 0.122, train accuracy: 0.961\n",
      "epoch: 198, time: 5506.390s, loss: 0.131, train accuracy: 0.938\n",
      "epoch: 198, time: 5507.687s, loss: 0.089, train accuracy: 0.961\n",
      "epoch: 198, time: 5508.979s, loss: 0.529, train accuracy: 0.898\n",
      "epoch: 198, time: 5510.295s, loss: 0.470, train accuracy: 0.828\n",
      "epoch: 198, time: 5511.606s, loss: 0.536, train accuracy: 0.820\n",
      "epoch: 198, time: 5512.916s, loss: 0.373, train accuracy: 0.859\n",
      "epoch: 198, time: 5514.219s, loss: 0.263, train accuracy: 0.898\n",
      "epoch: 198, time: 5515.531s, loss: 0.334, train accuracy: 0.859\n",
      "Accuracy on the test set: 0.822\n",
      "epoch: 199, time: 5518.457s, loss: 0.212, train accuracy: 0.938\n",
      "epoch: 199, time: 5519.797s, loss: 0.840, train accuracy: 0.750\n",
      "epoch: 199, time: 5521.101s, loss: 0.619, train accuracy: 0.789\n",
      "epoch: 199, time: 5522.404s, loss: 0.705, train accuracy: 0.773\n",
      "epoch: 199, time: 5523.717s, loss: 0.591, train accuracy: 0.789\n",
      "epoch: 199, time: 5525.008s, loss: 0.322, train accuracy: 0.891\n",
      "epoch: 199, time: 5526.402s, loss: 0.465, train accuracy: 0.844\n",
      "epoch: 199, time: 5527.704s, loss: 0.785, train accuracy: 0.766\n",
      "epoch: 199, time: 5529.001s, loss: 0.599, train accuracy: 0.781\n",
      "epoch: 199, time: 5530.350s, loss: 0.616, train accuracy: 0.766\n",
      "epoch: 199, time: 5531.645s, loss: 0.675, train accuracy: 0.773\n",
      "epoch: 199, time: 5532.950s, loss: 0.628, train accuracy: 0.812\n",
      "epoch: 199, time: 5534.282s, loss: 0.780, train accuracy: 0.758\n",
      "epoch: 199, time: 5535.589s, loss: 0.830, train accuracy: 0.758\n",
      "epoch: 199, time: 5536.897s, loss: 0.465, train accuracy: 0.797\n",
      "epoch: 199, time: 5538.189s, loss: 0.481, train accuracy: 0.836\n",
      "epoch: 199, time: 5539.509s, loss: 0.456, train accuracy: 0.820\n",
      "epoch: 199, time: 5540.805s, loss: 0.499, train accuracy: 0.836\n",
      "epoch: 199, time: 5542.094s, loss: 0.481, train accuracy: 0.867\n",
      "epoch: 199, time: 5543.407s, loss: 0.468, train accuracy: 0.852\n",
      "Accuracy on the test set: 0.791\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(0,200):\n",
    "\n",
    "    model.train()  # Put the network in train mode\n",
    "    for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "        optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = error(y_pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute relevant metrics\n",
    "\n",
    "        y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "        correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
    "\n",
    "        elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "        # Show progress every 20 batches \n",
    "        if not i % 20:\n",
    "            print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
    "    \n",
    "    correct_total = 0\n",
    "\n",
    "    model.eval()  # Put the network in eval mode\n",
    "    for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "        y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "    print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')\n",
    "    \n",
    "    # Save weights every 10 epochs\n",
    "    if epoch%10==0:\n",
    "        torch.save(model.state_dict(), f\"./weights/epoch-{epoch}_accuracy-{correct_total/len(testset):.3f}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3ee41-1653-4a95-9799-d7e9662b042a",
   "metadata": {},
   "source": [
    "# Load latest weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64993e44-ee6c-466f-b1b3-182fe3b9183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\raulv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\raulv\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\raulv\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights: epoch-190_accuracy-0.840.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./weights')\n",
    "weight_paths = [os.path.join('weights', basename) for basename in files]\n",
    "final_weight_file = os.path.basename(max(weight_paths, key=os.path.getctime))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
    "\n",
    "# Replace the final fully-connected layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = torch.nn.Linear(num_ftrs, len(classes))\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join('weights', final_weight_file), map_location=device))\n",
    "print('Loaded weights: ' + final_weight_file)\n",
    "\n",
    "# sets the module in eval node\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a1841-4b85-4bb0-8746-7b6bee724e88",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2846b7b-9c54-4bac-a1c9-42592d57963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.840\n"
     ]
    }
   ],
   "source": [
    "correct_total = 0\n",
    "for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "    y_pred = model(x_batch)\n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5665bb6-f491-4ca1-a12f-9e5cc4cfda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(X):\n",
    "    X = inverse_transform(X)\n",
    "\n",
    "    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n",
    "                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442b4134-a5d7-49b1-9c24-0a223482d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  plane dog   frog  ship  plane cat   dog   deer  plane plane truck dog   bird  bird  bird  plane\n",
      "Predicted:  plane dog   frog  ship  plane cat   frog  deer  plane plane truck dog   bird  bird  bird  plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "show(torchvision.utils.make_grid(images[:16]))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(16)))\n",
    "\n",
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0222e3-3285-4147-92da-f03ae49712d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 83.6 %\n",
      "Accuracy for class: car   is 92.3 %\n",
      "Accuracy for class: bird  is 81.7 %\n",
      "Accuracy for class: cat   is 64.0 %\n",
      "Accuracy for class: deer  is 82.9 %\n",
      "Accuracy for class: dog   is 79.9 %\n",
      "Accuracy for class: frog  is 86.7 %\n",
      "Accuracy for class: horse is 86.8 %\n",
      "Accuracy for class: ship  is 91.0 %\n",
      "Accuracy for class: truck is 91.0 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2575df-8bca-4a4e-bc4e-a6f21e902238",
   "metadata": {},
   "source": [
    "# Adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e78f946-d84e-4101-892e-ab34f5e95fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GeneticSolver:\n",
    "    def __init__(self, image_size, population_size=100, n_generations=1000, retain_best=0.8, retain_random=0.05, mutate_chance=0.05,\n",
    "                 verbosity=0, verbose_step=50, random_state=None, warm_start=False, early_stopping=True, patience=20):\n",
    "        \"\"\"\n",
    "        :param population_size: number of individual candidate solutions\n",
    "        :param n_generations: number of generations\n",
    "        :param retain_best: percentage of best candidates to select into the next generation\n",
    "        :param retain_random: probability of selecting sub-optimal candidate into the next generation\n",
    "        :param mutate_chance: candidate mutation chance\n",
    "        :param verbosity: level of verbosity (0 - quiet, 1 - evolution information, 2 - spamming like it's 2003)\n",
    "        :param verbosity_step: number of generations to process before showing the best score\n",
    "        :param random_state: if specified, initializes seed with this value\n",
    "        :param warm_start: if True, initial population generation step is omitted, allowing for continuing training\n",
    "        :param early_stopping: if True, evolution will stop if top-10 candidates are not changing for several generations\n",
    "        :param patience: number of generations to wait for best solution change when <early_stopping>\n",
    "        \"\"\"\n",
    "        self.image_size = image_size\n",
    "        self.population_size = population_size\n",
    "        self.n_generations = n_generations\n",
    "        self.retain_best = retain_best\n",
    "        self.retain_random = retain_random\n",
    "        self.mutate_chance = mutate_chance\n",
    "        self.verbosity = verbosity\n",
    "        self.verbosity_step = verbose_step\n",
    "        self.random_state = random_state\n",
    "        self.warm_start = warm_start\n",
    "        self.early_stopping = early_stopping\n",
    "        self.patience = patience\n",
    "\n",
    "        self._population = None\n",
    "\n",
    "    def solve(self, fitness_fn, n_generations=-1, verbose_step=None):\n",
    "        \"\"\"\n",
    "        :param fitness_fn: function to optimize w.r.t.\n",
    "        :param n_generations: number of evolution generations. Overrides initialization value if specified\n",
    "        :return: best gene from the population pool. You can still have access to population and the corresponding scores afterwards\n",
    "        \"\"\"\n",
    "        if verbose_step is None:\n",
    "            verbose_step = self.verbose_step\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        if self._population is None or self.warm_start:\n",
    "            self._population = self._generate_population(self.image_size)\n",
    "    \n",
    "        if n_generations != -1:\n",
    "            self.n_generations = n_generations\n",
    "    \n",
    "        scores = np.zeros(len(self._population))\n",
    "        prev_scores = np.zeros(len(self._population))\n",
    "        cnt_no_change_in_scores = 0\n",
    "\n",
    "        for generation in range(self.n_generations):\n",
    "            self._population, scores = self.evolve(fitness_fn)\n",
    "            if np.isclose(prev_scores[:10], scores[:10]).all():\n",
    "                cnt_no_change_in_scores += 1\n",
    "            else:\n",
    "                cnt_no_change_in_scores = 0\n",
    "                prev_scores = scores\n",
    "            \n",
    "            if self.verbosity:\n",
    "                if generation == 0:\n",
    "                    print(\"Generation #: best score\")\n",
    "                elif generation == self.n_generations - 1:\n",
    "                    print(\"Generation \",generation,\": \",scores[0])\n",
    "                elif generation % verbose_step == 0:\n",
    "                    print(\"Generation \",generation,\": \",scores[0])\n",
    "                    \n",
    "            if np.isclose(scores[:10], 1).any() or (self.early_stopping and cnt_no_change_in_scores >= self.patience):\n",
    "                if self.verbosity:\n",
    "                    print(\"Early stopping on generation \",generation, \" with best score \", scores[0])\n",
    "                break\n",
    "\n",
    "        return self._population[0], scores[0]\n",
    "\n",
    "    def _generate_population(self, image_size):\n",
    "        \"\"\"\n",
    "        Generating initial population of individual solutions\n",
    "        :return: initial population as an array\n",
    "        \"\"\"\n",
    "        return np.random.rand(self.population_size, *image_size)\n",
    "\n",
    "    def evolve(self, fitness_fn):\n",
    "        \"\"\"\n",
    "        Evolution step\n",
    "        :return: new generation of the same size along with scores of the best retained individuals\n",
    "        \"\"\"\n",
    "        scores = np.array(self.score_population(self._population, fitness_fn))\n",
    "        \n",
    "        retain_len = int(len(scores) * self.retain_best)\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        self._population = [self._population[idx] for idx in sorted_indices]\n",
    "        best_scores = scores[sorted_indices][:retain_len]\n",
    "        if self.verbosity > 1:\n",
    "            print(\"best scores:\", best_scores)\n",
    "        parents = self._population[:retain_len]\n",
    "        leftovers = self._population[retain_len:]\n",
    "\n",
    "        cnt_degenerate = 0\n",
    "        for gene in leftovers:\n",
    "            if np.random.rand() < self.retain_random:\n",
    "                cnt_degenerate += 1\n",
    "                parents.append(gene)\n",
    "        if self.verbosity > 1:\n",
    "            print(\"# of degenerates left: \", cnt_degenerate)\n",
    "\n",
    "        cnt_mutations = 0\n",
    "        for gene in parents[1:]:  # mutate everyone expecting for the best candidate\n",
    "            if np.random.rand() < self.mutate_chance:\n",
    "                self.mutate(gene, self.image_size)\n",
    "                cnt_mutations += 1\n",
    "        if self.verbosity > 1:\n",
    "            print(\"# of mutations: \", cnt_mutations)\n",
    "\n",
    "        places_left = self.population_size - retain_len\n",
    "        children = []\n",
    "        while len(children) < places_left:\n",
    "            mom_idx, dad_idx = np.random.randint(0, retain_len - 1, 2)\n",
    "            if mom_idx != dad_idx:\n",
    "                child1, child2 = self.crossover(parents[mom_idx], parents[dad_idx], self.image_size)\n",
    "                children.append(child1)\n",
    "                if len(children) < places_left:\n",
    "                    children.append(child2)\n",
    "        if self.verbosity > 1:\n",
    "            print(\"# of children: \", len(children))\n",
    "        parents.extend(children)\n",
    "        return parents, best_scores\n",
    "\n",
    "    @classmethod\n",
    "    def crossover(cls, mom, dad, image_size):\n",
    "        \"\"\"\n",
    "        Take two parents, return two children, interchanging half of the allels of each parent randomly\n",
    "        \"\"\"\n",
    "        # select_mask = np.random.randint(0, 2, size=(20, 20), dtype='bool')\n",
    "        select_mask = np.random.binomial(1, 0.5, size=image_size).astype('bool')\n",
    "        child1, child2 = np.copy(mom), np.copy(dad)\n",
    "        child1[select_mask] = dad[select_mask]\n",
    "        child2[select_mask] = mom[select_mask]\n",
    "        return child1, child2\n",
    "\n",
    "    @classmethod\n",
    "    def mutate(cls, field, image_size):\n",
    "        \"\"\"\n",
    "        Inplace mutation of the provided field\n",
    "        \"\"\"\n",
    "        a = np.random.binomial(1, 0.1, size=image_size).astype('bool')\n",
    "        field[a] = np.clip(field[a] + np.random.randn(*field[a].shape) * 0.1, 0, 1)\n",
    "        return field\n",
    "\n",
    "    @classmethod\n",
    "    def score_population(cls, population, fitness_function):\n",
    "        \"\"\"\n",
    "        Apply fitness function for each gene in a population\n",
    "        :param population: list of candidate solutions (images)\n",
    "        :return: list/1d-array of scores for each solution\n",
    "        \"\"\"\n",
    "        if type(population) is list:\n",
    "            population = np.array(population)\n",
    "            \n",
    "        return fitness_function(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "08041b8c-90cd-4db0-98e5-764ef6b0adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_class_probability_empty(X):\n",
    "    \"\"\" Maximize probability of adversarial target class, penalizing mean pixel intensity\"\"\"\n",
    "    y = model(torch.Tensor(X).to(device)).to('cpu').detach().numpy()\n",
    "    y_target = y[:, adv_target]\n",
    "    X_mean = X.mean(axis=1).mean(axis=1).mean(axis=1)\n",
    "    return y_target - X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2fc96e74-aba6-4c8c-a0a6-08ff1b5cf963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_probabilities(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = torch.Tensor(X)\n",
    "    prob = F.softmax(model(X.unsqueeze(0).to(device)), dim=1)\n",
    "\n",
    "    print('Confidence scores:\\n' + '\\n'.join(['{}: {}'.format(classes[i], p.item()) for i, p in enumerate(prob.squeeze())]))    \n",
    "    print('\\nLabel with highest confidence score: {}'.format(classes[torch.argmax(prob).item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750244d-d971-4117-ab18-7f1ec5ab846b",
   "metadata": {},
   "source": [
    "## Attack with a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "38687786-334f-4b03-a438-b81bf62f0c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation #: best score\n",
      "Generation  500 :  16.64337788783132\n",
      "Generation  999 :  17.394771363255803\n"
     ]
    }
   ],
   "source": [
    "adv_target = classes.index('frog')\n",
    "m = GeneticSolver(image_size=image_size, verbosity=True, verbose_step=100, warm_start=True, random_state=42, early_stopping=False)\n",
    "res, score = m.solve(fitness_class_probability_empty, n_generations=1000, verbose_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1720c8c9-a52a-479f-b0e6-d9a0244e72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence scores:\n",
      "plane: 9.209055711327887e-24\n",
      "car: 1.8352561765293533e-25\n",
      "bird: 2.0074374020712105e-12\n",
      "cat: 3.4401385531874313e-15\n",
      "deer: 1.0933132567400463e-18\n",
      "dog: 1.931635766323856e-15\n",
      "frog: 1.0\n",
      "horse: 9.284237228997536e-21\n",
      "ship: 7.525056508696135e-22\n",
      "truck: 1.8576779749688307e-23\n",
      "\n",
      "Label with highest confidence score: frog\n"
     ]
    }
   ],
   "source": [
    "show(torch.Tensor(res))\n",
    "show_probabilities(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2fa7e-3dc3-4f9e-8081-dd19db0b41ed",
   "metadata": {},
   "source": [
    "## Generating a dataset of adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0516888-14ce-4454-a0e6-9ba962ad474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_adversarial_dataset = True\n",
    "\n",
    "if generate_adversarial_dataset:\n",
    "    if os.path.exists(os.path.join('adversarial_dataset')):\n",
    "        shutil.rmtree(os.path.join('adversarial_dataset'))\n",
    "    !mkdir adversarial_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e3dabe29-f92f-48f1-b52a-38f605506092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for the dataset\n",
    "batch_size = 128\n",
    "num_batches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a5ff4-1f9b-4017-beb5-f4598d6335d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loop below takes around 1-2 days to run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "80af5e68-4a1f-452a-bcde-6c1764950bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for class: plane\n",
      "Batch: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                         | 37/128 [07:38<18:47, 12.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [262], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     adv_target \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mindex(aClass)\n\u001b[0;32m      9\u001b[0m     m \u001b[38;5;241m=\u001b[39m GeneticSolver(image_size\u001b[38;5;241m=\u001b[39mimage_size, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m     batch_list[i], score \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness_class_probability_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Create a tensor to hold the res tensors\u001b[39;00m\n\u001b[0;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([batch_size, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m])\n",
      "Cell \u001b[1;32mIn [243], line 55\u001b[0m, in \u001b[0;36mGeneticSolver.solve\u001b[1;34m(self, fitness_fn, n_generations, verbose_step)\u001b[0m\n\u001b[0;32m     52\u001b[0m cnt_no_change_in_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_generations):\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_population, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(prev_scores[:\u001b[38;5;241m10\u001b[39m], scores[:\u001b[38;5;241m10\u001b[39m])\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     57\u001b[0m         cnt_no_change_in_scores \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn [243], line 89\u001b[0m, in \u001b[0;36mGeneticSolver.evolve\u001b[1;34m(self, fitness_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitness_fn):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    Evolution step\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    :return: new generation of the same size along with scores of the best retained individuals\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_population\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness_fn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     91\u001b[0m     retain_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scores) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretain_best)\n\u001b[0;32m     92\u001b[0m     sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(scores)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn [243], line 161\u001b[0m, in \u001b[0;36mGeneticSolver.score_population\u001b[1;34m(cls, population, fitness_function)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(population) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    159\u001b[0m     population \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(population)\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfitness_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [181], line 3\u001b[0m, in \u001b[0;36mfitness_class_probability_empty\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfitness_class_probability_empty\u001b[39m(X):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\" Maximize probability of adversarial target class, penalizing mean pixel intensity\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m     y_target \u001b[38;5;241m=\u001b[39m y[:, adv_target]\n\u001b[0;32m      5\u001b[0m     X_mean \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\mobilenetv2.py:174\u001b[0m, in \u001b[0;36mMobileNetV2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\mobilenetv2.py:166\u001b[0m, in \u001b[0;36mMobileNetV2._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torchvision\\models\\mobilenetv2.py:62\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for aClass in classes:\n",
    "    print('Generating adversarial examples for class: ' + aClass)\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        print('Batch: ' + str(batch_num+1) + ' out of ' + str(num_batches))\n",
    "        batch_list = [0]*batch_size\n",
    "        for i in tqdm(range(0,batch_size)):\n",
    "            adv_target = classes.index(aClass)\n",
    "            m = GeneticSolver(image_size=image_size, verbosity=False, verbose_step=100, warm_start=True, random_state=42, early_stopping=False)\n",
    "            batch_list[i], score = m.solve(fitness_class_probability_empty, n_generations=1000, verbose_step=500)\n",
    "\n",
    "        # Create a tensor to hold the res tensors\n",
    "        batch = torch.zeros([batch_size, 3, 32, 32])\n",
    "\n",
    "        # Loop over the res tensors and concatenate them into the batch tensor\n",
    "        for i, bat in enumerate(batch_list):\n",
    "            batch[i] = torch.Tensor(bat)\n",
    "\n",
    "        torch.save(batch, os.path.join('adversarial_dataset', aClass + '_' + str(batch_num) + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "869b478e-dca3-4afc-8015-8544a2ed92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  plane plane\n"
     ]
    }
   ],
   "source": [
    "batch = torch.load(\"./adversarial_dataset/plane.pt\")\n",
    "outputs = model(batch.to(device))\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23295ea7-1c10-4140-89e3-cdce5c9bb33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course-env",
   "language": "python",
   "name": "dl_course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
