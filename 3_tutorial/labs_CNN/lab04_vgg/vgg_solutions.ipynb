{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM2M1Tn73NQ5"
   },
   "source": [
    "# VGG on CIFAR - solutions\n",
    "In this lab we will train a VGG model on the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeBGrEwi06fz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Vufhok43UWG"
   },
   "source": [
    "It is recommended to use the GPU for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTnvxLin1LNV"
   },
   "outputs": [],
   "source": [
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYGgIG8SGIr9"
   },
   "source": [
    "### Load the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40KsWyBt2qmv"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLHJlUyjGNhA"
   },
   "source": [
    "### Define the VGG architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkHt81xb2-SN"
   },
   "outputs": [],
   "source": [
    "class VGG_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16        \n",
    "        self.conv1a = nn.Conv2d(3,   64,  kernel_size=3, padding=1 )\n",
    "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64,  128, kernel_size=3, padding=1 )\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1 )\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1 )\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1 )\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1 )\n",
    "        self.pool4  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096,4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1, 2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x) \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4iagyWQ6Axl"
   },
   "outputs": [],
   "source": [
    "# Build the network and move its parameters to either GPU or CPU\n",
    "net = VGG_convnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvENiJAt6Auj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr=0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etpYx0fIHNvc"
   },
   "source": [
    "### Train the model on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmSJpneX6ApZ"
   },
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "optimizer=torch.optim.SGD(net.parameters(), lr=my_lr)\n",
    "\n",
    "for epoch in range(1,30):\n",
    "\n",
    "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "    \n",
    "    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute relevant metrics\n",
    "    \n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
    "\n",
    "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "    # Show progress every 20 batches \n",
    "    if not i % 20:\n",
    "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Uc1816EHVQY"
   },
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hItOOXuwCD0w"
   },
   "outputs": [],
   "source": [
    "correct_total = 0\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "  y_pred = net(x_batch)\n",
    "  y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woDv4gpdY85_"
   },
   "source": [
    "### Define a function to show an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6h5iFcBkC3ui"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n",
    "                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "# Function to show an image tensor\n",
    "def show(X):\n",
    "    X = inverse_transform(X)\n",
    "\n",
    "    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61nCgln8HZaN"
   },
   "source": [
    "### Show the model's prediction for a random sample from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2grnY_u2-O2"
   },
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "im_minibatch, label_minibatch = iter(testloader).next()\n",
    "im, label = im_minibatch[0].cpu(), label_minibatch[0].cpu()\n",
    "\n",
    "# diplay the picture\n",
    "show(im)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "prob = F.softmax(net.cpu()(im.unsqueeze(0)), dim=1)\n",
    "\n",
    "print('Confidence scores:\\n' + '\\n'.join(['{}: {}'.format(classes[i], p.item()) for i, p in enumerate(prob.squeeze())]))\n",
    "\n",
    "print('\\nLabel with highest confidence score: {}'.format(classes[torch.argmax(prob).item()]))\n",
    "print('\\nTrue label: {}'.format(classes[label]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vgg_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
