{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM2M1Tn73NQ5"
   },
   "source": [
    "# VGG on CIFAR\n",
    "In this lab we will train a VGG model on the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeBGrEwi06fz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Vufhok43UWG"
   },
   "source": [
    "It is recommended to use the GPU for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTnvxLin1LNV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "      device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYGgIG8SGIr9"
   },
   "source": [
    "### Load the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40KsWyBt2qmv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d149191989414ad3adad8ccd9fec1ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_cifar\\cifar-10-python.tar.gz to ./data_cifar\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLHJlUyjGNhA"
   },
   "source": [
    "### Define the VGG architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkHt81xb2-SN"
   },
   "outputs": [],
   "source": [
    "class VGG_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16        \n",
    "        self.conv1a = nn.Conv2d(3,   64,  kernel_size=3, padding=1 )\n",
    "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64,   128,  kernel_size=3, padding=1 )\n",
    "        self.conv2b = nn.Conv2d(128,   128,  kernel_size=3, padding=1 )\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
    "        self.conv3a = nn.Conv2d(128,   256,  kernel_size=3, padding=1 )\n",
    "        self.conv3b = nn.Conv2d(256,   256,  kernel_size=3, padding=1 )\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256,   512,  kernel_size=3, padding=1 )\n",
    "        self.pool4  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1,2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x) \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4iagyWQ6Axl"
   },
   "outputs": [],
   "source": [
    "# Build the network and move its parameters to either GPU or CPU\n",
    "net = VGG_convnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvENiJAt6Auj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr=0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etpYx0fIHNvc"
   },
   "source": [
    "### Train the model on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmSJpneX6ApZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, time: 2.989s, loss: 2.302, train accuracy: 0.109\n",
      "epoch: 1, time: 3.663s, loss: 2.299, train accuracy: 0.086\n",
      "epoch: 1, time: 4.323s, loss: 2.306, train accuracy: 0.078\n",
      "epoch: 1, time: 4.989s, loss: 2.303, train accuracy: 0.125\n",
      "epoch: 1, time: 5.655s, loss: 2.310, train accuracy: 0.094\n",
      "epoch: 1, time: 6.317s, loss: 2.298, train accuracy: 0.125\n",
      "epoch: 1, time: 6.982s, loss: 2.304, train accuracy: 0.078\n",
      "epoch: 1, time: 7.647s, loss: 2.303, train accuracy: 0.117\n",
      "epoch: 1, time: 8.310s, loss: 2.305, train accuracy: 0.094\n",
      "epoch: 1, time: 8.989s, loss: 2.306, train accuracy: 0.062\n",
      "epoch: 1, time: 9.672s, loss: 2.303, train accuracy: 0.078\n",
      "epoch: 1, time: 10.344s, loss: 2.304, train accuracy: 0.070\n",
      "epoch: 1, time: 11.024s, loss: 2.276, train accuracy: 0.148\n",
      "epoch: 1, time: 11.696s, loss: 2.275, train accuracy: 0.195\n",
      "epoch: 1, time: 12.372s, loss: 2.322, train accuracy: 0.070\n",
      "epoch: 1, time: 13.053s, loss: 2.305, train accuracy: 0.055\n",
      "epoch: 1, time: 13.734s, loss: 2.309, train accuracy: 0.125\n",
      "epoch: 1, time: 14.407s, loss: 2.292, train accuracy: 0.086\n",
      "epoch: 1, time: 15.091s, loss: 2.220, train accuracy: 0.156\n",
      "epoch: 1, time: 15.762s, loss: 2.304, train accuracy: 0.086\n",
      "epoch: 2, time: 16.127s, loss: 2.281, train accuracy: 0.125\n",
      "epoch: 2, time: 16.789s, loss: 2.259, train accuracy: 0.125\n",
      "epoch: 2, time: 17.463s, loss: 2.154, train accuracy: 0.227\n",
      "epoch: 2, time: 18.123s, loss: 2.085, train accuracy: 0.195\n",
      "epoch: 2, time: 18.787s, loss: 2.028, train accuracy: 0.180\n",
      "epoch: 2, time: 19.454s, loss: 2.110, train accuracy: 0.289\n",
      "epoch: 2, time: 20.118s, loss: 1.971, train accuracy: 0.281\n",
      "epoch: 2, time: 20.784s, loss: 2.096, train accuracy: 0.195\n",
      "epoch: 2, time: 21.447s, loss: 2.018, train accuracy: 0.242\n",
      "epoch: 2, time: 22.108s, loss: 2.126, train accuracy: 0.172\n",
      "epoch: 2, time: 22.767s, loss: 2.133, train accuracy: 0.250\n",
      "epoch: 2, time: 23.441s, loss: 2.054, train accuracy: 0.219\n",
      "epoch: 2, time: 24.106s, loss: 1.988, train accuracy: 0.266\n",
      "epoch: 2, time: 24.774s, loss: 2.253, train accuracy: 0.203\n",
      "epoch: 2, time: 25.439s, loss: 1.923, train accuracy: 0.258\n",
      "epoch: 2, time: 26.104s, loss: 1.852, train accuracy: 0.328\n",
      "epoch: 2, time: 26.784s, loss: 1.890, train accuracy: 0.258\n",
      "epoch: 2, time: 27.453s, loss: 1.871, train accuracy: 0.273\n",
      "epoch: 2, time: 28.127s, loss: 1.750, train accuracy: 0.312\n",
      "epoch: 2, time: 28.785s, loss: 1.882, train accuracy: 0.211\n",
      "epoch: 3, time: 29.152s, loss: 1.685, train accuracy: 0.391\n",
      "epoch: 3, time: 29.863s, loss: 1.679, train accuracy: 0.398\n",
      "epoch: 3, time: 30.535s, loss: 1.687, train accuracy: 0.438\n",
      "epoch: 3, time: 31.201s, loss: 2.210, train accuracy: 0.234\n",
      "epoch: 3, time: 31.865s, loss: 1.524, train accuracy: 0.430\n",
      "epoch: 3, time: 32.533s, loss: 1.815, train accuracy: 0.352\n",
      "epoch: 3, time: 33.200s, loss: 1.759, train accuracy: 0.336\n",
      "epoch: 3, time: 33.889s, loss: 1.704, train accuracy: 0.367\n",
      "epoch: 3, time: 34.575s, loss: 1.495, train accuracy: 0.398\n",
      "epoch: 3, time: 35.237s, loss: 1.421, train accuracy: 0.500\n",
      "epoch: 3, time: 35.898s, loss: 1.649, train accuracy: 0.453\n",
      "epoch: 3, time: 36.558s, loss: 1.510, train accuracy: 0.469\n",
      "epoch: 3, time: 37.235s, loss: 1.608, train accuracy: 0.367\n",
      "epoch: 3, time: 37.895s, loss: 1.766, train accuracy: 0.352\n",
      "epoch: 3, time: 38.552s, loss: 1.500, train accuracy: 0.430\n",
      "epoch: 3, time: 39.213s, loss: 1.464, train accuracy: 0.414\n",
      "epoch: 3, time: 39.892s, loss: 1.508, train accuracy: 0.469\n",
      "epoch: 3, time: 40.550s, loss: 1.542, train accuracy: 0.461\n",
      "epoch: 3, time: 41.211s, loss: 1.693, train accuracy: 0.422\n",
      "epoch: 3, time: 41.876s, loss: 1.345, train accuracy: 0.516\n",
      "epoch: 4, time: 42.235s, loss: 1.524, train accuracy: 0.422\n",
      "epoch: 4, time: 42.912s, loss: 1.303, train accuracy: 0.500\n",
      "epoch: 4, time: 43.576s, loss: 1.348, train accuracy: 0.531\n",
      "epoch: 4, time: 44.241s, loss: 1.310, train accuracy: 0.453\n",
      "epoch: 4, time: 44.905s, loss: 1.162, train accuracy: 0.578\n",
      "epoch: 4, time: 45.566s, loss: 1.462, train accuracy: 0.461\n",
      "epoch: 4, time: 46.231s, loss: 1.382, train accuracy: 0.508\n",
      "epoch: 4, time: 46.900s, loss: 1.450, train accuracy: 0.445\n",
      "epoch: 4, time: 47.565s, loss: 1.413, train accuracy: 0.492\n",
      "epoch: 4, time: 48.232s, loss: 1.431, train accuracy: 0.508\n",
      "epoch: 4, time: 48.909s, loss: 1.248, train accuracy: 0.586\n",
      "epoch: 4, time: 49.578s, loss: 1.193, train accuracy: 0.586\n",
      "epoch: 4, time: 50.240s, loss: 1.549, train accuracy: 0.438\n",
      "epoch: 4, time: 50.901s, loss: 1.250, train accuracy: 0.484\n",
      "epoch: 4, time: 51.569s, loss: 1.168, train accuracy: 0.539\n",
      "epoch: 4, time: 52.242s, loss: 1.364, train accuracy: 0.492\n",
      "epoch: 4, time: 52.906s, loss: 1.252, train accuracy: 0.555\n",
      "epoch: 4, time: 53.573s, loss: 1.059, train accuracy: 0.625\n",
      "epoch: 4, time: 54.239s, loss: 1.382, train accuracy: 0.484\n",
      "epoch: 4, time: 54.907s, loss: 1.225, train accuracy: 0.555\n",
      "epoch: 5, time: 55.283s, loss: 1.056, train accuracy: 0.617\n",
      "epoch: 5, time: 55.954s, loss: 1.081, train accuracy: 0.625\n",
      "epoch: 5, time: 56.616s, loss: 1.369, train accuracy: 0.539\n",
      "epoch: 5, time: 57.282s, loss: 0.931, train accuracy: 0.656\n",
      "epoch: 5, time: 57.949s, loss: 1.001, train accuracy: 0.656\n",
      "epoch: 5, time: 58.619s, loss: 0.932, train accuracy: 0.641\n",
      "epoch: 5, time: 59.288s, loss: 1.135, train accuracy: 0.602\n",
      "epoch: 5, time: 59.955s, loss: 1.049, train accuracy: 0.617\n",
      "epoch: 5, time: 60.630s, loss: 1.183, train accuracy: 0.586\n",
      "epoch: 5, time: 61.295s, loss: 1.040, train accuracy: 0.609\n",
      "epoch: 5, time: 61.965s, loss: 1.206, train accuracy: 0.539\n",
      "epoch: 5, time: 62.638s, loss: 0.988, train accuracy: 0.641\n",
      "epoch: 5, time: 63.302s, loss: 0.838, train accuracy: 0.664\n",
      "epoch: 5, time: 63.970s, loss: 0.887, train accuracy: 0.719\n",
      "epoch: 5, time: 64.636s, loss: 0.926, train accuracy: 0.641\n",
      "epoch: 5, time: 65.308s, loss: 1.063, train accuracy: 0.625\n",
      "epoch: 5, time: 65.976s, loss: 0.976, train accuracy: 0.672\n",
      "epoch: 5, time: 66.643s, loss: 0.947, train accuracy: 0.641\n",
      "epoch: 5, time: 67.311s, loss: 0.937, train accuracy: 0.641\n",
      "epoch: 5, time: 67.979s, loss: 0.818, train accuracy: 0.727\n",
      "epoch: 6, time: 68.351s, loss: 0.967, train accuracy: 0.656\n",
      "epoch: 6, time: 69.019s, loss: 1.167, train accuracy: 0.578\n",
      "epoch: 6, time: 69.686s, loss: 0.888, train accuracy: 0.680\n",
      "epoch: 6, time: 70.356s, loss: 0.839, train accuracy: 0.719\n",
      "epoch: 6, time: 71.020s, loss: 0.885, train accuracy: 0.688\n",
      "epoch: 6, time: 71.686s, loss: 0.856, train accuracy: 0.703\n",
      "epoch: 6, time: 72.352s, loss: 0.772, train accuracy: 0.742\n",
      "epoch: 6, time: 73.020s, loss: 0.693, train accuracy: 0.789\n",
      "epoch: 6, time: 73.685s, loss: 0.744, train accuracy: 0.750\n",
      "epoch: 6, time: 74.352s, loss: 0.930, train accuracy: 0.695\n",
      "epoch: 6, time: 75.018s, loss: 0.756, train accuracy: 0.742\n",
      "epoch: 6, time: 75.689s, loss: 0.856, train accuracy: 0.711\n",
      "epoch: 6, time: 76.357s, loss: 0.756, train accuracy: 0.758\n",
      "epoch: 6, time: 77.018s, loss: 0.810, train accuracy: 0.719\n",
      "epoch: 6, time: 77.683s, loss: 0.884, train accuracy: 0.680\n",
      "epoch: 6, time: 78.364s, loss: 0.835, train accuracy: 0.742\n",
      "epoch: 6, time: 79.031s, loss: 0.791, train accuracy: 0.695\n",
      "epoch: 6, time: 79.697s, loss: 0.834, train accuracy: 0.750\n",
      "epoch: 6, time: 80.364s, loss: 0.902, train accuracy: 0.672\n",
      "epoch: 6, time: 81.033s, loss: 3.268, train accuracy: 0.297\n",
      "epoch: 7, time: 81.393s, loss: 1.018, train accuracy: 0.680\n",
      "epoch: 7, time: 82.083s, loss: 0.763, train accuracy: 0.719\n",
      "epoch: 7, time: 82.743s, loss: 0.653, train accuracy: 0.742\n",
      "epoch: 7, time: 83.406s, loss: 0.652, train accuracy: 0.773\n",
      "epoch: 7, time: 84.080s, loss: 0.644, train accuracy: 0.789\n",
      "epoch: 7, time: 84.746s, loss: 0.837, train accuracy: 0.727\n",
      "epoch: 7, time: 85.413s, loss: 0.690, train accuracy: 0.734\n",
      "epoch: 7, time: 86.077s, loss: 0.781, train accuracy: 0.695\n",
      "epoch: 7, time: 86.731s, loss: 0.762, train accuracy: 0.734\n",
      "epoch: 7, time: 87.390s, loss: 0.929, train accuracy: 0.648\n",
      "epoch: 7, time: 88.053s, loss: 0.683, train accuracy: 0.766\n",
      "epoch: 7, time: 88.711s, loss: 0.619, train accuracy: 0.789\n",
      "epoch: 7, time: 89.368s, loss: 0.605, train accuracy: 0.781\n",
      "epoch: 7, time: 90.031s, loss: 0.608, train accuracy: 0.805\n",
      "epoch: 7, time: 90.689s, loss: 0.897, train accuracy: 0.719\n",
      "epoch: 7, time: 91.347s, loss: 0.498, train accuracy: 0.828\n",
      "epoch: 7, time: 92.008s, loss: 0.699, train accuracy: 0.734\n",
      "epoch: 7, time: 92.666s, loss: 0.626, train accuracy: 0.773\n",
      "epoch: 7, time: 93.329s, loss: 0.752, train accuracy: 0.797\n",
      "epoch: 7, time: 93.993s, loss: 0.697, train accuracy: 0.750\n",
      "epoch: 8, time: 94.350s, loss: 0.522, train accuracy: 0.844\n",
      "epoch: 8, time: 95.036s, loss: 0.495, train accuracy: 0.836\n",
      "epoch: 8, time: 95.711s, loss: 0.490, train accuracy: 0.820\n",
      "epoch: 8, time: 96.369s, loss: 0.533, train accuracy: 0.797\n",
      "epoch: 8, time: 97.044s, loss: 0.452, train accuracy: 0.852\n",
      "epoch: 8, time: 97.761s, loss: 0.749, train accuracy: 0.773\n",
      "epoch: 8, time: 98.487s, loss: 0.555, train accuracy: 0.781\n",
      "epoch: 8, time: 99.176s, loss: 0.398, train accuracy: 0.852\n",
      "epoch: 8, time: 99.847s, loss: 0.610, train accuracy: 0.742\n",
      "epoch: 8, time: 100.538s, loss: 0.700, train accuracy: 0.758\n",
      "epoch: 8, time: 101.226s, loss: 0.528, train accuracy: 0.805\n",
      "epoch: 8, time: 101.902s, loss: 0.409, train accuracy: 0.859\n",
      "epoch: 8, time: 102.565s, loss: 0.612, train accuracy: 0.797\n",
      "epoch: 8, time: 103.225s, loss: 0.519, train accuracy: 0.789\n",
      "epoch: 8, time: 103.886s, loss: 0.555, train accuracy: 0.805\n",
      "epoch: 8, time: 104.547s, loss: 0.479, train accuracy: 0.844\n",
      "epoch: 8, time: 105.230s, loss: 0.539, train accuracy: 0.812\n",
      "epoch: 8, time: 105.900s, loss: 0.540, train accuracy: 0.820\n",
      "epoch: 8, time: 106.569s, loss: 0.613, train accuracy: 0.766\n",
      "epoch: 8, time: 107.251s, loss: 0.480, train accuracy: 0.844\n",
      "epoch: 9, time: 107.625s, loss: 0.380, train accuracy: 0.875\n",
      "epoch: 9, time: 108.305s, loss: 0.306, train accuracy: 0.898\n",
      "epoch: 9, time: 108.983s, loss: 0.595, train accuracy: 0.797\n",
      "epoch: 9, time: 109.650s, loss: 0.424, train accuracy: 0.844\n",
      "epoch: 9, time: 110.327s, loss: 0.273, train accuracy: 0.906\n",
      "epoch: 9, time: 110.995s, loss: 0.387, train accuracy: 0.859\n",
      "epoch: 9, time: 111.669s, loss: 0.461, train accuracy: 0.812\n",
      "epoch: 9, time: 112.329s, loss: 0.456, train accuracy: 0.867\n",
      "epoch: 9, time: 113.004s, loss: 0.406, train accuracy: 0.859\n",
      "epoch: 9, time: 113.667s, loss: 0.373, train accuracy: 0.867\n",
      "epoch: 9, time: 114.327s, loss: 0.505, train accuracy: 0.820\n",
      "epoch: 9, time: 114.995s, loss: 0.384, train accuracy: 0.852\n",
      "epoch: 9, time: 115.661s, loss: 0.276, train accuracy: 0.906\n",
      "epoch: 9, time: 116.349s, loss: 0.484, train accuracy: 0.789\n",
      "epoch: 9, time: 117.024s, loss: 0.365, train accuracy: 0.875\n",
      "epoch: 9, time: 117.693s, loss: 0.546, train accuracy: 0.805\n",
      "epoch: 9, time: 118.368s, loss: 0.602, train accuracy: 0.797\n",
      "epoch: 9, time: 119.034s, loss: 0.470, train accuracy: 0.836\n",
      "epoch: 9, time: 119.703s, loss: 0.338, train accuracy: 0.883\n",
      "epoch: 9, time: 120.374s, loss: 0.510, train accuracy: 0.812\n",
      "epoch: 10, time: 120.742s, loss: 0.353, train accuracy: 0.906\n",
      "epoch: 10, time: 121.427s, loss: 0.565, train accuracy: 0.812\n",
      "epoch: 10, time: 122.100s, loss: 0.210, train accuracy: 0.914\n",
      "epoch: 10, time: 122.777s, loss: 0.270, train accuracy: 0.945\n",
      "epoch: 10, time: 123.437s, loss: 0.278, train accuracy: 0.898\n",
      "epoch: 10, time: 124.100s, loss: 0.364, train accuracy: 0.883\n",
      "epoch: 10, time: 124.762s, loss: 0.379, train accuracy: 0.883\n",
      "epoch: 10, time: 125.419s, loss: 0.243, train accuracy: 0.898\n",
      "epoch: 10, time: 126.083s, loss: 0.218, train accuracy: 0.922\n",
      "epoch: 10, time: 126.744s, loss: 0.318, train accuracy: 0.898\n",
      "epoch: 10, time: 127.415s, loss: 0.468, train accuracy: 0.844\n",
      "epoch: 10, time: 128.095s, loss: 0.345, train accuracy: 0.898\n",
      "epoch: 10, time: 128.795s, loss: 0.395, train accuracy: 0.859\n",
      "epoch: 10, time: 129.472s, loss: 0.336, train accuracy: 0.875\n",
      "epoch: 10, time: 130.157s, loss: 0.230, train accuracy: 0.930\n",
      "epoch: 10, time: 130.832s, loss: 0.273, train accuracy: 0.898\n",
      "epoch: 10, time: 131.507s, loss: 0.349, train accuracy: 0.867\n",
      "epoch: 10, time: 132.187s, loss: 0.336, train accuracy: 0.867\n",
      "epoch: 10, time: 132.890s, loss: 0.267, train accuracy: 0.945\n",
      "epoch: 10, time: 133.567s, loss: 0.371, train accuracy: 0.875\n",
      "epoch: 11, time: 133.933s, loss: 0.319, train accuracy: 0.891\n",
      "epoch: 11, time: 134.623s, loss: 0.175, train accuracy: 0.945\n",
      "epoch: 11, time: 135.304s, loss: 0.199, train accuracy: 0.922\n",
      "epoch: 11, time: 136.017s, loss: 0.434, train accuracy: 0.828\n",
      "epoch: 11, time: 136.727s, loss: 0.196, train accuracy: 0.938\n",
      "epoch: 11, time: 137.409s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 11, time: 138.096s, loss: 0.474, train accuracy: 0.836\n",
      "epoch: 11, time: 138.786s, loss: 0.227, train accuracy: 0.914\n",
      "epoch: 11, time: 139.494s, loss: 0.277, train accuracy: 0.891\n",
      "epoch: 11, time: 140.179s, loss: 0.196, train accuracy: 0.945\n",
      "epoch: 11, time: 140.851s, loss: 0.273, train accuracy: 0.883\n",
      "epoch: 11, time: 141.521s, loss: 2.303, train accuracy: 0.117\n",
      "epoch: 11, time: 142.217s, loss: 0.479, train accuracy: 0.820\n",
      "epoch: 11, time: 142.890s, loss: 0.378, train accuracy: 0.852\n",
      "epoch: 11, time: 143.551s, loss: 0.276, train accuracy: 0.891\n",
      "epoch: 11, time: 144.217s, loss: 0.319, train accuracy: 0.891\n",
      "epoch: 11, time: 144.888s, loss: 0.306, train accuracy: 0.906\n",
      "epoch: 11, time: 145.559s, loss: 0.242, train accuracy: 0.914\n",
      "epoch: 11, time: 146.226s, loss: 0.329, train accuracy: 0.906\n",
      "epoch: 11, time: 146.905s, loss: 0.292, train accuracy: 0.891\n",
      "epoch: 12, time: 147.269s, loss: 0.307, train accuracy: 0.875\n",
      "epoch: 12, time: 147.983s, loss: 0.211, train accuracy: 0.922\n",
      "epoch: 12, time: 148.651s, loss: 0.173, train accuracy: 0.930\n",
      "epoch: 12, time: 149.345s, loss: 0.169, train accuracy: 0.922\n",
      "epoch: 12, time: 150.020s, loss: 0.171, train accuracy: 0.930\n",
      "epoch: 12, time: 150.685s, loss: 0.180, train accuracy: 0.945\n",
      "epoch: 12, time: 151.353s, loss: 0.157, train accuracy: 0.945\n",
      "epoch: 12, time: 152.035s, loss: 0.172, train accuracy: 0.930\n",
      "epoch: 12, time: 152.724s, loss: 0.223, train accuracy: 0.922\n",
      "epoch: 12, time: 153.376s, loss: 0.191, train accuracy: 0.930\n",
      "epoch: 12, time: 154.038s, loss: 0.191, train accuracy: 0.922\n",
      "epoch: 12, time: 154.693s, loss: 0.140, train accuracy: 0.953\n",
      "epoch: 12, time: 155.346s, loss: 0.284, train accuracy: 0.883\n",
      "epoch: 12, time: 156.009s, loss: 0.366, train accuracy: 0.883\n",
      "epoch: 12, time: 156.662s, loss: 0.200, train accuracy: 0.914\n",
      "epoch: 12, time: 157.322s, loss: 0.123, train accuracy: 0.961\n",
      "epoch: 12, time: 157.979s, loss: 0.207, train accuracy: 0.938\n",
      "epoch: 12, time: 158.642s, loss: 0.194, train accuracy: 0.930\n",
      "epoch: 12, time: 159.303s, loss: 0.327, train accuracy: 0.875\n",
      "epoch: 12, time: 159.961s, loss: 0.324, train accuracy: 0.898\n",
      "epoch: 13, time: 160.323s, loss: 0.168, train accuracy: 0.945\n",
      "epoch: 13, time: 160.988s, loss: 0.090, train accuracy: 0.969\n",
      "epoch: 13, time: 161.660s, loss: 0.093, train accuracy: 0.977\n",
      "epoch: 13, time: 162.321s, loss: 0.140, train accuracy: 0.945\n",
      "epoch: 13, time: 162.982s, loss: 0.150, train accuracy: 0.969\n",
      "epoch: 13, time: 163.646s, loss: 0.089, train accuracy: 0.984\n",
      "epoch: 13, time: 164.316s, loss: 0.067, train accuracy: 0.992\n",
      "epoch: 13, time: 164.975s, loss: 0.388, train accuracy: 0.883\n",
      "epoch: 13, time: 165.671s, loss: 0.248, train accuracy: 0.906\n",
      "epoch: 13, time: 166.341s, loss: 0.215, train accuracy: 0.945\n",
      "epoch: 13, time: 167.008s, loss: 0.117, train accuracy: 0.969\n",
      "epoch: 13, time: 167.672s, loss: 0.137, train accuracy: 0.969\n",
      "epoch: 13, time: 168.327s, loss: 1.414, train accuracy: 0.531\n",
      "epoch: 13, time: 168.989s, loss: 0.130, train accuracy: 0.961\n",
      "epoch: 13, time: 169.654s, loss: 0.249, train accuracy: 0.898\n",
      "epoch: 13, time: 170.319s, loss: 0.198, train accuracy: 0.938\n",
      "epoch: 13, time: 170.980s, loss: 0.081, train accuracy: 0.969\n",
      "epoch: 13, time: 171.637s, loss: 0.164, train accuracy: 0.930\n",
      "epoch: 13, time: 172.299s, loss: 0.137, train accuracy: 0.961\n",
      "epoch: 13, time: 172.955s, loss: 0.166, train accuracy: 0.945\n",
      "epoch: 14, time: 173.316s, loss: 0.186, train accuracy: 0.953\n",
      "epoch: 14, time: 173.982s, loss: 0.067, train accuracy: 0.969\n",
      "epoch: 14, time: 174.645s, loss: 0.065, train accuracy: 0.984\n",
      "epoch: 14, time: 175.304s, loss: 0.127, train accuracy: 0.961\n",
      "epoch: 14, time: 175.966s, loss: 0.099, train accuracy: 0.969\n",
      "epoch: 14, time: 176.631s, loss: 0.121, train accuracy: 0.938\n",
      "epoch: 14, time: 177.290s, loss: 0.114, train accuracy: 0.977\n",
      "epoch: 14, time: 177.959s, loss: 0.076, train accuracy: 0.961\n",
      "epoch: 14, time: 178.622s, loss: 0.062, train accuracy: 0.969\n",
      "epoch: 14, time: 179.285s, loss: 0.079, train accuracy: 0.961\n",
      "epoch: 14, time: 179.948s, loss: 0.096, train accuracy: 0.984\n",
      "epoch: 14, time: 180.639s, loss: 0.038, train accuracy: 0.992\n",
      "epoch: 14, time: 181.312s, loss: 0.137, train accuracy: 0.938\n",
      "epoch: 14, time: 181.981s, loss: 0.199, train accuracy: 0.938\n",
      "epoch: 14, time: 182.649s, loss: 0.320, train accuracy: 0.906\n",
      "epoch: 14, time: 183.308s, loss: 0.104, train accuracy: 0.953\n",
      "epoch: 14, time: 183.969s, loss: 0.121, train accuracy: 0.969\n",
      "epoch: 14, time: 184.629s, loss: 0.111, train accuracy: 0.969\n",
      "epoch: 14, time: 185.286s, loss: 0.102, train accuracy: 0.953\n",
      "epoch: 14, time: 185.958s, loss: 0.067, train accuracy: 0.984\n",
      "epoch: 15, time: 186.313s, loss: 0.196, train accuracy: 0.953\n",
      "epoch: 15, time: 186.979s, loss: 0.036, train accuracy: 0.992\n",
      "epoch: 15, time: 187.639s, loss: 0.063, train accuracy: 0.984\n",
      "epoch: 15, time: 188.299s, loss: 0.074, train accuracy: 0.969\n",
      "epoch: 15, time: 188.955s, loss: 0.049, train accuracy: 0.984\n",
      "epoch: 15, time: 189.617s, loss: 0.066, train accuracy: 0.961\n",
      "epoch: 15, time: 190.288s, loss: 0.066, train accuracy: 0.969\n",
      "epoch: 15, time: 190.955s, loss: 0.102, train accuracy: 0.977\n",
      "epoch: 15, time: 191.639s, loss: 0.106, train accuracy: 0.969\n",
      "epoch: 15, time: 192.320s, loss: 0.245, train accuracy: 0.945\n",
      "epoch: 15, time: 193.004s, loss: 0.261, train accuracy: 0.945\n",
      "epoch: 15, time: 193.673s, loss: 0.023, train accuracy: 0.992\n",
      "epoch: 15, time: 194.336s, loss: 0.141, train accuracy: 0.961\n",
      "epoch: 15, time: 194.999s, loss: 0.264, train accuracy: 0.922\n",
      "epoch: 15, time: 195.668s, loss: 0.107, train accuracy: 0.953\n",
      "epoch: 15, time: 196.346s, loss: 0.054, train accuracy: 0.992\n",
      "epoch: 15, time: 197.048s, loss: 0.062, train accuracy: 0.961\n",
      "epoch: 15, time: 197.733s, loss: 0.237, train accuracy: 0.906\n",
      "epoch: 15, time: 198.425s, loss: 0.091, train accuracy: 0.977\n",
      "epoch: 15, time: 199.104s, loss: 0.126, train accuracy: 0.961\n",
      "epoch: 16, time: 199.476s, loss: 0.087, train accuracy: 0.969\n",
      "epoch: 16, time: 200.165s, loss: 0.049, train accuracy: 0.969\n",
      "epoch: 16, time: 200.854s, loss: 0.086, train accuracy: 0.977\n",
      "epoch: 16, time: 201.539s, loss: 0.046, train accuracy: 0.984\n",
      "epoch: 16, time: 202.235s, loss: 0.112, train accuracy: 0.953\n",
      "epoch: 16, time: 202.928s, loss: 0.020, train accuracy: 1.000\n",
      "epoch: 16, time: 203.598s, loss: 0.016, train accuracy: 1.000\n",
      "epoch: 16, time: 204.268s, loss: 0.127, train accuracy: 0.961\n",
      "epoch: 16, time: 204.927s, loss: 0.131, train accuracy: 0.969\n",
      "epoch: 16, time: 205.594s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 16, time: 206.269s, loss: 0.049, train accuracy: 0.992\n",
      "epoch: 16, time: 206.934s, loss: 0.104, train accuracy: 0.961\n",
      "epoch: 16, time: 207.605s, loss: 0.060, train accuracy: 0.969\n",
      "epoch: 16, time: 208.266s, loss: 0.038, train accuracy: 0.992\n",
      "epoch: 16, time: 208.933s, loss: 0.099, train accuracy: 0.961\n",
      "epoch: 16, time: 209.592s, loss: 0.059, train accuracy: 0.977\n",
      "epoch: 16, time: 210.270s, loss: 0.050, train accuracy: 0.984\n",
      "epoch: 16, time: 210.954s, loss: 0.066, train accuracy: 0.969\n",
      "epoch: 16, time: 211.631s, loss: 0.112, train accuracy: 0.961\n",
      "epoch: 16, time: 212.301s, loss: 0.037, train accuracy: 0.992\n",
      "epoch: 17, time: 212.673s, loss: 0.059, train accuracy: 0.984\n",
      "epoch: 17, time: 213.363s, loss: 0.111, train accuracy: 0.969\n",
      "epoch: 17, time: 214.045s, loss: 0.049, train accuracy: 0.984\n",
      "epoch: 17, time: 214.722s, loss: 0.111, train accuracy: 0.953\n",
      "epoch: 17, time: 215.408s, loss: 0.037, train accuracy: 0.992\n",
      "epoch: 17, time: 216.092s, loss: 0.063, train accuracy: 0.977\n",
      "epoch: 17, time: 216.777s, loss: 0.046, train accuracy: 0.992\n",
      "epoch: 17, time: 217.458s, loss: 0.086, train accuracy: 0.969\n",
      "epoch: 17, time: 218.174s, loss: 0.075, train accuracy: 0.977\n",
      "epoch: 17, time: 218.890s, loss: 0.131, train accuracy: 0.969\n",
      "epoch: 17, time: 219.560s, loss: 0.165, train accuracy: 0.953\n",
      "epoch: 17, time: 220.231s, loss: 0.040, train accuracy: 0.977\n",
      "epoch: 17, time: 220.908s, loss: 0.062, train accuracy: 0.984\n",
      "epoch: 17, time: 221.572s, loss: 0.027, train accuracy: 0.992\n",
      "epoch: 17, time: 222.237s, loss: 0.066, train accuracy: 0.969\n",
      "epoch: 17, time: 222.899s, loss: 0.047, train accuracy: 0.977\n",
      "epoch: 17, time: 223.563s, loss: 0.035, train accuracy: 1.000\n",
      "epoch: 17, time: 224.226s, loss: 0.064, train accuracy: 0.984\n",
      "epoch: 17, time: 224.890s, loss: 0.040, train accuracy: 0.984\n",
      "epoch: 17, time: 225.549s, loss: 0.104, train accuracy: 0.961\n",
      "epoch: 18, time: 225.914s, loss: 0.047, train accuracy: 0.977\n",
      "epoch: 18, time: 226.582s, loss: 0.017, train accuracy: 1.000\n",
      "epoch: 18, time: 227.249s, loss: 0.020, train accuracy: 0.992\n",
      "epoch: 18, time: 227.915s, loss: 0.006, train accuracy: 1.000\n",
      "epoch: 18, time: 228.580s, loss: 0.071, train accuracy: 0.977\n",
      "epoch: 18, time: 229.247s, loss: 0.034, train accuracy: 0.992\n",
      "epoch: 18, time: 229.913s, loss: 0.088, train accuracy: 0.969\n",
      "epoch: 18, time: 230.582s, loss: 0.033, train accuracy: 0.992\n",
      "epoch: 18, time: 231.249s, loss: 0.153, train accuracy: 0.953\n",
      "epoch: 18, time: 231.916s, loss: 0.058, train accuracy: 0.992\n",
      "epoch: 18, time: 232.585s, loss: 0.048, train accuracy: 0.977\n",
      "epoch: 18, time: 233.254s, loss: 0.028, train accuracy: 0.992\n",
      "epoch: 18, time: 233.921s, loss: 0.072, train accuracy: 0.984\n",
      "epoch: 18, time: 234.586s, loss: 0.025, train accuracy: 0.992\n",
      "epoch: 18, time: 235.256s, loss: 0.068, train accuracy: 0.977\n",
      "epoch: 18, time: 235.927s, loss: 0.115, train accuracy: 0.961\n",
      "epoch: 18, time: 236.594s, loss: 0.038, train accuracy: 0.984\n",
      "epoch: 18, time: 237.263s, loss: 0.101, train accuracy: 0.977\n",
      "epoch: 18, time: 237.929s, loss: 0.063, train accuracy: 0.953\n",
      "epoch: 18, time: 238.596s, loss: 0.041, train accuracy: 0.984\n",
      "epoch: 19, time: 238.957s, loss: 0.060, train accuracy: 0.984\n",
      "epoch: 19, time: 239.636s, loss: 0.029, train accuracy: 0.984\n",
      "epoch: 19, time: 240.301s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 19, time: 240.964s, loss: 0.026, train accuracy: 0.992\n",
      "epoch: 19, time: 241.627s, loss: 0.026, train accuracy: 0.992\n",
      "epoch: 19, time: 242.284s, loss: 0.015, train accuracy: 0.992\n",
      "epoch: 19, time: 242.941s, loss: 0.062, train accuracy: 0.977\n",
      "epoch: 19, time: 243.601s, loss: 0.037, train accuracy: 0.984\n",
      "epoch: 19, time: 244.266s, loss: 0.021, train accuracy: 0.992\n",
      "epoch: 19, time: 244.934s, loss: 0.047, train accuracy: 0.984\n",
      "epoch: 19, time: 245.599s, loss: 0.036, train accuracy: 0.984\n",
      "epoch: 19, time: 246.264s, loss: 0.152, train accuracy: 0.953\n",
      "epoch: 19, time: 246.923s, loss: 0.114, train accuracy: 0.969\n",
      "epoch: 19, time: 247.586s, loss: 0.059, train accuracy: 0.984\n",
      "epoch: 19, time: 248.246s, loss: 0.068, train accuracy: 0.969\n",
      "epoch: 19, time: 248.909s, loss: 0.039, train accuracy: 0.984\n",
      "epoch: 19, time: 249.573s, loss: 0.103, train accuracy: 0.984\n",
      "epoch: 19, time: 250.234s, loss: 0.136, train accuracy: 0.961\n",
      "epoch: 19, time: 250.894s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 19, time: 251.554s, loss: 0.019, train accuracy: 0.992\n",
      "epoch: 20, time: 251.913s, loss: 0.073, train accuracy: 0.977\n",
      "epoch: 20, time: 252.579s, loss: 0.014, train accuracy: 1.000\n",
      "epoch: 20, time: 253.241s, loss: 0.031, train accuracy: 0.992\n",
      "epoch: 20, time: 253.898s, loss: 0.134, train accuracy: 0.953\n",
      "epoch: 20, time: 254.558s, loss: 0.052, train accuracy: 0.977\n",
      "epoch: 20, time: 255.224s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 20, time: 255.892s, loss: 0.055, train accuracy: 0.977\n",
      "epoch: 20, time: 256.555s, loss: 0.023, train accuracy: 0.992\n",
      "epoch: 20, time: 257.225s, loss: 0.080, train accuracy: 0.992\n",
      "epoch: 20, time: 257.891s, loss: 0.023, train accuracy: 0.992\n",
      "epoch: 20, time: 258.549s, loss: 0.035, train accuracy: 0.992\n",
      "epoch: 20, time: 259.209s, loss: 0.098, train accuracy: 0.969\n",
      "epoch: 20, time: 259.871s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 20, time: 260.537s, loss: 0.010, train accuracy: 1.000\n",
      "epoch: 20, time: 261.206s, loss: 0.022, train accuracy: 1.000\n",
      "epoch: 20, time: 261.873s, loss: 0.103, train accuracy: 0.969\n",
      "epoch: 20, time: 262.539s, loss: 0.081, train accuracy: 0.977\n",
      "epoch: 20, time: 263.209s, loss: 0.067, train accuracy: 0.984\n",
      "epoch: 20, time: 263.877s, loss: 0.112, train accuracy: 0.961\n",
      "epoch: 20, time: 264.544s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 21, time: 264.904s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 21, time: 265.575s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 21, time: 266.243s, loss: 0.073, train accuracy: 0.969\n",
      "epoch: 21, time: 266.908s, loss: 0.035, train accuracy: 0.992\n",
      "epoch: 21, time: 267.579s, loss: 0.135, train accuracy: 0.961\n",
      "epoch: 21, time: 268.245s, loss: 0.014, train accuracy: 1.000\n",
      "epoch: 21, time: 268.910s, loss: 0.012, train accuracy: 1.000\n",
      "epoch: 21, time: 269.572s, loss: 0.027, train accuracy: 0.992\n",
      "epoch: 21, time: 270.238s, loss: 0.048, train accuracy: 0.984\n",
      "epoch: 21, time: 270.903s, loss: 0.026, train accuracy: 0.992\n",
      "epoch: 21, time: 271.579s, loss: 0.022, train accuracy: 0.984\n",
      "epoch: 21, time: 272.244s, loss: 0.091, train accuracy: 0.977\n",
      "epoch: 21, time: 272.908s, loss: 0.031, train accuracy: 0.992\n",
      "epoch: 21, time: 273.575s, loss: 0.016, train accuracy: 0.992\n",
      "epoch: 21, time: 274.242s, loss: 0.108, train accuracy: 0.977\n",
      "epoch: 21, time: 274.905s, loss: 0.043, train accuracy: 0.969\n",
      "epoch: 21, time: 275.572s, loss: 0.036, train accuracy: 0.992\n",
      "epoch: 21, time: 276.238s, loss: 0.021, train accuracy: 0.984\n",
      "epoch: 21, time: 276.904s, loss: 0.035, train accuracy: 0.977\n",
      "epoch: 21, time: 277.569s, loss: 0.022, train accuracy: 0.992\n",
      "epoch: 22, time: 277.926s, loss: 0.527, train accuracy: 0.898\n",
      "epoch: 22, time: 278.599s, loss: 0.041, train accuracy: 0.992\n",
      "epoch: 22, time: 279.264s, loss: 0.036, train accuracy: 0.992\n",
      "epoch: 22, time: 279.930s, loss: 0.025, train accuracy: 1.000\n",
      "epoch: 22, time: 280.596s, loss: 0.026, train accuracy: 1.000\n",
      "epoch: 22, time: 281.262s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 22, time: 281.931s, loss: 0.025, train accuracy: 0.992\n",
      "epoch: 22, time: 282.600s, loss: 0.040, train accuracy: 0.984\n",
      "epoch: 22, time: 283.271s, loss: 0.027, train accuracy: 0.992\n",
      "epoch: 22, time: 283.937s, loss: 0.017, train accuracy: 0.984\n",
      "epoch: 22, time: 284.603s, loss: 0.068, train accuracy: 0.984\n",
      "epoch: 22, time: 285.269s, loss: 0.022, train accuracy: 0.984\n",
      "epoch: 22, time: 285.931s, loss: 0.012, train accuracy: 1.000\n",
      "epoch: 22, time: 286.593s, loss: 0.029, train accuracy: 0.992\n",
      "epoch: 22, time: 287.256s, loss: 0.082, train accuracy: 0.977\n",
      "epoch: 22, time: 287.919s, loss: 0.013, train accuracy: 0.992\n",
      "epoch: 22, time: 288.585s, loss: 0.019, train accuracy: 0.992\n",
      "epoch: 22, time: 289.252s, loss: 0.027, train accuracy: 0.992\n",
      "epoch: 22, time: 289.917s, loss: 0.060, train accuracy: 0.984\n",
      "epoch: 22, time: 290.585s, loss: 0.014, train accuracy: 1.000\n",
      "epoch: 23, time: 290.946s, loss: 0.020, train accuracy: 0.992\n",
      "epoch: 23, time: 291.625s, loss: 0.017, train accuracy: 1.000\n",
      "epoch: 23, time: 292.291s, loss: 0.033, train accuracy: 0.977\n",
      "epoch: 23, time: 292.955s, loss: 0.034, train accuracy: 0.984\n",
      "epoch: 23, time: 293.621s, loss: 0.035, train accuracy: 0.977\n",
      "epoch: 23, time: 294.285s, loss: 0.041, train accuracy: 0.977\n",
      "epoch: 23, time: 294.948s, loss: 0.026, train accuracy: 0.984\n",
      "epoch: 23, time: 295.607s, loss: 0.057, train accuracy: 0.984\n",
      "epoch: 23, time: 296.272s, loss: 0.076, train accuracy: 0.984\n",
      "epoch: 23, time: 296.936s, loss: 0.065, train accuracy: 0.984\n",
      "epoch: 23, time: 297.604s, loss: 0.026, train accuracy: 0.992\n",
      "epoch: 23, time: 298.289s, loss: 0.047, train accuracy: 0.984\n",
      "epoch: 23, time: 298.965s, loss: 0.033, train accuracy: 0.977\n",
      "epoch: 23, time: 299.639s, loss: 0.083, train accuracy: 0.977\n",
      "epoch: 23, time: 300.318s, loss: 0.018, train accuracy: 1.000\n",
      "epoch: 23, time: 300.980s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 23, time: 301.642s, loss: 0.040, train accuracy: 0.977\n",
      "epoch: 23, time: 302.310s, loss: 0.055, train accuracy: 0.992\n",
      "epoch: 23, time: 302.975s, loss: 0.040, train accuracy: 0.984\n",
      "epoch: 23, time: 303.636s, loss: 0.050, train accuracy: 0.977\n",
      "epoch: 24, time: 303.994s, loss: 0.005, train accuracy: 1.000\n",
      "epoch: 24, time: 304.663s, loss: 0.016, train accuracy: 0.992\n",
      "epoch: 24, time: 305.319s, loss: 0.001, train accuracy: 1.000\n",
      "epoch: 24, time: 305.978s, loss: 0.025, train accuracy: 0.984\n",
      "epoch: 24, time: 306.630s, loss: 0.071, train accuracy: 0.984\n",
      "epoch: 24, time: 307.287s, loss: 0.092, train accuracy: 0.977\n",
      "epoch: 24, time: 307.968s, loss: 0.064, train accuracy: 0.984\n",
      "epoch: 24, time: 308.639s, loss: 0.041, train accuracy: 0.984\n",
      "epoch: 24, time: 309.305s, loss: 0.084, train accuracy: 0.977\n",
      "epoch: 24, time: 309.991s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 24, time: 310.666s, loss: 0.030, train accuracy: 0.992\n",
      "epoch: 24, time: 311.340s, loss: 0.012, train accuracy: 1.000\n",
      "epoch: 24, time: 312.015s, loss: 0.019, train accuracy: 0.992\n",
      "epoch: 24, time: 312.679s, loss: 0.011, train accuracy: 1.000\n",
      "epoch: 24, time: 313.343s, loss: 0.030, train accuracy: 0.984\n",
      "epoch: 24, time: 314.016s, loss: 0.069, train accuracy: 0.969\n",
      "epoch: 24, time: 314.684s, loss: 0.017, train accuracy: 0.992\n",
      "epoch: 24, time: 315.354s, loss: 0.086, train accuracy: 0.984\n",
      "epoch: 24, time: 316.022s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 24, time: 316.692s, loss: 0.039, train accuracy: 0.977\n",
      "epoch: 25, time: 317.052s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 25, time: 317.728s, loss: 0.010, train accuracy: 0.992\n",
      "epoch: 25, time: 318.394s, loss: 0.021, train accuracy: 0.984\n",
      "epoch: 25, time: 319.090s, loss: 0.046, train accuracy: 0.992\n",
      "epoch: 25, time: 319.782s, loss: 0.064, train accuracy: 0.992\n",
      "epoch: 25, time: 320.465s, loss: 0.011, train accuracy: 1.000\n",
      "epoch: 25, time: 321.133s, loss: 0.020, train accuracy: 0.992\n",
      "epoch: 25, time: 321.798s, loss: 0.030, train accuracy: 0.992\n",
      "epoch: 25, time: 322.462s, loss: 0.000, train accuracy: 1.000\n",
      "epoch: 25, time: 323.136s, loss: 0.061, train accuracy: 0.969\n",
      "epoch: 25, time: 323.806s, loss: 0.007, train accuracy: 1.000\n",
      "epoch: 25, time: 324.480s, loss: 0.014, train accuracy: 1.000\n",
      "epoch: 25, time: 325.145s, loss: 0.037, train accuracy: 0.992\n",
      "epoch: 25, time: 325.810s, loss: 0.010, train accuracy: 0.992\n",
      "epoch: 25, time: 326.476s, loss: 0.031, train accuracy: 0.984\n",
      "epoch: 25, time: 327.145s, loss: 0.087, train accuracy: 0.969\n",
      "epoch: 25, time: 327.819s, loss: 0.018, train accuracy: 0.992\n",
      "epoch: 25, time: 328.482s, loss: 0.059, train accuracy: 0.984\n",
      "epoch: 25, time: 329.153s, loss: 0.062, train accuracy: 0.977\n",
      "epoch: 25, time: 329.825s, loss: 0.133, train accuracy: 0.961\n",
      "epoch: 26, time: 330.217s, loss: 0.043, train accuracy: 0.977\n",
      "epoch: 26, time: 330.885s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 26, time: 331.550s, loss: 0.019, train accuracy: 0.992\n",
      "epoch: 26, time: 332.217s, loss: 0.016, train accuracy: 0.992\n",
      "epoch: 26, time: 332.881s, loss: 0.071, train accuracy: 0.984\n",
      "epoch: 26, time: 333.543s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 26, time: 334.205s, loss: 0.020, train accuracy: 0.992\n",
      "epoch: 26, time: 334.864s, loss: 0.014, train accuracy: 0.992\n",
      "epoch: 26, time: 335.524s, loss: 0.012, train accuracy: 0.992\n",
      "epoch: 26, time: 336.188s, loss: 0.019, train accuracy: 0.992\n",
      "epoch: 26, time: 336.848s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 26, time: 337.547s, loss: 0.021, train accuracy: 0.992\n",
      "epoch: 26, time: 338.273s, loss: 0.010, train accuracy: 1.000\n",
      "epoch: 26, time: 339.007s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 26, time: 339.684s, loss: 0.127, train accuracy: 0.969\n",
      "epoch: 26, time: 340.365s, loss: 0.126, train accuracy: 0.969\n",
      "epoch: 26, time: 341.047s, loss: 0.015, train accuracy: 0.992\n",
      "epoch: 26, time: 341.713s, loss: 0.020, train accuracy: 1.000\n",
      "epoch: 26, time: 342.382s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 26, time: 343.048s, loss: 0.024, train accuracy: 0.992\n",
      "epoch: 27, time: 343.408s, loss: 0.025, train accuracy: 0.992\n",
      "epoch: 27, time: 344.082s, loss: 0.017, train accuracy: 0.992\n",
      "epoch: 27, time: 344.765s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 27, time: 345.450s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 27, time: 346.120s, loss: 0.013, train accuracy: 0.992\n",
      "epoch: 27, time: 346.790s, loss: 0.034, train accuracy: 0.992\n",
      "epoch: 27, time: 347.462s, loss: 0.012, train accuracy: 0.992\n",
      "epoch: 27, time: 348.129s, loss: 0.031, train accuracy: 0.992\n",
      "epoch: 27, time: 348.796s, loss: 0.012, train accuracy: 0.992\n",
      "epoch: 27, time: 349.462s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 27, time: 350.130s, loss: 0.016, train accuracy: 0.992\n",
      "epoch: 27, time: 350.799s, loss: 0.011, train accuracy: 0.992\n",
      "epoch: 27, time: 351.468s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 27, time: 352.139s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 27, time: 352.807s, loss: 0.097, train accuracy: 0.961\n",
      "epoch: 27, time: 353.471s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 27, time: 354.140s, loss: 0.010, train accuracy: 1.000\n",
      "epoch: 27, time: 354.810s, loss: 0.015, train accuracy: 0.984\n",
      "epoch: 27, time: 355.477s, loss: 0.033, train accuracy: 0.992\n",
      "epoch: 27, time: 356.145s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 28, time: 356.506s, loss: 0.001, train accuracy: 1.000\n",
      "epoch: 28, time: 357.179s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 28, time: 357.854s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 28, time: 358.548s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 28, time: 359.225s, loss: 0.051, train accuracy: 0.992\n",
      "epoch: 28, time: 359.889s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 28, time: 360.558s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 28, time: 361.227s, loss: 0.008, train accuracy: 0.992\n",
      "epoch: 28, time: 361.895s, loss: 0.005, train accuracy: 1.000\n",
      "epoch: 28, time: 362.559s, loss: 0.005, train accuracy: 1.000\n",
      "epoch: 28, time: 363.231s, loss: 0.025, train accuracy: 0.992\n",
      "epoch: 28, time: 363.897s, loss: 0.045, train accuracy: 0.977\n",
      "epoch: 28, time: 364.566s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 28, time: 365.243s, loss: 0.025, train accuracy: 0.977\n",
      "epoch: 28, time: 365.905s, loss: 0.014, train accuracy: 1.000\n",
      "epoch: 28, time: 366.573s, loss: 0.016, train accuracy: 0.992\n",
      "epoch: 28, time: 367.240s, loss: 0.011, train accuracy: 0.992\n",
      "epoch: 28, time: 367.901s, loss: 0.002, train accuracy: 1.000\n",
      "epoch: 28, time: 368.567s, loss: 0.091, train accuracy: 0.969\n",
      "epoch: 28, time: 369.233s, loss: 0.081, train accuracy: 0.992\n",
      "epoch: 29, time: 369.594s, loss: 0.049, train accuracy: 0.992\n",
      "epoch: 29, time: 370.268s, loss: 0.017, train accuracy: 0.992\n",
      "epoch: 29, time: 370.933s, loss: 0.026, train accuracy: 0.984\n",
      "epoch: 29, time: 371.589s, loss: 0.055, train accuracy: 0.977\n",
      "epoch: 29, time: 372.249s, loss: 0.031, train accuracy: 0.984\n",
      "epoch: 29, time: 372.922s, loss: 0.003, train accuracy: 1.000\n",
      "epoch: 29, time: 373.589s, loss: 0.028, train accuracy: 0.992\n",
      "epoch: 29, time: 374.264s, loss: 0.044, train accuracy: 0.984\n",
      "epoch: 29, time: 374.930s, loss: 0.004, train accuracy: 1.000\n",
      "epoch: 29, time: 375.589s, loss: 0.009, train accuracy: 1.000\n",
      "epoch: 29, time: 376.251s, loss: 0.010, train accuracy: 0.992\n",
      "epoch: 29, time: 376.914s, loss: 0.042, train accuracy: 0.984\n",
      "epoch: 29, time: 377.585s, loss: 0.023, train accuracy: 0.992\n",
      "epoch: 29, time: 378.241s, loss: 0.017, train accuracy: 0.992\n",
      "epoch: 29, time: 378.896s, loss: 0.049, train accuracy: 0.977\n",
      "epoch: 29, time: 379.556s, loss: 0.020, train accuracy: 0.992\n",
      "epoch: 29, time: 380.223s, loss: 0.080, train accuracy: 0.969\n",
      "epoch: 29, time: 380.874s, loss: 0.110, train accuracy: 0.992\n",
      "epoch: 29, time: 381.544s, loss: 0.008, train accuracy: 1.000\n",
      "epoch: 29, time: 382.207s, loss: 0.065, train accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "optimizer=torch.optim.SGD(net.parameters(), lr=my_lr)\n",
    "\n",
    "for epoch in range(1,30):\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(trainloader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "        optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
    "\n",
    "        y_pred = net(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute relevant metrics\n",
    "\n",
    "        y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "        correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
    "\n",
    "        elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "        # Show progress every 20 batches \n",
    "        if not i % 20:\n",
    "            print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Uc1816EHVQY"
   },
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hItOOXuwCD0w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.781\n"
     ]
    }
   ],
   "source": [
    "correct_total = 0\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(testloader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
    "\n",
    "    y_pred = net(x_batch)\n",
    "    y_pred_max = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
    "\n",
    "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woDv4gpdY85_"
   },
   "source": [
    "### Define a function to show an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6h5iFcBkC3ui"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n",
    "                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "# Function to show an image tensor\n",
    "def show(X):\n",
    "    X = inverse_transform(X)\n",
    "\n",
    "    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61nCgln8HZaN"
   },
   "source": [
    "### Show the model's prediction for a random sample from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2grnY_u2-O2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence scores:\n",
      "plane: 0.002573496662080288\n",
      "car: 8.215323032345623e-05\n",
      "bird: 6.492046900063997e-09\n",
      "cat: 1.7911591498886992e-07\n",
      "deer: 7.812821500863265e-09\n",
      "dog: 1.1750080908257132e-09\n",
      "frog: 3.71310989066842e-07\n",
      "horse: 8.212850399758054e-10\n",
      "ship: 0.9973141551017761\n",
      "truck: 2.962857615784742e-05\n",
      "\n",
      "Label with highest confidence score: ship\n",
      "\n",
      "True label: plane\n"
     ]
    }
   ],
   "source": [
    "# choose a picture at random\n",
    "im_minibatch, label_minibatch = next(iter(testloader))\n",
    "im, label = im_minibatch[0].cpu(), label_minibatch[0].cpu()\n",
    "\n",
    "# diplay the picture\n",
    "show(im)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "prob = F.softmax(net.cpu()(im.unsqueeze(0)), dim=1)\n",
    "\n",
    "print('Confidence scores:\\n' + '\\n'.join(['{}: {}'.format(classes[i], p.item()) for i, p in enumerate(prob.squeeze())]))\n",
    "\n",
    "print('\\nLabel with highest confidence score: {}'.format(classes[torch.argmax(prob).item()]))\n",
    "print('\\nTrue label: {}'.format(classes[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vgg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_course-env",
   "language": "python",
   "name": "dl_course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
