{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9C20DXlMOAi9"
   },
   "source": [
    "# Classifying names with a character-level RNN\n",
    "In this notebook we will use a recurrent neural network to predict the language from which certain surnames originate. When given some surname the network outputs a probability distribution over 18 possible languages corresponding to the likelyhood that they originate from these languages. \n",
    "\n",
    "This exercise was taken from the [PyTorch website](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4t1dQLLZDKc"
   },
   "source": [
    "### Download the dataset\n",
    "The dataset that is used can be downloaded [here](https://download.pytorch.org/tutorial/data.zip). Extract it to the directory where this notebook is located.\n",
    "Included in the ``data/names`` directory are 18 text files named as\n",
    "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
    "line, mostly romanized (but we still need to convert from Unicode to\n",
    "ASCII)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNu_cHzjcUk8"
   },
   "source": [
    "If you are running this notebook on Colab you can access the dataset by storing it on your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1575820225896,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "eo3dBmNZcQZr",
    "outputId": "48ff91d2-0f98-4d5c-cb5b-42351ca45c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPJHoYlkdot3"
   },
   "source": [
    "**Change the following path variable such that it points to the location of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1575820229986,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "GdI9hWoEd6xi",
    "outputId": "2e8b7bc3-8211-4eec-ab71-5344ec20c748"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic.txt',\n",
       " 'Chinese.txt',\n",
       " 'Czech.txt',\n",
       " 'Dutch.txt',\n",
       " 'English.txt',\n",
       " 'French.txt',\n",
       " 'German.txt',\n",
       " 'Greek.txt',\n",
       " 'Irish.txt',\n",
       " 'Italian.txt',\n",
       " 'Japanese.txt',\n",
       " 'Korean.txt',\n",
       " 'Polish.txt',\n",
       " 'Portuguese.txt',\n",
       " 'Russian.txt',\n",
       " 'Scottish.txt',\n",
       " 'Spanish.txt',\n",
       " 'Vietnamese.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_to_data = './'  # TODO -- set this to the right location!\n",
    "\n",
    "os.listdir('./data/names/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTyw5SkeXVxu"
   },
   "source": [
    "### Preparing the data\n",
    "We first preprocess the dataset by limiting ourselves to ASCII characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1575820233114,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "6Ztn7HClez8U",
    "outputId": "9e14ea05-37da-4765-f6c0-029cb5f7bf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8daKzr0eg7LT"
   },
   "outputs": [],
   "source": [
    "# Build a dictionary containing a list of names for each language\n",
    "names_per_language = dict()\n",
    "languages = list()  # Keep a list containing all languages\n",
    "\n",
    "def readNames(file_path):  # Define a function that reads all names from some file in /data/names/ and converts them to ASCII\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        unicode_names = f.read().strip().split('\\n')  # Split the file on new lines. Each line contains a name (in unicode)\n",
    "        return [unicodeToAscii(name) for name in unicode_names]  # Convert all names to ASCII\n",
    "\n",
    "# For all files in /data/names/ read the names. Group the names by the language they are in\n",
    "\n",
    "for filename in os.listdir(path_to_data + 'data/names/'):\n",
    "    language, _ = filename.split('.')  # Remove the file extention to obtain the class label (the language)\n",
    "    languages.append(language)\n",
    "    names = readNames(path_to_data + 'data/names/' + filename)  # Read the names in the current file\n",
    "    names_per_language[language] = names\n",
    "\n",
    "n_languages = len(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYL9BPerj2BB"
   },
   "source": [
    "Now we have ``names_per_language``, a dictionary mapping each language to a list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1575820241407,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "QHOPEma4j2Jj",
    "outputId": "b316449e-f1b7-4ad9-afa2-2e898a12b6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbing', 'Abel', 'Abeln', 'Abt', 'Achilles']\n"
     ]
    }
   ],
   "source": [
    "print(names_per_language['German'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrO3p0ciXdDh"
   },
   "source": [
    "### Exercise - Transforming names into suitable inputs\n",
    "\n",
    "Now that we have all the names organized, we need to turn them into\n",
    "Tensors to make any use of them.\n",
    "\n",
    "To represent a single letter, we use a \"one-hot vector\" of size\n",
    "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
    "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix\n",
    "``<line_length x 1 x n_letters>``.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in\n",
    "batches - we're just using a batch size of 1 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1575820245027,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "Z8e9Kdxpl6sS",
    "outputId": "dc9af26c-20c0-4659-97a2-7d178f515d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3PZ8LZlXiur"
   },
   "source": [
    "### Exercise - Define a RNN architecture\n",
    "\n",
    "Create a neural network that takes as input some encoding of a character as well as a hidden state tensor. These two tensors are concatenated and passed to the following:\n",
    "* a linear layer that produces the next hidden state tensor (no activation function)\n",
    "* a linear layer that produces an output tensor (no activation function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02jJFESsnA3W"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size+hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWuIJQnJ9NRn"
   },
   "source": [
    "To run a step of this network we need to pass an input (in our case, the\n",
    "Tensor for the current letter) and a previous hidden state (which we\n",
    "initialize as zeros at first). We'll get back the output and a next hidden state (which we keep for the next\n",
    "step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1575820272527,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "jts3zvXo7mSD",
    "outputId": "ded21516-e4da-4c6a-e6a1-5c63ff1c9c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 57])\n",
      "torch.Size([1, 57])\n",
      "torch.Size([1, 128])\n",
      "tensor([[0.0568, 0.0599, 0.0582, 0.0555, 0.0570, 0.0572, 0.0582, 0.0516, 0.0554,\n",
      "         0.0555, 0.0502, 0.0498, 0.0588, 0.0563, 0.0564, 0.0544, 0.0575, 0.0513]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)  # Initialize the hidden state as zeros\n",
    "\n",
    "print(input_tensor.shape)  # The name contains 6 characters which are all encoded as 1-hot vectors of length 57 (corresponding to all possible input characters)\n",
    "print(input_tensor[0].shape)  # Show the shape of a single character. The 1 is the batch dimension. In this example we set the batch size to 1 for simplicity\n",
    "print(hidden.shape)  # Show the shape of the hidden state vector\n",
    "\n",
    "output, next_hidden = rnn(input_tensor[0], hidden)  # Pass the first letter in the name to the network, as well as the initial hidden state\n",
    "\n",
    "print(F.softmax(output, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhR9-5IKXoj2"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pDvQVMhANx2"
   },
   "source": [
    "First we will define a function to sample random data points from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1575820277354,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     },
     "user_tz": -60
    },
    "id": "cMF_KUeH_nNt",
    "outputId": "fc45fd72-81d3-4b9d-9f0a-f87df527266b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0, Name: Romero, Language: Spanish\n",
      "Example 1, Name: Nunes, Language: Portuguese\n",
      "Example 2, Name: Adam, Language: German\n",
      "Example 3, Name: Aitken, Language: Scottish\n",
      "Example 4, Name: Nikolaou, Language: Greek\n",
      "Example 5, Name: Nassar, Language: Arabic\n",
      "Example 6, Name: Vasyatkin, Language: Russian\n",
      "Example 7, Name: Pinho, Language: Portuguese\n",
      "Example 8, Name: Chmiel, Language: Polish\n",
      "Example 9, Name: Macha, Language: Czech\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_train_example():\n",
    "    # Select a random name in some random language\n",
    "    language = random.choice(languages)\n",
    "    name = random.choice(names_per_language[language])\n",
    "    # Convert the name to a suitable input tensor\n",
    "    name_tensor = lineToTensor(name)\n",
    "    # Convert the language to a suitable target tensor\n",
    "    lang_tensor = torch.LongTensor([languages.index(language)])  # The tensor datatype is 'long' as it contains an integer corresponding to the index of the language\n",
    "    return language, name, lang_tensor, name_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    language, name, lang_tensor, name_tensor = random_train_example()\n",
    "\n",
    "    print(f'Example {i}, Name: {name}, Language: {language}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzNuGzIVZOZE"
   },
   "source": [
    "Next we define a function that performs stochastic gradient descent using a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNMfSkKMDF2V"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "def train_on_example(name_tensor, language_tensor):\n",
    "    hidden_state = torch.zeros(1, n_hidden)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for character_tensor in name_tensor:  # Perform a forward pass for each character in the name\n",
    "        out, hidden_state = rnn(character_tensor, hidden_state)\n",
    "\n",
    "    loss = criterion(out, language_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return out, loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEb04AhsZgYE"
   },
   "source": [
    "Now iterate through the dataset to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdcLFM-VFJMw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1000, Loss: 2.748 Name: Kaloxylos        Language: Greek            Classified as: Spanish          Incorrect\n",
      "Example 2000, Loss: 2.667 Name: Kosmatka         Language: Polish           Classified as: Czech            Incorrect\n",
      "Example 3000, Loss: 3.070 Name: Ghannam          Language: Arabic           Classified as: English          Incorrect\n",
      "Example 4000, Loss: 2.674 Name: Jon              Language: Korean           Classified as: Korean           Correct\n",
      "Example 5000, Loss: 2.480 Name: Iniguez          Language: Spanish          Classified as: Russian          Incorrect\n",
      "Example 6000, Loss: 2.215 Name: Yamana           Language: Japanese         Classified as: Italian          Incorrect\n",
      "Example 7000, Loss: 2.080 Name: Arian            Language: Arabic           Classified as: Arabic           Correct\n",
      "Example 8000, Loss: 1.495 Name: Gashibayazov     Language: Russian          Classified as: Russian          Correct\n",
      "Example 9000, Loss: 2.504 Name: Tuma             Language: Arabic           Classified as: Korean           Incorrect\n",
      "Example 10000, Loss: 3.096 Name: Markytan         Language: Czech            Classified as: Greek            Incorrect\n",
      "Example 11000, Loss: 3.112 Name: Sleiman          Language: Arabic           Classified as: Irish            Incorrect\n",
      "Example 12000, Loss: 2.452 Name: Essa             Language: Arabic           Classified as: Vietnamese       Incorrect\n",
      "Example 13000, Loss: 3.011 Name: Stary            Language: Czech            Classified as: Japanese         Incorrect\n",
      "Example 14000, Loss: 2.649 Name: Rojas            Language: Spanish          Classified as: Greek            Incorrect\n",
      "Example 15000, Loss: 2.161 Name: Egerton          Language: English          Classified as: Scottish         Incorrect\n",
      "Example 16000, Loss: 1.872 Name: Hebert           Language: French           Classified as: French           Correct\n",
      "Example 17000, Loss: 3.835 Name: Bim              Language: Russian          Classified as: Korean           Incorrect\n",
      "Example 18000, Loss: 1.550 Name: Meeuwissen       Language: Dutch            Classified as: Dutch            Correct\n",
      "Example 19000, Loss: 3.008 Name: Graham           Language: Scottish         Classified as: Arabic           Incorrect\n",
      "Example 20000, Loss: 1.008 Name: Dubhain          Language: Irish            Classified as: Irish            Correct\n",
      "Example 21000, Loss: 2.305 Name: Yount            Language: French           Classified as: German           Incorrect\n",
      "Example 22000, Loss: 0.664 Name: Crespo           Language: Portuguese       Classified as: Portuguese       Correct\n",
      "Example 23000, Loss: 1.715 Name: D'cruz           Language: Portuguese       Classified as: Spanish          Incorrect\n",
      "Example 24000, Loss: 0.696 Name: Malouf           Language: Arabic           Classified as: Arabic           Correct\n",
      "Example 25000, Loss: 1.105 Name: Chun             Language: Korean           Classified as: Chinese          Incorrect\n",
      "Example 26000, Loss: 2.242 Name: Summers          Language: English          Classified as: Dutch            Incorrect\n",
      "Example 27000, Loss: 2.682 Name: Whyte            Language: English          Classified as: Korean           Incorrect\n",
      "Example 28000, Loss: 0.043 Name: Chrysanthopoulos Language: Greek            Classified as: Greek            Correct\n",
      "Example 29000, Loss: 1.124 Name: Vo               Language: Vietnamese       Classified as: Vietnamese       Correct\n",
      "Example 30000, Loss: 2.283 Name: Puga             Language: Spanish          Classified as: Japanese         Incorrect\n",
      "Example 31000, Loss: 0.876 Name: Bagirov          Language: Russian          Classified as: Russian          Correct\n",
      "Example 32000, Loss: 1.711 Name: Wyrick           Language: Polish           Classified as: Czech            Incorrect\n",
      "Example 33000, Loss: 0.914 Name: Cheng            Language: Chinese          Classified as: Chinese          Correct\n",
      "Example 34000, Loss: 1.722 Name: Paget            Language: French           Classified as: German           Incorrect\n",
      "Example 35000, Loss: 2.157 Name: Ashe             Language: English          Classified as: Arabic           Incorrect\n",
      "Example 36000, Loss: 2.201 Name: Sai              Language: Vietnamese       Classified as: Chinese          Incorrect\n",
      "Example 37000, Loss: 1.013 Name: Perez            Language: Spanish          Classified as: Spanish          Correct\n",
      "Example 38000, Loss: 0.645 Name: Stroggylis       Language: Greek            Classified as: Greek            Correct\n",
      "Example 39000, Loss: 1.371 Name: D'antonio        Language: Italian          Classified as: Italian          Correct\n",
      "Example 40000, Loss: 1.642 Name: Jeon             Language: Korean           Classified as: Scottish         Incorrect\n",
      "Example 41000, Loss: 0.345 Name: Teshima          Language: Japanese         Classified as: Japanese         Correct\n",
      "Example 42000, Loss: 2.279 Name: Watling          Language: English          Classified as: Italian          Incorrect\n",
      "Example 43000, Loss: 4.072 Name: Janson           Language: German           Classified as: Scottish         Incorrect\n",
      "Example 44000, Loss: 1.842 Name: John             Language: Irish            Classified as: Korean           Incorrect\n",
      "Example 45000, Loss: 0.888 Name: Hoefler          Language: German           Classified as: German           Correct\n",
      "Example 46000, Loss: 2.764 Name: Solos            Language: Spanish          Classified as: Greek            Incorrect\n",
      "Example 47000, Loss: 1.915 Name: Vandroogenbroeck Language: Dutch            Classified as: Czech            Incorrect\n",
      "Example 48000, Loss: 1.690 Name: Babayan          Language: Russian          Classified as: Irish            Incorrect\n",
      "Example 49000, Loss: 1.277 Name: Fabbro           Language: Italian          Classified as: Portuguese       Incorrect\n",
      "Example 50000, Loss: 0.324 Name: Scarsi           Language: Italian          Classified as: Italian          Correct\n",
      "Example 51000, Loss: 1.666 Name: Moreno           Language: Spanish          Classified as: Italian          Incorrect\n",
      "Example 52000, Loss: 1.550 Name: Bruckner         Language: Czech            Classified as: German           Incorrect\n",
      "Example 53000, Loss: 2.285 Name: Grant            Language: Scottish         Classified as: French           Incorrect\n",
      "Example 54000, Loss: 0.427 Name: Gomolka          Language: Polish           Classified as: Polish           Correct\n",
      "Example 55000, Loss: 1.809 Name: Winman           Language: English          Classified as: Irish            Incorrect\n",
      "Example 56000, Loss: 0.831 Name: Huo              Language: Chinese          Classified as: Chinese          Correct\n",
      "Example 57000, Loss: 0.325 Name: O'Donnell        Language: Irish            Classified as: Irish            Correct\n",
      "Example 58000, Loss: 2.440 Name: Tsai             Language: Korean           Classified as: Japanese         Incorrect\n",
      "Example 59000, Loss: 4.774 Name: Carideo          Language: Italian          Classified as: Portuguese       Incorrect\n",
      "Example 60000, Loss: 2.050 Name: Greco            Language: Italian          Classified as: Portuguese       Incorrect\n",
      "Example 61000, Loss: 0.655 Name: Halabi           Language: Arabic           Classified as: Arabic           Correct\n",
      "Example 62000, Loss: 0.334 Name: Yoo              Language: Korean           Classified as: Korean           Correct\n",
      "Example 63000, Loss: 0.452 Name: Bakshtanowsky    Language: Russian          Classified as: Russian          Correct\n",
      "Example 64000, Loss: 2.198 Name: Michel           Language: Polish           Classified as: Irish            Incorrect\n",
      "Example 65000, Loss: 1.466 Name: Close            Language: Greek            Classified as: Greek            Correct\n",
      "Example 66000, Loss: 0.345 Name: Johnstone        Language: Scottish         Classified as: Scottish         Correct\n",
      "Example 67000, Loss: 0.643 Name: Ortega           Language: Spanish          Classified as: Spanish          Correct\n",
      "Example 68000, Loss: 0.047 Name: Schetchikov      Language: Russian          Classified as: Russian          Correct\n",
      "Example 69000, Loss: 1.682 Name: Hawlata          Language: Czech            Classified as: Scottish         Incorrect\n",
      "Example 70000, Loss: 2.680 Name: Mikhail          Language: Arabic           Classified as: Russian          Incorrect\n",
      "Example 71000, Loss: 3.259 Name: Martin           Language: Scottish         Classified as: Arabic           Incorrect\n",
      "Example 72000, Loss: 0.200 Name: Panoulias        Language: Greek            Classified as: Greek            Correct\n",
      "Example 73000, Loss: 2.242 Name: Schwenke         Language: German           Classified as: Russian          Incorrect\n",
      "Example 74000, Loss: 0.393 Name: Bahlaev          Language: Russian          Classified as: Russian          Correct\n",
      "Example 75000, Loss: 0.203 Name: Stroggylis       Language: Greek            Classified as: Greek            Correct\n",
      "Example 76000, Loss: 1.205 Name: Assen            Language: Dutch            Classified as: Arabic           Incorrect\n",
      "Example 77000, Loss: 1.717 Name: Devin            Language: Irish            Classified as: French           Incorrect\n",
      "Example 78000, Loss: 1.236 Name: Roach            Language: Irish            Classified as: Irish            Correct\n",
      "Example 79000, Loss: 3.140 Name: Mcfadden         Language: English          Classified as: Dutch            Incorrect\n",
      "Example 80000, Loss: 2.051 Name: Babanoff         Language: Russian          Classified as: French           Incorrect\n",
      "Example 81000, Loss: 1.195 Name: Snijder          Language: Dutch            Classified as: Dutch            Correct\n",
      "Example 82000, Loss: 1.054 Name: Reijnder         Language: Dutch            Classified as: Dutch            Correct\n",
      "Example 83000, Loss: 0.784 Name: Labelle          Language: French           Classified as: French           Correct\n",
      "Example 84000, Loss: 1.551 Name: Hou              Language: Chinese          Classified as: Korean           Incorrect\n",
      "Example 85000, Loss: 1.029 Name: Chao             Language: Chinese          Classified as: Chinese          Correct\n",
      "Example 86000, Loss: 0.251 Name: Duong            Language: Vietnamese       Classified as: Vietnamese       Correct\n",
      "Example 87000, Loss: 0.793 Name: Arena            Language: Spanish          Classified as: Spanish          Correct\n",
      "Example 88000, Loss: 0.051 Name: Nakamoto         Language: Japanese         Classified as: Japanese         Correct\n",
      "Example 89000, Loss: 0.736 Name: Serafim          Language: Portuguese       Classified as: Portuguese       Correct\n",
      "Example 90000, Loss: 1.606 Name: Kumiega          Language: Polish           Classified as: Japanese         Incorrect\n",
      "Example 91000, Loss: 2.443 Name: Hierro           Language: Spanish          Classified as: Portuguese       Incorrect\n",
      "Example 92000, Loss: 0.520 Name: Traverso         Language: Italian          Classified as: Italian          Correct\n",
      "Example 93000, Loss: 1.575 Name: Domhnall         Language: Irish            Classified as: Scottish         Incorrect\n",
      "Example 94000, Loss: 1.241 Name: Bradan           Language: Irish            Classified as: Irish            Correct\n",
      "Example 95000, Loss: 1.151 Name: Docherty         Language: Scottish         Classified as: English          Incorrect\n",
      "Example 96000, Loss: 2.974 Name: Sai              Language: Vietnamese       Classified as: Chinese          Incorrect\n",
      "Example 97000, Loss: 0.458 Name: Hadad            Language: Arabic           Classified as: Arabic           Correct\n",
      "Example 98000, Loss: 2.739 Name: Oorschot         Language: Dutch            Classified as: French           Incorrect\n",
      "Example 99000, Loss: 0.391 Name: Gibson           Language: Scottish         Classified as: Scottish         Correct\n",
      "Example 100000, Loss: 2.722 Name: Kohl             Language: German           Classified as: Korean           Incorrect\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_iters = 100000\n",
    "\n",
    "for i in range(1, n_iters + 1):\n",
    "    language, name, lang_tensor, name_tensor = random_train_example()\n",
    "    output, loss = train_on_example(name_tensor, lang_tensor)\n",
    "\n",
    "    if not i % 1000:\n",
    "        lang_pred = languages[torch.argmax(output).item()]\n",
    "\n",
    "        print(f'Example {i}, Loss: {loss:.3f} Name: {name:16s} Language: {language:16s} Classified as: {lang_pred:16s} {\"Correct\" if lang_pred == language else \"Incorrect\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbACHnfkXuq9"
   },
   "source": [
    "### Evaluating the network\n",
    "\n",
    "We now define a function that gives the network names you can enter manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDN60k38XVAw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict(input_name, num_langs=3):\n",
    "    name_tensor = lineToTensor(input_name)\n",
    "    hidden_state = torch.zeros(1, n_hidden)\n",
    "    for character_tensor in name_tensor:\n",
    "        out, hidden_state = rnn(character_tensor, hidden_state) \n",
    "\n",
    "    dist = list(zip(languages, F.softmax(out, dim=1).squeeze()))\n",
    "\n",
    "    topk_langs = sorted(dist, key=lambda p: p[1].item())[-num_langs:]\n",
    "\n",
    "    for lang, p in reversed(topk_langs):\n",
    "        print(f'{lang}, {p.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "id": "-qOBToI1N3XW",
    "outputId": "5572c5b6-1dc2-4b5f-a802-434e4598a29e"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Raul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irish, 0.18651339411735535\n",
      "Korean, 0.1522650420665741\n",
      "French, 0.14341449737548828\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Michail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irish, 0.2261301726102829\n",
      "French, 0.14685103297233582\n",
      "Russian, 0.12820947170257568\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Maria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish, 0.5005667805671692\n",
      "Portuguese, 0.1241036057472229\n",
      "Arabic, 0.1228787750005722\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Matilde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English, 0.2228420227766037\n",
      "Irish, 0.2162756472826004\n",
      "Italian, 0.1416422724723816\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Dovesky\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian, 0.9048061370849609\n",
      "Czech, 0.06269638985395432\n",
      "Greek, 0.01034452859312296\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Hazaki\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese, 0.495209664106369\n",
      "Polish, 0.40988248586654663\n",
      "Russian, 0.05778494477272034\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Brune\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scottish, 0.47328299283981323\n",
      "French, 0.2216845452785492\n",
      "German, 0.13623590767383575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m       predict(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\ipykernel\\kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1176\u001b[0m     )\n\u001b[1;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\1B\\Deep Learning from Theory to Practice\\Tutorials\\dl_course-env\\lib\\site-packages\\ipykernel\\kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "      predict(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_for_name_classification.ipynb",
   "provenance": [
    {
     "file_id": "19Ubm0kUDdZAvzodCjkYSpYecN2p77KUQ",
     "timestamp": 1575823623248
    }
   ]
  },
  "kernelspec": {
   "display_name": "dl_course-env",
   "language": "python",
   "name": "dl_course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
